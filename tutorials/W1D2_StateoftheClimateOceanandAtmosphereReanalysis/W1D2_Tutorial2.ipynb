{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "# Tutorial 2: A lot of weather makes climate - exploring the ERA5 Reanalysis\n",
    "\n",
    "**Week 1, Day 2, Ocean-Atmosphere Reanalysis**\n",
    "\n",
    "__Content creators:__ Hell, Momme, Name Surname, Day Lead's Name\n",
    "\n",
    "**Content reviewers:** Ohad Zivan and Will Gregory \n",
    "\n",
    "**Content editors:** Ohad Zivan and Chi Zhang\n",
    "\n",
    "**Production editors:** \n",
    "\n",
    "**Our 2023 Sponsors:** NASA TOPS & Neuromatch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {},
    "tags": []
   },
   "source": [
    "## Overview\n",
    "\n",
    "In the previous section we learned about ENSO, which as an atmosphere-ocean dynamical phenomena. We will now examine the atmosphere and the ocean systems more generally. \n",
    "\n",
    " In this tutorial you will learn how to handle reanalysis data and how they derive weather and climate varaivles of interest. We will begin with two ways to access the ECMWF ERA5 renalysis, either through Poodac, or alternatively through the web copernicus api. You will learn how to pick and mask a region on interest, and see how important climate variables will change within on short timescales between days, months.\n",
    "\n",
    "By the end of this tutorial you will be able to:\n",
    "- a) access and select reanalysis data of interest\n",
    "- b) plot variables so that you can see changes in on different time scales.\n",
    "- c) derive timeseries of these variables.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {},
    "tags": []
   },
   "source": [
    "---\n",
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "cellView": "both",
    "execution": {},
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from intake import open_catalog\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import xarray as xr\n",
    "import fsspec\n",
    "import boto3\n",
    "import botocore\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import warnings\n",
    "from cartopy import crs as ccrs, feature as cfeature\n",
    "from IPython.display import IFrame\n",
    "import ipywidgets as widgets       # interactive display\n",
    "\n",
    "#  Suppress warnings issued by Cartopy when downloading data files\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "cellView": "form",
    "execution": {},
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Figure settings\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "plt.style.use(\"https://raw.githubusercontent.com/ClimateMatchAcademy/course-content/main/cma.mplstyle\")\n",
    "\n",
    "def font_for_print():\n",
    "\n",
    "    SMALL_SIZE = 8\n",
    "    MEDIUM_SIZE = 8\n",
    "    BIGGER_SIZE = 10\n",
    "    legend_properties = {'weight':'bold'}\n",
    "\n",
    "    plt.rc('font', size=SMALL_SIZE, serif='Helvetica Neue', weight='normal')          # controls default text sizes\n",
    "    #plt.rc('font', size=SMALL_SIZE, serif='DejaVu Sans', weight='light')\n",
    "    plt.rc('text', usetex='false')\n",
    "    plt.rc('axes', titlesize=MEDIUM_SIZE, labelweight='normal')     # fontsize of the axes title\n",
    "    plt.rc('axes', labelsize=SMALL_SIZE, labelweight='normal') #, family='bold')    # fontsize of the x and y labels\n",
    "    plt.rc('xtick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "    plt.rc('ytick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "    plt.rc('legend', fontsize=SMALL_SIZE, frameon=False)    # legend fontsize\n",
    "    plt.rc('figure', titlesize=MEDIUM_SIZE, titleweight='bold', autolayout=True) #, family='bold')  # fontsize of the figure title\n",
    "\n",
    "    plt.rc('axes', labelsize= SMALL_SIZE, labelweight='normal')\n",
    "\n",
    "font_for_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "cellView": "form",
    "execution": {},
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plotting functions\n",
    "\n",
    "def format_axes(ax):\n",
    "    ax.add_feature(cfeature.COASTLINE)\n",
    "    ax.add_feature(cfeature.LAKES, edgecolor='black', facecolor='None', alpha=0.3 )\n",
    "    gl = ax.gridlines(draw_labels=True, linewidth=1, color='black', alpha=0.5, linestyle='--')\n",
    "    gl.xlocator = matplotlib.ticker.MaxNLocator(2)\n",
    "    gl.ylocator = matplotlib.ticker.MaxNLocator(2)\n",
    "    gl.xlabels_top  = False\n",
    "    gl.ylabels_left = False\n",
    "\n",
    "    \n",
    "def plot_variable_Facet(dataset, var, time_dim = \"time\", title=None, cmap = None):\n",
    "\n",
    "    if len(dataset[time_dim]) > 6:\n",
    "        raise Warning(\"too many time steps selected, please select less then 6\")\n",
    "        return\n",
    "\n",
    "    cmap = plt.cm.coolwarm if cmap is None else cmap\n",
    "\n",
    "    data_sel_plot = dataset[var].plot(\n",
    "        aspect = 0.8,\n",
    "        transform=ccrs.PlateCarree(),\n",
    "        col=time_dim,\n",
    "        subplot_kws={\"projection\": ccrs.Orthographic(-80, 35)},\n",
    "        cmap=cmap,\n",
    "        add_colorbar =True)#,col_wrap=1 )\n",
    "\n",
    "    for ax in data_sel_plot.axs[0]:\n",
    "        format_axes(ax)\n",
    "\n",
    "    if title is not None:\n",
    "        title_name= title\n",
    "    else:\n",
    "        try:\n",
    "            title_name = ERA5_durinal_cycle[var].attrs['long_name']\n",
    "        except:\n",
    "            title_name = None\n",
    "            pass\n",
    "\n",
    "    plt.suptitle(title_name, y = 1.01)\n",
    "\n",
    "    return data_sel_plot\n",
    "\n",
    "def cbar_label(DD):\n",
    "    return DD.attrs['long_name'] + ' [' + DD.attrs['units']+ ']'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "cellView": "form",
    "execution": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "\n",
    "def set_region_figure(lon_range, lat_range, projection = ccrs.PlateCarree(), figsize =(5, 4.5) ):\n",
    "    # source:https://foundations.projectpythia.org/core/cartopy/cartopy.html\n",
    "\n",
    "    lonE, lonW = lon_range\n",
    "    latN, latS = lat_range\n",
    "\n",
    "    cLat = (latN + latS) / 2\n",
    "    cLon = (lonW + lonE) / 2\n",
    "    projLccNY = ccrs.LambertConformal(central_longitude=cLon, central_latitude=cLat)\n",
    "\n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    ax = plt.subplot(1, 1, 1, projection=projLccNY)\n",
    "    ax.set_extent([lonW, lonE, latS, latN])#, crs=projPC)\n",
    "\n",
    "    #ax.set_facecolor(cfeature.COLORS['water'])\n",
    "    #ax.add_feature(cfeature.LAND)\n",
    "    #ax.add_feature(cfeature.COASTLINE)\n",
    "    #ax.add_feature(cfeature.BORDERS, linestyle='--')\n",
    "\n",
    "    #ax.add_feature(cfeature.NaturalEarthFeature('physical', 'land', '50m', edgecolor='black', alpha = 0.2, facecolor='gray'))\n",
    "    #ax.add_feature(cfeature.LAKES, facecolor='white', alpha=0.5 )\n",
    "\n",
    "    # gl = ax.gridlines(\n",
    "    #     draw_labels=True, linewidth=1, color='black', alpha=0.5, linestyle='--'\n",
    "    # )\n",
    "\n",
    "    format_axes(ax)\n",
    "    #ax.add_feature(cfeature.STATES)\n",
    "    #ax.add_feature(cfeature.RIVERS)\n",
    "    return fig, ax\n",
    "\n",
    "def get_time_compared_to_UTC(longitude):\n",
    "    \"\"\"\n",
    "    Converts a longitude value to the corresponding local time and offset from UTC.\n",
    "\n",
    "    Parameters:\n",
    "    longitude (float): The longitude value in degrees.\n",
    "\n",
    "    Returns:\n",
    "    numpy.datetime64: The current local time at the given longitude.\n",
    "    datetime.timedelta: The offset from UTC in hours and minutes.\n",
    "    \"\"\"\n",
    "    # Calculate the time offset from UTC based on the longitude\n",
    "    offset_hours = round(longitude / 15)\n",
    "    offset_minutes = round((longitude / 15 - offset_hours) * 60)\n",
    "    offset = np.timedelta64(offset_hours, 'h') + np.timedelta64(offset_minutes, 'm')\n",
    "\n",
    "    return offset.astype('m8[h]')\n",
    "\n",
    "def geographic_lon_to_360(lon):\n",
    "    return 360 + lon\n",
    "\n",
    "def inverted_geographic_lon_to_360(lon):\n",
    "    return lon - 180"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Title Video 1: Video 1 Name \n",
    "\n",
    "something something + link? \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "## Introduction: What are Reanalysis data?\n",
    "\n",
    "We know that earth is warming. But how do we know that, and how do we know how that changes weather and climate? These are very hard questions, but thanks to work of many scientist, we now have data that allows to pick at any place of the planet and look how weather and cliamte has changes since 1979. This data is called **Reanalysis data**, and refers to the process of combining historical observations from a variety of sources, such as weather stations, satellites, and buoys, with numerical models to create a comprehensive and consistent record of past weather and climate conditions. Reanalysis data is then used to study the Earth's climate system over a wide range of time scales, from seasonal to decadal to century-scale changes. By providing a complete picture of the Earth's climate history, reanalysis data is great tool to understand the causes and effects of climate change.\n",
    "\n",
    "[This video](https://climate.copernicus.eu/climate-reanalysis) from the European Centre for Medium-Range Weather Forecasts (ECMWF) provides you with a brief introdution about their reanalysis, called **ERA5**. Note that there is not one reanalysis product that that fits all needs, such that there are many earth reanalysis like MERRA-2, NCEP-NCAR, JRA-55C, and many others [see extensive list here](https://climatedataguide.ucar.edu/climate-data/atmospheric-reanalysis-overview-comparison-tables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "## Part I: Accessing ERA5 data\n",
    "\n",
    "For this tutorial we stick with ERA5. \n",
    "There are multiple way to accesss ERA5 data. You can browse the [Copernicus ERA5 storage](https://cds.climate.copernicus.eu/cdsapp#!/search?text=ERA5%20back%20extension&type=dataset), use the [copernicus client](https://cds.climate.copernicus.eu/api-how-to), or the [era5cli package](https://era5cli.readthedocs.io/en/stable/). Here are futher instruction [how to use it directly in your jupyter notebook](https://towardsdatascience.com/read-era5-directly-into-memory-with-python-511a2740bba0). \n",
    "\n",
    "However, for the this tutorial we will access the data through the an AWS s3 bucket of the data: [ECMWF ERA5 Reanalysis](https://registry.opendata.aws/ecmwf-era5/). For that we just need the name of the bucket \"era5-pds\"\n",
    "\n",
    "https://github.com/planet-os/notebooks/blob/master/aws/era5-s3-via-boto.ipynb\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1979/\n",
      "1980/\n",
      "1981/\n",
      "1982/\n",
      "1983/\n",
      "1984/\n",
      "1985/\n",
      "1986/\n",
      "1987/\n",
      "1988/\n",
      "1989/\n",
      "1990/\n",
      "1991/\n",
      "1992/\n",
      "1993/\n",
      "1994/\n",
      "1995/\n",
      "1996/\n",
      "1997/\n",
      "1998/\n",
      "1999/\n",
      "2000/\n",
      "2001/\n",
      "2002/\n",
      "2003/\n",
      "2004/\n",
      "2005/\n",
      "2006/\n",
      "2007/\n",
      "2008/\n",
      "2009/\n",
      "2010/\n",
      "2011/\n",
      "2012/\n",
      "2013/\n",
      "2014/\n",
      "2015/\n",
      "2016/\n",
      "2017/\n",
      "2018/\n",
      "2019/\n",
      "2020/\n",
      "2021/\n",
      "2022/\n",
      "2023/\n",
      "QA/\n",
      "zarr/\n"
     ]
    }
   ],
   "source": [
    "# not needed/nor working in stand-alone version\n",
    "# cat = open_catalog(\"https://raw.githubusercontent.com/pangeo-data/pangeo-datastore/master/intake-catalogs/atmosphere.yaml\")\n",
    "# ERA5  = cat[\"era5_hourly_reanalysis_single_levels_sa\"].to_dask()\n",
    "# ERA5\n",
    "# !aws s3 ls --no-sign-request s3://era5-pds/2010/01/\n",
    "# url = 's3://era5-pds/PRE 2010/01/main.nc'\n",
    "# ncfile = fsspec.open(url)\n",
    "# ds = xr.open_dataset(ncfile.open())\n",
    "\n",
    "era5_bucket = 'era5-pds'\n",
    "client = boto3.client('s3', config=botocore.client.Config(signature_version=botocore.UNSIGNED))\n",
    "paginator = client.get_paginator('list_objects')\n",
    "result = paginator.paginate(Bucket=era5_bucket, Delimiter='/')\n",
    "for prefix in result.search('CommonPrefixes'):\n",
    "    print(prefix.get('Prefix'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "You can see the available variables here if you like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# not needed/nor working in stand-alone version\n",
    "# for k in list(set(ERA5.variables.keys()) - set(ERA5.coords.keys()) ) :\n",
    "#     print('variable name:' , k, ':')\n",
    "#     print('long name:' ,ERA5[k].attrs['long_name'])\n",
    "#     print('units:', ERA5[k].attrs['units'] )\n",
    "#     print('--------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "You see here an xarray dataset as introduced at the first day, with its coordinates and 17 variables covering the whole globe (-90 to +90 degrees in latitude, 0 to 360 degrees on longitude) and 30 years from 1979 to 2018. With this dataser you have access to our best guesses of variables on the earth surface with a spatial resolution 1/4 degree, that means each grid point represents about 25 km x 25 km, and a temporal resolution of 1 hour (!). That is a lot of data, but still just a fraction the data available trough the ERA5 web api (LINK). See the end of the tutorial for more information which variables are available. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "## Part II: Selecting regions and plotting data\n",
    "Because the available data is so large, infact certainly too large to store it on your computer, we here just use subsets of this data to illustrate its use. Select one of the regions below to work with. \n",
    "\n",
    "Alternatively you can also define your own region (where you live for example), eventhough coastal regions work best for this exercise. For that please define a longitude and latitude range of a size between 10 and 50 degrees of a coastal region.\n",
    "To find the longitude and latitude coodinates of your region, you can use [google earth view](https://earth.google.com/), and read the position of your cursor in lower right corner.\n",
    "\n",
    "#### Note about the geographic coordinate system and the coodinates used in this data set:\n",
    "A point on earth is reference in latitude-longitude coodinates relative to the zero meridian going through the Greenwich UK (longitude = 0 degree) and the equator (latitude = 0 degrees). That means points east of Greenwich up to the dateline on the other side of the globe are referencedas 0 to +180 and point to the west are 0 to -180. -180 and +180 refer to the same longitude, the so called \"dateline\" in the central pacific. However, Our data is referenced in an alternative way: Starting at the dateline, at 180 degrees longitude and then counting eastward to 360. \n",
    "The conversion between both reference systems is given in the fuctions below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# Note I: The order of range has to follow the convention of the data set.\n",
    "# For this dataset, the longitude range goes from 0 to 360 degrees and\n",
    "# the latitude range from 90 degrees North to 90 South.\n",
    "\n",
    "## Regions:\n",
    "\n",
    "# North eastern United States\n",
    "lat_range = [55.2, 30.2] # From north to south\n",
    "lon_range = [geographic_lon_to_360(-90.0), geographic_lon_to_360(-65)] # from west to east\n",
    "\n",
    "# Coast of Brazil\n",
    "\n",
    "# Coast western Africa\n",
    "\n",
    "# Coast South Andes\n",
    "\n",
    "# Coast of India\n",
    "\n",
    "# Coast of South East Asia\n",
    "\n",
    "# !!! add more examples here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "next select a year and month that you want to work with. We recommend using a spring or summer month in the respective hemisphere:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {}
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:\\\\Users\\\\ohadz\\\\Desktop\\\\CMA stuff\\\\Python\\\\course-content\\\\tutorials\\\\W1D2_StateoftheClimateOceanandAtmosphereReanalysis\\\\ERA5_select_example.nc'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\climatematch_test\\lib\\site-packages\\xarray\\backends\\file_manager.py:210\u001b[0m, in \u001b[0;36mCachingFileManager._acquire_with_cache_info\u001b[1;34m(self, needs_lock)\u001b[0m\n\u001b[0;32m    209\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 210\u001b[0m     file \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cache\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_key\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m    211\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\climatematch_test\\lib\\site-packages\\xarray\\backends\\lru_cache.py:56\u001b[0m, in \u001b[0;36mLRUCache.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m---> 56\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cache\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     57\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cache\u001b[38;5;241m.\u001b[39mmove_to_end(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: [<class 'netCDF4._netCDF4.Dataset'>, ('C:\\\\Users\\\\ohadz\\\\Desktop\\\\CMA stuff\\\\Python\\\\course-content\\\\tutorials\\\\W1D2_StateoftheClimateOceanandAtmosphereReanalysis\\\\ERA5_select_example.nc',), 'r', (('clobber', True), ('diskless', False), ('format', 'NETCDF4'), ('persist', False)), '491d462f-8832-4ba1-81a8-61c204978371']",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 12\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m### for pangeo access:\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# date = '2018-03'\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     10\u001b[0m \n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m### stand-alone version:\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m ERA5_select \u001b[38;5;241m=\u001b[39m \u001b[43mxr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mERA5_select_example.nc\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m ERA5_select\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\climatematch_test\\lib\\site-packages\\xarray\\backends\\api.py:525\u001b[0m, in \u001b[0;36mopen_dataset\u001b[1;34m(filename_or_obj, engine, chunks, cache, decode_cf, mask_and_scale, decode_times, decode_timedelta, use_cftime, concat_characters, decode_coords, drop_variables, inline_array, backend_kwargs, **kwargs)\u001b[0m\n\u001b[0;32m    513\u001b[0m decoders \u001b[38;5;241m=\u001b[39m _resolve_decoders_kwargs(\n\u001b[0;32m    514\u001b[0m     decode_cf,\n\u001b[0;32m    515\u001b[0m     open_backend_dataset_parameters\u001b[38;5;241m=\u001b[39mbackend\u001b[38;5;241m.\u001b[39mopen_dataset_parameters,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    521\u001b[0m     decode_coords\u001b[38;5;241m=\u001b[39mdecode_coords,\n\u001b[0;32m    522\u001b[0m )\n\u001b[0;32m    524\u001b[0m overwrite_encoded_chunks \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moverwrite_encoded_chunks\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m--> 525\u001b[0m backend_ds \u001b[38;5;241m=\u001b[39m backend\u001b[38;5;241m.\u001b[39mopen_dataset(\n\u001b[0;32m    526\u001b[0m     filename_or_obj,\n\u001b[0;32m    527\u001b[0m     drop_variables\u001b[38;5;241m=\u001b[39mdrop_variables,\n\u001b[0;32m    528\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mdecoders,\n\u001b[0;32m    529\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    530\u001b[0m )\n\u001b[0;32m    531\u001b[0m ds \u001b[38;5;241m=\u001b[39m _dataset_from_backend_dataset(\n\u001b[0;32m    532\u001b[0m     backend_ds,\n\u001b[0;32m    533\u001b[0m     filename_or_obj,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    541\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    542\u001b[0m )\n\u001b[0;32m    543\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ds\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\climatematch_test\\lib\\site-packages\\xarray\\backends\\netCDF4_.py:588\u001b[0m, in \u001b[0;36mNetCDF4BackendEntrypoint.open_dataset\u001b[1;34m(self, filename_or_obj, mask_and_scale, decode_times, concat_characters, decode_coords, drop_variables, use_cftime, decode_timedelta, group, mode, format, clobber, diskless, persist, lock, autoclose)\u001b[0m\n\u001b[0;32m    567\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mopen_dataset\u001b[39m(  \u001b[38;5;66;03m# type: ignore[override]  # allow LSP violation, not supporting **kwargs\u001b[39;00m\n\u001b[0;32m    568\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    569\u001b[0m     filename_or_obj: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m|\u001b[39m os\u001b[38;5;241m.\u001b[39mPathLike[Any] \u001b[38;5;241m|\u001b[39m BufferedIOBase \u001b[38;5;241m|\u001b[39m AbstractDataStore,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    585\u001b[0m     autoclose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    586\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Dataset:\n\u001b[0;32m    587\u001b[0m     filename_or_obj \u001b[38;5;241m=\u001b[39m _normalize_path(filename_or_obj)\n\u001b[1;32m--> 588\u001b[0m     store \u001b[38;5;241m=\u001b[39m \u001b[43mNetCDF4DataStore\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    589\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename_or_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    590\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    591\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    592\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgroup\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    593\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclobber\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclobber\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    594\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdiskless\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdiskless\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    595\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpersist\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpersist\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    596\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlock\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlock\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    597\u001b[0m \u001b[43m        \u001b[49m\u001b[43mautoclose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mautoclose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    598\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    600\u001b[0m     store_entrypoint \u001b[38;5;241m=\u001b[39m StoreBackendEntrypoint()\n\u001b[0;32m    601\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m close_on_error(store):\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\climatematch_test\\lib\\site-packages\\xarray\\backends\\netCDF4_.py:389\u001b[0m, in \u001b[0;36mNetCDF4DataStore.open\u001b[1;34m(cls, filename, mode, format, group, clobber, diskless, persist, lock, lock_maker, autoclose)\u001b[0m\n\u001b[0;32m    383\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(\n\u001b[0;32m    384\u001b[0m     clobber\u001b[38;5;241m=\u001b[39mclobber, diskless\u001b[38;5;241m=\u001b[39mdiskless, persist\u001b[38;5;241m=\u001b[39mpersist, \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mformat\u001b[39m\n\u001b[0;32m    385\u001b[0m )\n\u001b[0;32m    386\u001b[0m manager \u001b[38;5;241m=\u001b[39m CachingFileManager(\n\u001b[0;32m    387\u001b[0m     netCDF4\u001b[38;5;241m.\u001b[39mDataset, filename, mode\u001b[38;5;241m=\u001b[39mmode, kwargs\u001b[38;5;241m=\u001b[39mkwargs\n\u001b[0;32m    388\u001b[0m )\n\u001b[1;32m--> 389\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmanager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroup\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlock\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlock\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mautoclose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mautoclose\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\climatematch_test\\lib\\site-packages\\xarray\\backends\\netCDF4_.py:336\u001b[0m, in \u001b[0;36mNetCDF4DataStore.__init__\u001b[1;34m(self, manager, group, mode, lock, autoclose)\u001b[0m\n\u001b[0;32m    334\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_group \u001b[38;5;241m=\u001b[39m group\n\u001b[0;32m    335\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mode \u001b[38;5;241m=\u001b[39m mode\n\u001b[1;32m--> 336\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mformat \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mds\u001b[49m\u001b[38;5;241m.\u001b[39mdata_model\n\u001b[0;32m    337\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_filename \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mds\u001b[38;5;241m.\u001b[39mfilepath()\n\u001b[0;32m    338\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_remote \u001b[38;5;241m=\u001b[39m is_remote_uri(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_filename)\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\climatematch_test\\lib\\site-packages\\xarray\\backends\\netCDF4_.py:398\u001b[0m, in \u001b[0;36mNetCDF4DataStore.ds\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    396\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[0;32m    397\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mds\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 398\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_acquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\climatematch_test\\lib\\site-packages\\xarray\\backends\\netCDF4_.py:392\u001b[0m, in \u001b[0;36mNetCDF4DataStore._acquire\u001b[1;34m(self, needs_lock)\u001b[0m\n\u001b[0;32m    391\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_acquire\u001b[39m(\u001b[38;5;28mself\u001b[39m, needs_lock\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m--> 392\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_manager\u001b[38;5;241m.\u001b[39macquire_context(needs_lock) \u001b[38;5;28;01mas\u001b[39;00m root:\n\u001b[0;32m    393\u001b[0m         ds \u001b[38;5;241m=\u001b[39m _nc4_require_group(root, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_group, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mode)\n\u001b[0;32m    394\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ds\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\climatematch_test\\lib\\contextlib.py:135\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__enter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    133\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwds, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc\n\u001b[0;32m    134\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 135\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    136\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[0;32m    137\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgenerator didn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt yield\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\climatematch_test\\lib\\site-packages\\xarray\\backends\\file_manager.py:198\u001b[0m, in \u001b[0;36mCachingFileManager.acquire_context\u001b[1;34m(self, needs_lock)\u001b[0m\n\u001b[0;32m    195\u001b[0m \u001b[38;5;129m@contextlib\u001b[39m\u001b[38;5;241m.\u001b[39mcontextmanager\n\u001b[0;32m    196\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21macquire_context\u001b[39m(\u001b[38;5;28mself\u001b[39m, needs_lock\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m    197\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Context manager for acquiring a file.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 198\u001b[0m     file, cached \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_acquire_with_cache_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43mneeds_lock\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    199\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    200\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m file\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\climatematch_test\\lib\\site-packages\\xarray\\backends\\file_manager.py:216\u001b[0m, in \u001b[0;36mCachingFileManager._acquire_with_cache_info\u001b[1;34m(self, needs_lock)\u001b[0m\n\u001b[0;32m    214\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m    215\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mode\n\u001b[1;32m--> 216\u001b[0m file \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_opener(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    217\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# ensure file doesn't get overridden when opened again\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32msrc\\netCDF4\\_netCDF4.pyx:2449\u001b[0m, in \u001b[0;36mnetCDF4._netCDF4.Dataset.__init__\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32msrc\\netCDF4\\_netCDF4.pyx:2012\u001b[0m, in \u001b[0;36mnetCDF4._netCDF4._ensure_nc_success\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:\\\\Users\\\\ohadz\\\\Desktop\\\\CMA stuff\\\\Python\\\\course-content\\\\tutorials\\\\W1D2_StateoftheClimateOceanandAtmosphereReanalysis\\\\ERA5_select_example.nc'"
     ]
    }
   ],
   "source": [
    "### for pangeo access:\n",
    "# date = '2018-03'\n",
    "\n",
    "# # select the longitude-latitude box\n",
    "# ERA5_select = ERA5.sel(longitude= slice(lon_range[0] , lon_range[1])).sel(latitude = slice(lat_range[0] , lat_range[1]))\n",
    "\n",
    "# # select the month and the 3 variables we are intersted in\n",
    "# ERA5_select = ERA5_select.sel(time =date)[['t2m', 'u10', 'v10', 'tcc']]\n",
    "# #ERA5_select = ERA5_select.isel(time =slice(0, 72))\n",
    "\n",
    "### stand-alone version:\n",
    "ERA5_select = xr.open_dataset('ERA5_select_example.nc')\n",
    "ERA5_select"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "Now lets plot data in this selected month. To understand the variable of the data we do that in 3 three different ways.\n",
    "1) Durinal cycle: We plot the mean of the 2-meter temperature, cloud cover, and surface wind speed at 0,6,12,18h of the local time (!)\n",
    "1) Synoptic variability: We plot the same variables at noon local time every 5th day.\n",
    "2) Monthly climatology: we plot the monthly climatology of the same variables\n",
    "\n",
    "To get he surface wind speed we need to combine the zonald and meridional wind to an new variable \"u_speed\" in the data set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "ERA5_select['u_speed'] = np.sqrt(ERA5_select['u10']**2 + ERA5_select['v10']**2)\n",
    "# for having the right name and units in the DataArray:\n",
    "ERA5_select['u_speed'].attrs['long_name'] = \"10-meter wind speed\"\n",
    "ERA5_select['u_speed'].attrs['units'] = \"m/s\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "## Part III: Plotting spatial maps\n",
    "### 1. Making a first plot\n",
    "Let plot some data! Pick any day wihtin the month you selected before and plot the 2-meter temperature, the wind speed and the total cloud cover."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "date = \"2018-03\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# ERA5_one_day = ERA5_select.isel(time = 29)\n",
    "# or alternatively, you can speficy the data of the day\n",
    "day_string = date +'-02'\n",
    "ERA5_one_day = ERA5_select.sel(time = day_string ).mean('time')\n",
    "\n",
    "for var in  ['t2m', 'tcc', 'u_speed']:\n",
    "    F, ax = set_region_figure(lon_range, lat_range)\n",
    "\n",
    "    #format_axes(ax)\n",
    "    ax.set_title('Example Region | '+ var +' | '+ day_string)\n",
    "    dataplot = ax.contourf(ERA5_select.longitude, ERA5_select.latitude, ERA5_one_day[var], transform=ccrs.PlateCarree())\n",
    "    plt.colorbar(dataplot, orientation='vertical', label = cbar_label(ERA5_select[var]) )\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "### *Exercise:*\n",
    "- Change the day you plot and try to observe how the temperature and the other two variables change betwee the days. We will look at the more carefully below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "### 2. Synoptic Variabilty\n",
    "Lets explore how the temperature, ccloud cover and surface wind speed change in this region due to changes in weather. In most regions of the world the weather changes about every 5 days. Such that it will be helpful to look at the daily data every 5th day.\n",
    "\n",
    "### Exercise:\n",
    "To select dailyt means every 5 days, use the data in the selected region 'ERA5_select' an the function xr.resample. Then take the daily mean and then select the 0, 5, 10, and 15th day.\n",
    "In a last step create the monthly mean of the data and subtract it from the select 5 days such that we can plot the anomalies from the monthly mean:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# annswer\n",
    "ERA5_synoptic= ERA5_select.resample({'time': '1D'}).mean('time').isel(time=[0,5,10,15])\n",
    "ERA5_select_mm = ERA5_select.mean('time').compute()\n",
    "ERA5_synoptic = (ERA5_synoptic - ERA5_select.mean('time')).compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "Lets then plot the monthly mean and the 4 days foreach variable. Use the framework from the last section for the monthly mean and the function *plot_variable_Facet* like this:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# plot_variable_Facet(dataset, # the calculated data with only 4 selected timesteps\n",
    "#                     var_name, #the name of the variable you want to plot (string)\n",
    "#                     time_dim, \"time\", #the dimension along the facets of plots will be made, use \"time\" here\n",
    "#                     title # optional string to give the plot a title\n",
    "#                    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "#answer, most compact version\n",
    "for var in ['t2m', 'u_speed', 'tcc']:\n",
    "\n",
    "    F, ax = set_region_figure(lon_range, lat_range)\n",
    "    ax.set_title('Monthly mean of '+ var )\n",
    "    dataplot = ax.contourf(ERA5_select_mm.longitude, ERA5_select_mm.latitude, ERA5_select_mm[var], transform=ccrs.PlateCarree())\n",
    "    plt.colorbar(dataplot, orientation='vertical', label = cbar_label(ERA5_select[var]) )\n",
    "    plt.show()\n",
    "\n",
    "    title_str =  ERA5_select[var].attrs['long_name'] + \" | daily anomalie from the monthly mean \"\n",
    "    aa = plot_variable_Facet(ERA5_synoptic, var, time_dim =\"time\", title =title_str)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "you should see 4 panels for each variable. Each panel shows the difference, the anomalie, to the monthly mean, and each panel is 5 days appart. You see that indeed the "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "### 3. Durinal cycle - Coastel clouds at the coast on a sunny day?\n",
    "There is more the synoptic variability (~5 days) in the data. Lets think about how our data varying within 24 hours, but for that we have to look at the hourly data, rather then the daily mean. \n",
    "During the day, the sun warms the surface and effect many other variables, like winds and cloud cover, eventhough that really depends on the region and the month you choose. To see the durinal cycle in the data we want to select timestamps in the morning (6 am), at noon (12pm), in the evening (6pm), at midnight (12 am). \n",
    "\n",
    "However, the ERA5 data is saved with the UTC (Coordinated Universal Time), such that we have to shift the time axis to the local time. Here we take a shortcut use the longitudinal coordinate as proxi for the local time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# this functionn takes a longitudinal coodinate and returns the timezone difference compared to UTC.\n",
    "# lets use here the center between the longitude boundaries of the domain and express it in the -180 to 180 coordinates again\n",
    "time_shift = get_time_compared_to_UTC(np.mean(lon_range) - 360)\n",
    "# define a new coodinate \"local_time\" and add it to the coordinates of the dataset\n",
    "ERA5_select.coords['local_time'] = ERA5_select.coords['time'] + time_shift\n",
    "\n",
    "#this provides us with two time coorinates, one in UTC \"time\" and one in local time \"local time\"\n",
    "print(\"UTC time   \", ERA5_select.coords['time'][0:2].data)\n",
    "print(\"local time \", ERA5_select.coords['local_time'][0:2].data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "Now we want to calculate the typical durinal cycle for the year and the month we chose before. For that, we can group the data by hour of the day, andthen take the mean for each hour of the day over the whole month, and then select hour 0 (midnight), 6, 12, and 24:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "ERA5_durinal_cycle= ERA5_select.groupby('local_time.hour').mean('time').sel(hour=[0,6, 12,18])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "It is often better to show the data as the anomalie from a mean value, to see the differences in the data better. For that, we here just take the mean over the whole month and subtract it. The remaining data is the anomalous data, i.e. the anomalie of the durinal cyle from the monthly mean:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "ERA5_durinal_cycle_anomalie = ERA5_durinal_cycle - ERA5_select.mean('time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# here we take the anomalie value because the spatial temperature difference can be quiet large.\n",
    "var= 't2m'\n",
    "plot_variable_Facet(ERA5_durinal_cycle_anomalie, var, time_dim =\"hour\", title = \"2-meter temperature Anomalie from monthly mean at hour:\")\n",
    "plt.show()\n",
    "\n",
    "var= 'u_speed'\n",
    "plot_variable_Facet(ERA5_durinal_cycle_anomalie, var, time_dim =\"hour\", title = \"typical Wind Speed Anomalie at hour:\")\n",
    "ax = plt.gca()\n",
    "plt.show()\n",
    "\n",
    "var= 'tcc'\n",
    "plot_variable_Facet(ERA5_durinal_cycle_anomalie, var, time_dim =\"hour\", title = \"Total Cloud Cover Anomalie at hour\", cmap = plt.cm.Purples)\n",
    "ax = plt.gca()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "### *Discussion Questions:*\n",
    " - Where in your choosen region do you see the largest typical temperature changes over the course of the day? Where do see the smallest changes? Is that what you expected?\n",
    " - Look at the wind speed and the surface temperature. Where do you see the strongest wind anomalies over the course of a day, why? \n",
    " - Where do you see the most cloud cover? how is that related to the winds and the temperature?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "#### short answers: \n",
    "- Where in your choosen region do you see the largest typical temperature changes over the course of the day? Where do see the smallest changes? Is that what you expected?\n",
    "the largest changes are over land, because the land repsonses quickly to solar radiation. the changes over the ocean are small, because the ocean need much longer to heat up by the sun.\n",
    " - Look at the wind speed and the surface temperature. Where do you see the strongest wind anomalies over the course of a day, why? \n",
    "The winds are stronger over land when the solar radiation is highest and the surface the warmest. The changes in the durinal cycle of winds over the ocean however is small (that doesn't mean the winds are generally weak).\n",
    " - Where do you see the most cloud cover? how is that related to the winds and the temperature?\n",
    " the largest cloud cover is along the coast line because of the sea-breeze phenomonen. it advects cold air from the ocean over to the land and leads to clouds.\n",
    " \n",
    " have a look here:\n",
    " https://www.youtube.com/watch?v=X2Wfp2rPvMY \n",
    " and read here:\n",
    " https://resources.eumetrain.org/satmanu/CMs/SB/print.htm "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "## Part 4: Another way to look at variabilty: Creating time series\n",
    "\n",
    "By not you might have realized that there are a lot of change in the data on many time scale, ranging from changes wihtin a day to, changes from day to day and from month to month. This *variability* in the data important to understand when we do climate analysis. \n",
    "\n",
    "Rather then plotting spatial maps for different time steps or time scale, in this last part of the tutorial we will create timeseries from the same data you look at already. That is staight foreward. Instead of taking the mean in time, we take the mean in space. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "ERA5_ts = ERA5_select.mean(['longitude', 'latitude']).compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "fig, ax_list = plt.subplots(3, 1, figsize=(7, 6.6),  sharex=True)\n",
    "\n",
    "for var, ax in  zip(['t2m', 'tcc', 'u_speed'], ax_list ):\n",
    "\n",
    "    ax.plot(ERA5_ts.time, ERA5_ts[var])\n",
    "    ax.set_title(cbar_label(ERA5_select[var]), loc='left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "### *Questions*\n",
    "- Which variable is dominated by the durinal cycle?\n",
    "- which variable by the synoptic scale (~ 5 day)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "## *Exercise*:\n",
    "In this final exercise, let's compare the effect of spatial averaging and temporal avering on the data.\n",
    "For that, focus on the surface wind speed 'u_speed' and make four different time series that represent the wind speed in the region\n",
    "- 1) ERA5_ts_spatial_average  - *this is the timeseries of the spatial average of data for each timestep (as above)*\n",
    "- 2) ERA5_ts_point - *this is the hourly timeseries on data at one grid point in the center of your domain*\n",
    "- 3) ERA5_ts_point_daily  - *this is the timeseries of the point data but resamples the daily values*\n",
    "- 3) ERA5_ts_spatial_average_daily  - *this is the timeseries of the spatially averaged data but also resamples the daily values*\n",
    "\n",
    "plot the data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# answers:\n",
    "var = 'u_speed'\n",
    "ERA5_ts_spatial_average = ERA5_select[var].mean(['longitude', 'latitude']).compute()\n",
    "ERA5_ts_point           = ERA5_select[var].sel( longitude =np.mean(lon_range) , latitude =np.mean(lat_range), method ='nearest' ).compute()\n",
    "\n",
    "ERA5_ts_point_daily     = ERA5_ts_point.resample({'time' :'1D'}, offset= '12h').mean()\n",
    "ERA5_ts_spatial_average_daily = ERA5_ts_spatial_average.resample({'time' :'1D'}, offset= '12h').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "#answer part II:\n",
    "ERA5_ts_point.plot(color= 'gray', label = 'point data')\n",
    "ERA5_ts_point_daily.plot(color= 'black', marker='*', label = 'daily average point data')\n",
    "\n",
    "ERA5_ts_spatial_average.plot(color= 'darkblue', label = 'spatial average')\n",
    "ERA5_ts_spatial_average_daily.plot(color= 'blue', marker='*', label = 'daily and spatial average')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "## *Questions*:\n",
    "- What is the difference in these 4 four time series?\n",
    "- What version represents the wind speed in the region the best way?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "#comments:\n",
    "\n",
    "All four timeseries are different represenations on the wind variability in the region. \n",
    "The spatial averaging acts as a smothing of the data and hene has less varaiblity the the point data. However, we often don't have all the data all the time and instead just some *sample* of the wind speed, as for example in the point data. \n",
    "But that point data shows a different variability than then spatial average, regardless if we resample to 1 day or not. Be aware that the resolution of the data and the way it is averaged and sampled matters!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "---\n",
    "# Summary\n",
    "\n",
    "In this tutorial you learned how to access and navigaate ERA5 renanlysis data. You can now select subregions in the renalysis and take averages or subsamples in space and time.\n",
    "You have seen how averaging data reduces the variabilty and that any dataset, ranging from timeseries to spatial maps has a resolution and a timestep that are important to know when understanding the data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "---\n",
    "# Bonus: Extending the timeseries analysis to long timeperiods\n",
    "\n",
    "\n",
    "Use the tools provided above and make a timeseries of the surface temperature und and surface wind over the 30 years of the ERA5 data. First select the region in ERA5 as before but know use all time steps. Then resample to daily means and plot each variable in a single planel or figure.\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "W1D2_Tutorial2",
   "provenance": [],
   "toc_visible": true
  },
  "kernel": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
