{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "# Tutorial 1: Paleoclimate Proxies\n",
    "\n",
    "**Week 1, Day 4, Paleoclimate**\n",
    "\n",
    "**Content creators:** Sloane Garelick\n",
    "\n",
    "**Content reviewers:** Brodie Pearson\n",
    "\n",
    "**Content editors:** Yosmely Berm√∫dez, Agustina Pesce, Zahra Khodakaramimaghsoud\n",
    "\n",
    "**Production editors:** TBD\n",
    "\n",
    "**Our 2023 Sponsors:** TBD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "###**Code and Data Sources**\n",
    "\n",
    "Code for this tutorial is based on existing notebooks from LinkedEarth that [convert LiPD files to a Pandas dataframe](https://github.com/LinkedEarth/notebooks/blob/master/PAGES2k/01.lipd2df.ipynb) and [create a map of the PAGES2k network](https:///github.com/LinkedEarth/notebooks/blob/master/PAGES2k/02.plot_map.ipynb).\n",
    "\n",
    "The following data is used in this tutorial:\n",
    "\n",
    "\n",
    "*   PAGES2k Consortium. A global multiproxy database for temperature reconstructions of the Common Era. Sci Data 4, 170088 (2017). https://doi.org/10.1038/sdata.2017.88\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "# **Tutorial 1 Objectives**\n",
    "\n",
    "In this tutorial, you'll learn about different types of paleoclimate proxies (physical characteristics of the environment that can stand in for direct measurements) and how they can be used to reconstruct past variations in Earth's climate on various spatial and temporal timescales. In the process of exploring examples of proxy types and datasets, you'll also learn some fundamental skills for working with [Pyleoclim](https://pyleoclim-util.readthedocs.io/en/master/), a Python package designed for the analysis of paleoclimate data.\n",
    "\n",
    "\n",
    "By the end of this tutorial you will be able to:\n",
    "\n",
    "*   Understand some types of paleoclimate proxies and archives that exist\n",
    "*   Create a global map of locations of proxy paleoclimate records in a specific data network \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {},
    "executionInfo": {
     "elapsed": 23940,
     "status": "ok",
     "timestamp": 1680669683427,
     "user": {
      "displayName": "Brodie Pearson",
      "userId": "05269028596972519847"
     },
     "user_tz": 420
    },
    "tags": [
     "colab"
    ]
   },
   "outputs": [],
   "source": [
    "# # Install libraries\n",
    "# !pip install Pandas\n",
    "# !pip install pooch\n",
    "# !pip install matplotlib as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {},
    "executionInfo": {
     "elapsed": 96816,
     "status": "ok",
     "timestamp": 1680669801626,
     "user": {
      "displayName": "Brodie Pearson",
      "userId": "05269028596972519847"
     },
     "user_tz": 420
    },
    "tags": [
     "colab"
    ]
   },
   "outputs": [],
   "source": [
    "# !pip install --no-binary shapely shapely --force # Add this to use cartopy. in this way it doesn't crush\n",
    "# !pip install cartopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {},
    "executionInfo": {
     "elapsed": 20360,
     "status": "ok",
     "timestamp": 1680669824346,
     "user": {
      "displayName": "Brodie Pearson",
      "userId": "05269028596972519847"
     },
     "user_tz": 420
    },
    "tags": [
     "colab"
    ]
   },
   "outputs": [],
   "source": [
    "# !pip install LiPD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pooch # to donwload the  PAGES2K data\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import lipd\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "import cartopy.io.shapereader as shapereader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "## Common helper functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Convert the PAGES2K LiDP files into a pandas.DataFrame\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Convert the PAGES2K LiDP files into a pandas.DataFrame\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  Convert the PAGES2K LiDP files into a pandas.DataFrame\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "######  Convert the PAGES2K LiDP files into a pandas.DataFrame\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#######  Convert the PAGES2K LiDP files into a pandas.DataFrame\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "########  Convert the PAGES2K LiDP files into a pandas.DataFrame\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#########  Convert the PAGES2K LiDP files into a pandas.DataFrame\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##########  Convert the PAGES2K LiDP files into a pandas.DataFrame\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###########  Convert the PAGES2K LiDP files into a pandas.DataFrame\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "############  Convert the PAGES2K LiDP files into a pandas.DataFrame\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#############  Convert the PAGES2K LiDP files into a pandas.DataFrame\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##############  Convert the PAGES2K LiDP files into a pandas.DataFrame\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###############  Convert the PAGES2K LiDP files into a pandas.DataFrame\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "################  Convert the PAGES2K LiDP files into a pandas.DataFrame\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#################  Convert the PAGES2K LiDP files into a pandas.DataFrame\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##################  Convert the PAGES2K LiDP files into a pandas.DataFrame\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###################  Convert the PAGES2K LiDP files into a pandas.DataFrame\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####################  Convert the PAGES2K LiDP files into a pandas.DataFrame\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####################  Convert the PAGES2K LiDP files into a pandas.DataFrame\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "######################  Convert the PAGES2K LiDP files into a pandas.DataFrame\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#######################  Convert the PAGES2K LiDP files into a pandas.DataFrame\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "########################  Convert the PAGES2K LiDP files into a pandas.DataFrame\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#########################  Convert the PAGES2K LiDP files into a pandas.DataFrame\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##########################  Convert the PAGES2K LiDP files into a pandas.DataFrame\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###########################  Convert the PAGES2K LiDP files into a pandas.DataFrame\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "############################  Convert the PAGES2K LiDP files into a pandas.DataFrame\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#############################  Convert the PAGES2K LiDP files into a pandas.DataFrame\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##############################  Convert the PAGES2K LiDP files into a pandas.DataFrame\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###############################  Convert the PAGES2K LiDP files into a pandas.DataFrame\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "################################  Convert the PAGES2K LiDP files into a pandas.DataFrame\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#################################  Convert the PAGES2K LiDP files into a pandas.DataFrame\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##################################  Convert the PAGES2K LiDP files into a pandas.DataFrame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {},
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# @title Convert the PAGES2K LiDP files into a pandas.DataFrame\n",
    "\n",
    "# Function to convert the PAGES2K LiDP files in a pandas.DataFrame\n",
    "def lipd2df(lipd_dirpath, pkl_filepath=None, col_str=[\n",
    "            'paleoData_pages2kID',\n",
    "            'dataSetName', 'archiveType',\n",
    "            'geo_meanElev', 'geo_meanLat', 'geo_meanLon',\n",
    "            'year', 'yearUnits',\n",
    "            'paleoData_variableName',\n",
    "            'paleoData_units',\n",
    "            'paleoData_values',\n",
    "            'paleoData_proxy']):\n",
    "    \"\"\"\n",
    "    Convert a bunch of PAGES2k LiPD files to a `pandas.DataFrame` to boost data loading.\n",
    "\n",
    "    If `pkl_filepath` isn't `None`, save the DataFrame as a pikle file.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "        lipd_dirpath: str\n",
    "          Path of the PAGES2k LiPD files\n",
    "        pkl_filepath: str or None\n",
    "          Path of the converted pickle file. Default: `None`\n",
    "        col_str: list of str\n",
    "          Name of the variables to extract from the LiPD files\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "        df: `pandas.DataFrame`\n",
    "          Converted Pandas DataFrame\n",
    "    \"\"\"\n",
    "\n",
    "    # Save the current working directory for later use, as the LiPD utility will change it in the background\n",
    "    work_dir = os.getcwd()\n",
    "    # LiPD utility requries the absolute path\n",
    "    lipd_dirpath = os.path.abspath(lipd_dirpath)\n",
    "    # Load LiPD files\n",
    "    lipds = lipd.readLipd(lipd_dirpath)\n",
    "    # Extract timeseries from the list of LiDP objects\n",
    "    ts_list = lipd.extractTs(lipds)\n",
    "    # Recover the working directory\n",
    "    os.chdir(work_dir)\n",
    "    # Create an empty pandas.DataFrame with the number of rows to be the number of the timeseries (PAGES2k records),\n",
    "    # and the columns to be the variables we'd like to extract\n",
    "    df_tmp = pd.DataFrame(index=range(len(ts_list)), columns=col_str)\n",
    "    # Loop over the timeseries and pick those for global temperature analysis\n",
    "    i = 0\n",
    "    for ts in ts_list:\n",
    "        if 'paleoData_useInGlobalTemperatureAnalysis' in ts.keys() and \\\n",
    "            ts['paleoData_useInGlobalTemperatureAnalysis'] == 'TRUE':\n",
    "            for name in col_str:\n",
    "                try:\n",
    "                    df_tmp.loc[i, name] = ts[name]\n",
    "                except:\n",
    "                    df_tmp.loc[i, name] = np.nan\n",
    "            i += 1\n",
    "    # Drop the rows with all NaNs (those not for global temperature analysis)\n",
    "    df = df_tmp.dropna(how='all')\n",
    "    # Save the dataframe to a pickle file for later use\n",
    "    if pkl_filepath:\n",
    "        save_path = os.path.abspath(pkl_filepath)\n",
    "        print(f'Saving pickle file at: {save_path}')\n",
    "        df.to_pickle(save_path)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "## Convert PAGES2k LiPD files to a Pandas dataframe\n",
    "\n",
    "As we've now seen from introductory video, there are various types of paleoclimate archives (e.g., sediment cores, corals, speleothems, tree rings, etc.) and proxies (e.g., isotopes, pollen, organic biomarkers, etc.). There are many existing paleoclimate reconstructions spanning a variety of timescales and from global locations. Given the temporal and spatial vastness of existing paleoclimate records, it can be challenging to know what paleoclimate data already exists and where to find it. A useful solution is compiling all existing paleoclimate records for a single climate variable (e.g., temperature, greenhouse gas concentration, precipitation, etc.) and over a specific time period (e.g., Holocene to present). \n",
    "\n",
    "One example of this is the **PAGES2k network**, which is a community-sourced database of temperature-sensitive proxy records. The database consists of 692 records from 648 locations, that are from a variety of archives (e.g., trees, ice, sediment, corals, speleothems, etc.) and span the Common Era (1 CE to present, i.e., the past ~2,000 years). You can read more about the PAGES2k network, in [PAGES 2k Consortium (2017)](https://www.nature.com/articles/sdata201788).\n",
    "\n",
    "In this tutorial, we will explore the types of proxy records in the PAGES2k network and create a map of proxy record locations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "The PAGES2k network is stored in a specific file format known as Linked Paleo Data format (LiPD). LiPD files contain time series information in addition to supporting metadata (e.g., root metadata, location). Pyleoclim leverages this additional information using LiPD-specific functionality.\n",
    "\n",
    "Data stored in the .lpd format can be loaded directly into Pyleoclim as a Lipd object. If the data_path points to one LiPD file, pyleo.Lipd will load the specific record, while if data_path points to a folder of lipd files, pyleo.Lipd will load the full set of records.\n",
    "\n",
    "The first thing we need to do it to download the data and transform it into a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# Set the name to save the PAGES2K data\n",
    "fname = \"pages2k_data\"\n",
    "\n",
    "if not os.path.exists(fname):\n",
    "\n",
    "    # Download the data\n",
    "    lipd_file_paht = pooch.retrieve(\n",
    "        url=\"https://ndownloader.figshare.com/files/8119937\",\n",
    "        known_hash=None,\n",
    "        path=\"./\",\n",
    "        fname=fname,\n",
    "        processor=pooch.Unzip()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {},
    "executionInfo": {
     "elapsed": 139313,
     "status": "ok",
     "timestamp": 1680670246822,
     "user": {
      "displayName": "Brodie Pearson",
      "userId": "05269028596972519847"
     },
     "user_tz": 420
    }
   },
   "outputs": [],
   "source": [
    "# Convert all the lipd file in a DataFrame\n",
    "fname = \"pages2k_data\"\n",
    "\n",
    "pages2k_data = lipd2df(lipd_dirpath=os.path.join(\".\", f\"{fname}.unzip\", \"LiPD_Files\"), pkl_filepath=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "The PAGES2k data is now stored as a dataframe and we can view the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {},
    "executionInfo": {
     "elapsed": 628,
     "status": "ok",
     "timestamp": 1680670283233,
     "user": {
      "displayName": "Brodie Pearson",
      "userId": "05269028596972519847"
     },
     "user_tz": 420
    }
   },
   "outputs": [],
   "source": [
    "# Print the PAGES2K data\n",
    "pages2k_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "##Plotting a map of proxy reconstruction locations\n",
    "\n",
    "Now that we have converted the data into a Pandas dataframe, we can create a map. We are going to plot the PAGES2k network on a map to understand the spatial distribution of the temperature records and the types of proxies that were measured."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "Before genereting the plot, we have to define the colours and the marker types that we want to use in the plot. We also need to set a list with the different `archive_type` names that appear in the data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# Set a list of markers and colors for the different archive_type\n",
    "markers = ['p', 'p', 'o', 'v', 'd', '*', 's', 's', '8', 'D', '^']\n",
    "colors = [\n",
    "    np.array([ 1., 0.83984375, 0.]),\n",
    "    np.array([ 0.73828125, 0.71484375, 0.41796875]),\n",
    "    np.array([ 1., 0.546875, 0.]),\n",
    "    np.array([ 0.41015625, 0.41015625, 0.41015625]),\n",
    "    np.array([ 0.52734375, 0.8046875 , 0.97916667]),\n",
    "    np.array([ 0., 0.74609375, 1.]),\n",
    "    np.array([ 0.25390625, 0.41015625, 0.87890625]),\n",
    "    np.array([ 0.54296875, 0.26953125, 0.07421875]),\n",
    "    np.array([ 1, 0, 0]),\n",
    "    np.array([ 1., 0.078125  , 0.57421875]),\n",
    "    np.array([ 0.1953125, 0.80078125, 0.1953125])\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "We are now going to create a plot that will allow us to see the PAGES2k network on a map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {},
    "executionInfo": {
     "elapsed": 5407,
     "status": "ok",
     "timestamp": 1680670611982,
     "user": {
      "displayName": "Brodie Pearson",
      "userId": "05269028596972519847"
     },
     "user_tz": 420
    }
   },
   "outputs": [],
   "source": [
    "# Create the plot\n",
    "\n",
    "fig = plt.figure(figsize=(10, 5))\n",
    "ax = fig.add_subplot(1, 1, 1, projection=ccrs.Robinson())\n",
    "\n",
    "# Add plot title\n",
    "plt.title(f'PAGES2k Network (n={len(pages2k_data)})', fontsize=20, fontweight='bold')\n",
    "\n",
    "# Set the base map\n",
    "# ----------------\n",
    "ax.set_global()\n",
    "# Add coast lines\n",
    "ax.coastlines()\n",
    "# Add land fratures using gray color\n",
    "ax.add_feature(cfeature.LAND, facecolor='gray', alpha=0.3)\n",
    "ax.gridlines(edgecolor='gray', linestyle=':')\n",
    "\n",
    "\n",
    "# Plot the different archive types\n",
    "# -------------------------------\n",
    "# Extract the name of the different archive types\n",
    "archive_types = pages2k_data.archiveType.unique()\n",
    "# Plot the archive_type using a forloop\n",
    "for i, type_i in enumerate(archive_types):\n",
    "    df = pages2k_data[pages2k_data['archiveType']==type_i]\n",
    "    # Count the number of appearances of the same archive_type\n",
    "    count = df['archiveType'].count()\n",
    "    # Generate the plot\n",
    "    ax.scatter(\n",
    "        df['geo_meanLon'],\n",
    "        df['geo_meanLat'],\n",
    "        marker=markers[i],\n",
    "        c=colors[i],\n",
    "        edgecolor='k',\n",
    "        s=50,\n",
    "        transform=ccrs.Geodetic(),\n",
    "        label=f'{type_i} (n = {count})',\n",
    "    )\n",
    "# Add legend to the plot\n",
    "ax.legend(\n",
    "    scatterpoints=1,\n",
    "    bbox_to_anchor=(0, -0.4),\n",
    "    loc='lower left',\n",
    "    ncol=3,\n",
    "    fontsize=15,\n",
    ")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "Now you can see the global distribution and temperature proxy type of the 692 records in the PAGES2k network!\n",
    "\n",
    "What do you notice about the map?\n",
    "\n",
    "*   Which temperature proxy is the most and least abundant in this database?\n",
    "*   In what region do you observe the most and least temperature records?\n",
    "\n",
    "\n",
    "We can see the spatial distribution of paleoclimate temperature records spanning the past 2,000 years, but the next step is to extract and analyze the temperature time series of these reconstructions.\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "W1D4_Tutorial1",
   "provenance": [
    {
     "file_id": "1lHuVrVtAW4fQzc0dFdlZuwY0i71KWw_t",
     "timestamp": 1677637469824
    }
   ],
   "toc_visible": true
  },
  "gpuClass": "standard",
  "kernel": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}