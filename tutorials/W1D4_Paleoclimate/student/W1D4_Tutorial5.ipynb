{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "# **Tutorial 5: Paleoclimate Data Analysis Tools**\n",
    "**Week 1, Day 4, Paleoclimate**\n",
    "\n",
    "**Content creators:** Sloane Garelick\n",
    "\n",
    "**Content reviewers:** Brodie Pearson\n",
    "\n",
    "**Content editors:** Yosmely Berm√∫dez, Agustina Pesce, Zahra Khodakaramimaghsoud\n",
    "\n",
    "**Production editors:** TBD\n",
    "\n",
    "**Our 2023 Sponsors:** TBD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "###**Code and Data Sources**\n",
    "\n",
    "Code for this tutorial is based on existing notebooks from LinkedEarth for [anlayzing LiPD datasets](https://github.com/LinkedEarth/paleoHackathon/blob/main/notebooks/PaleoHack-nb03_EDA.ipynb) and [resampling data with `Pyleoclim`](https://github.com/LinkedEarth/PyleoTutorials/blob/main/notebooks/L1_uniform_time_sampling.ipynb).\n",
    "\n",
    "Data from the following sources are used in this tutorial:\n",
    "\n",
    "*   Tierney, J.E., et al. 2008. Northern Hemisphere Controls on Tropical Southeast African Climate During the Past 60,000 Years. Science, Vol. 322, No. 5899, pp. 252-255, 10 October 2008. https://doi:10.1126/science.1160485\n",
    "*   Tierney, J.E., and deMenocal, P.. 2013. Abrupt Shifts in Horn of Africa Hydroclimate Since the Last Glacial Maximum. Science, 342(6160), 843-846. https://doi:10.1126/science.1240411\n",
    "*   Tierney, J.E., Pausata, F., deMenocal, P. 2017. Rainfall Regimes of the Green Sahara. Science Advances, 3(1), e1601503. https://doi:10.1126/sciadv.1601503 \n",
    "*   Shanahan, T.M., et al. 2015. The time-transgressive termination of the African Humid Period. Nature Geoscience, 8(2), 140-144. https://doi:10.1038/ngeo2329\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "#**Tutorial 5 Objectives**\n",
    "\n",
    "In this tutorial, you will explore various computational analyses for interpreting paleoclimate data and understand why these methods are useful. A common issue in the paleosciences is the presence of uneven time spacing between consecutive observations. While `pyleoclim` includes several methods that can deal with this effectively, there are certain applications for which it is ncessary to place the records on a uniform time axis. In this tutorial you'll learn a few ways to do this with `pyleoclim`. Additionally, we will explore another useful paleoclimate data analysis tool, Principal Component Analysis (PCA), which allows us to identify a common signal between various paleoclimate reconstructions. \n",
    "\n",
    "\n",
    "By the end of this tutorial you will be able to perform the following data analysis techniques on proxy-based climate reconstructions:\n",
    "\n",
    "*   Interpolation\n",
    "*   Binning \n",
    "*   Principal component analysis\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {},
    "executionInfo": {
     "elapsed": 56196,
     "status": "ok",
     "timestamp": 1681483997954,
     "user": {
      "displayName": "Sloane Garelick",
      "userId": "04706287370408131987"
     },
     "user_tz": 240
    },
    "tags": [
     "colab"
    ]
   },
   "outputs": [],
   "source": [
    "# # Install libraries\n",
    "# !pip install cartopy\n",
    "# !pip install pyleoclim\n",
    "# !pip install pandas\n",
    "# !pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import cartopy\n",
    "import pyleoclim as pyleo\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "## Load the sample dataset for analysis\n",
    "\n",
    "For this tutorial, we are going to use an example dataset to practice the various data analysis techniques. The dataset we'll be using is a record of hydrogen isotoeps of leaf waxes (dDwax) from Lake Tanganyika in East Africa [(Tierney et al., 2008)](https://www.science.org/doi/10.1126/science.1160485?url_ver=Z39.88-2003&rfr_id=ori:rid:crossref.org&rfr_dat=cr_pub%20%200pubmed). Recall from the introductory video that dDwax is a proxy that records changes in the amount of precipitation in the tropics. In the previous tutorial, we looked at dD data from high-latitude ice cores. In that case, dD was a proxy for temperature, but in the tropics, dD reflects rainfall amount, as explained in the introductory video.\n",
    "\n",
    "Let's first read the data from a .csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "import pooch\n",
    "\n",
    "# fname = 'tanganyika_dD.csv'\n",
    "url = \"https://osf.io/sujvp/download/\"\n",
    "data_path = pooch.retrieve(\n",
    "    url,\n",
    "    known_hash=None\n",
    ")\n",
    "\n",
    "tang_dD = pd.read_csv(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {},
    "executionInfo": {
     "elapsed": 171,
     "status": "ok",
     "timestamp": 1681484069071,
     "user": {
      "displayName": "Sloane Garelick",
      "userId": "04706287370408131987"
     },
     "user_tz": 240
    }
   },
   "outputs": [],
   "source": [
    "tang_dD.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "We can now create a `Series` in Pyleoclim and assign names to different variables so that we can easily plot the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {},
    "executionInfo": {
     "elapsed": 736,
     "status": "ok",
     "timestamp": 1681484071869,
     "user": {
      "displayName": "Sloane Garelick",
      "userId": "04706287370408131987"
     },
     "user_tz": 240
    }
   },
   "outputs": [],
   "source": [
    "ts_tang = pyleo.Series(\n",
    "    time=tang_dD['Age'],\n",
    "    value= tang_dD['dD_IVonly'],\n",
    "    time_name='Age',\n",
    "    time_unit='yr BP',\n",
    "    value_name='dDwax',\n",
    "    value_unit='per mille',\n",
    "    label='Lake Tanganyika dDprecip'\n",
    ")\n",
    "\n",
    "ts_tang.plot(color='C1',invert_yaxis=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "You may notice that the inverted the y-axis. When we're plotting dD data, we typically invert the y-axis because more negative (\"depleted\") values suggest increased rainfall, whereas more positive (\"enriched\") values suggest decreased rainfall."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "## Uniform Time-Sampling of the Data\n",
    "There a number of different reasons we might want to assign new values to our data. For example, if the data is not evenly spaced, we might need to resample it so that it is evenly spaced in order to use some other data analysis technique or to more easily compare to other data. \n",
    "\n",
    "First, let's check whether our data is already evenly spaced using the .is_evenly_spaced() method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {},
    "executionInfo": {
     "elapsed": 138,
     "status": "ok",
     "timestamp": 1681484075182,
     "user": {
      "displayName": "Sloane Garelick",
      "userId": "04706287370408131987"
     },
     "user_tz": 240
    }
   },
   "outputs": [],
   "source": [
    "ts_tang.is_evenly_spaced()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "Our data is not evenly spaced. There are a few different methods available in `pyleoclim` to place the on a uniform axis: interpolating, binning, and coarse graining via a Gaussian kernel as in Rehfeld et al. (2011). In general all of these methods use the available data near a chosen time to estimate what the value was at that time, but each method differs in which nearby data points it uses and how it uses them.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "###Interpolation\n",
    "To start out, let's try using interpolation to evenly space our data. Interpolation projects the data onto an evenly spaced time axis with a distance between points (step size) of our choosing. There are a variety of different methods by which the data can be interpolated, these being: `linear`, `nearest`, `zero`, `slinear`, `quadratic`, `cubic`, `previous`, and `next`. More on these and their associated key word arguments can be found in the [documentation](https://pyleoclim-util.readthedocs.io/en/latest/core/api.html#pyleoclim.core.series.Series.interp). By default, the function `.interp()` implements linear interpolation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "tang_linear = ts_tang.interp() #default method = 'linear'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {},
    "executionInfo": {
     "elapsed": 167,
     "status": "ok",
     "timestamp": 1681484080381,
     "user": {
      "displayName": "Sloane Garelick",
      "userId": "04706287370408131987"
     },
     "user_tz": 240
    }
   },
   "outputs": [],
   "source": [
    "#Checking whether or not the series is now evenly spaced\n",
    "tang_linear.is_evenly_spaced()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "Now that we've interpolated our data, let's compare the original dataset to the linearly interpolated dataset we just created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {},
    "executionInfo": {
     "elapsed": 443,
     "status": "ok",
     "timestamp": 1681484174043,
     "user": {
      "displayName": "Sloane Garelick",
      "userId": "04706287370408131987"
     },
     "user_tz": 240
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = ts_tang.plot(label='Original')\n",
    "tang_linear.plot(ax=ax, label='Linear', invert_yaxis=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "Notice that although there are some minor differences between the original and linearly interpolated data, the records are essential the same.\n",
    "\n",
    "Let's compare a few of the different interpolation methods (e.g., quadratic, next, zero) with one another just to see how they are similar and different:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "tang_quadratic = ts_tang.interp(method='quadratic')\n",
    "tang_next = ts_tang.interp(method='next')\n",
    "tang_zero = ts_tang.interp(method='zero')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {},
    "executionInfo": {
     "elapsed": 584,
     "status": "ok",
     "timestamp": 1681484202723,
     "user": {
      "displayName": "Sloane Garelick",
      "userId": "04706287370408131987"
     },
     "user_tz": 240
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = tang_linear.plot(label='Linear',invert_yaxis=True)\n",
    "tang_quadratic.plot(ax=ax,label='Quadratic')\n",
    "tang_next.plot(ax=ax,label='Next')\n",
    "tang_zero.plot(ax=ax,label='Zero')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "You can see how the methods can produce slightly different results, but reproduce the same overall trend."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "###Binning\n",
    "Another option for resampling our data onto a uniform time axis is binning. Binning is when a set of time intervals is defined and data is grouped or binned with other data in the same interval, then all those points in a \"bin\" are averaged to get a data value for that bin. The defaults for binning pick a bin size at the coarsest time spacing present in the dataset and average data over a uniform sequence of such intervals. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "tang_bin = ts_tang.bin()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {},
    "executionInfo": {
     "elapsed": 457,
     "status": "ok",
     "timestamp": 1681484224785,
     "user": {
      "displayName": "Sloane Garelick",
      "userId": "04706287370408131987"
     },
     "user_tz": 240
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = ts_tang.plot(label='Original',invert_yaxis=True)\n",
    "tang_bin.plot(ax=ax,label='Binned')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "Again, notice that although there are some minor differences between the original and binned data, the records still capture the same overall trend."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "##Principal Component Analysis (PCA)\n",
    "Principal Component Analysis (PCA) is a tool that allows us to identify a common signal between various paleoclimate reconstructions. Doing so involves resampling all of the records onto a common time-step, so we will practice applying the skills we've learned so far in this tutorial.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "So far, we've been looking at dD data from Lake Tanganyika in tropical East Africa. Let's compare this dD record to other existing dD records from lake and marine sediment cores in tropical Africa from the Gulf of Aden [(Tierney and deMenocal, 2017)](https://doi:10.1126/science.1240411), Lake Bosumtwi [(Shanahan et al., 2015)](https://doi:10.1038/ngeo2329), and the West African Margin [(Tierney et al., 2017)](https://doi:10.1126/sciadv.1601503).\n",
    "\n",
    "First, let's load these datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {},
    "executionInfo": {
     "elapsed": 484,
     "status": "ok",
     "timestamp": 1681484228855,
     "user": {
      "displayName": "Sloane Garelick",
      "userId": "04706287370408131987"
     },
     "user_tz": 240
    }
   },
   "outputs": [],
   "source": [
    "# Gulf of Aden\n",
    "# fname = 'aden_dD.csv'\n",
    "url = \"https://osf.io/gm2v9/download/\"\n",
    "\n",
    "data_path = pooch.retrieve(\n",
    "    url,\n",
    "    known_hash=None\n",
    ")\n",
    "\n",
    "aden_dD = pd.read_csv(data_path)\n",
    "aden_dD.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {},
    "executionInfo": {
     "elapsed": 370,
     "status": "ok",
     "timestamp": 1681484235076,
     "user": {
      "displayName": "Sloane Garelick",
      "userId": "04706287370408131987"
     },
     "user_tz": 240
    }
   },
   "outputs": [],
   "source": [
    "#Lake Bosumtwi\n",
    "# fname = \"bosumtwi_dD.csv\"\n",
    "url = \"https://osf.io/mr7d9/download/\"\n",
    "\n",
    "data_path = pooch.retrieve(\n",
    "    url,\n",
    "    known_hash=None\n",
    ")\n",
    "\n",
    "bosumtwi_dD = pd.read_csv(data_path)\n",
    "\n",
    "bosumtwi_dD.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {},
    "executionInfo": {
     "elapsed": 354,
     "status": "ok",
     "timestamp": 1681484237400,
     "user": {
      "displayName": "Sloane Garelick",
      "userId": "04706287370408131987"
     },
     "user_tz": 240
    }
   },
   "outputs": [],
   "source": [
    "# GC27 (West African Margin)\n",
    "# fname = \"gc27_dD.csv\"\n",
    "url = \"https://osf.io/k6e3a/download/\"\n",
    "\n",
    "data_path = pooch.retrieve(\n",
    "    url,\n",
    "    known_hash=None\n",
    ")\n",
    "\n",
    "gc27_dD = pd.read_csv(data_path)\n",
    "gc27_dD.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "Next, let's convert each dataset into a `Series` in Pyleoclim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "ts_tanganyika = pyleo.Series(\n",
    "    time=tang_dD['Age'],\n",
    "    value= tang_dD['dD_IVonly'],\n",
    "    time_name='Age',\n",
    "    time_unit='yr BP',\n",
    "    value_name='dDwax',\n",
    "    label='Lake Tanganyika'\n",
    ")\n",
    "ts_aden = pyleo.Series(\n",
    "    time=aden_dD['age_calBP'],\n",
    "    value= aden_dD['dDwaxIVcorr'],\n",
    "    time_name='Age',\n",
    "    time_unit='yr BP',\n",
    "    value_name='dDwax',\n",
    "    label='Gulf of Aden'\n",
    ")\n",
    "ts_bosumtwi = pyleo.Series(\n",
    "    time=bosumtwi_dD['age_calBP'],\n",
    "    value=bosumtwi_dD['d2HleafwaxC31ivc'],\n",
    "    time_name='Age',\n",
    "    time_unit='yr BP',\n",
    "    value_name = 'dDwax',\n",
    "    label='Lake Bosumtwi'\n",
    ")\n",
    "ts_gc27 = pyleo.Series(\n",
    "    time=gc27_dD['age_BP'],\n",
    "    value=gc27_dD['dDwax_iv'],\n",
    "    time_name='Age',\n",
    "    time_unit='yr BP',\n",
    "    value_name='dDwax',\n",
    "    label='GC27'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "Now let's set up a `MultipleSeries` using Pyleoclim with all four dD datasets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "ts_list = [ts_tanganyika, ts_aden, ts_bosumtwi, ts_gc27]\n",
    "ms_africa = pyleo.MultipleSeries(ts_list, name='African dDwax')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "We can now create a stackplot with all four dD records:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {},
    "executionInfo": {
     "elapsed": 756,
     "status": "ok",
     "timestamp": 1681484266500,
     "user": {
      "displayName": "Sloane Garelick",
      "userId": "04706287370408131987"
     },
     "user_tz": 240
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = ms_africa.stackplot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "By creating a stackplot, we can easily compare between the datasets. However, the four dD records aren't the same resolution and don't span the same time interval.\n",
    "\n",
    "To better compare the records and assess a common trend, we can use PCA. First, we can use `.common_time()` to place the records on a shared time axis with a common sampling frequency. Let's set the time step 500 years and standarize the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {},
    "executionInfo": {
     "elapsed": 1048,
     "status": "ok",
     "timestamp": 1681484350993,
     "user": {
      "displayName": "Sloane Garelick",
      "userId": "04706287370408131987"
     },
     "user_tz": 240
    }
   },
   "outputs": [],
   "source": [
    "africa_ct = ms_africa.common_time(step=0.5).standardize()\n",
    "fig, ax = africa_ct.stackplot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "We now have standardized dD records that are the same sampling resolution and span the same time interval. Now let's apply PCA:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "PCA = africa_ct.pca()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "The result is an object containing multiple outputs, and with two plotting methods attached to it. For example, we can print the percentage of variance accounted for by each mode, which is saved as pctvar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {},
    "executionInfo": {
     "elapsed": 224,
     "status": "ok",
     "timestamp": 1681484449770,
     "user": {
      "displayName": "Sloane Garelick",
      "userId": "04706287370408131987"
     },
     "user_tz": 240
    }
   },
   "outputs": [],
   "source": [
    "print(PCA.pctvar.round())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "This means that 97% of the variance in the four paleoclimate records is explained by the first principal component. The number of datasets in the PCA constrains the number of principal components that can be defined, which is why we only have four components in this example.\n",
    "\n",
    "Now let's create a new series for the first mode of variance and plot it against the original datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "pc1 = PCA.pcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "mode1 = pyleo.Series(\n",
    "    time=africa_ct.series_list[0].time,\n",
    "    value=PCA.pcs[:,0],\n",
    "    label=r'$PC_1$',\n",
    "    value_name='PC1',\n",
    "    time_name ='age',\n",
    "    time_unit = 'yr BP'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {},
    "executionInfo": {
     "elapsed": 1026,
     "status": "ok",
     "timestamp": 1681484506972,
     "user": {
      "displayName": "Sloane Garelick",
      "userId": "04706287370408131987"
     },
     "user_tz": 240
    }
   },
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots()\n",
    "\n",
    "ax1.set_ylabel('dDwax')\n",
    "ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n",
    "ax2.set_ylabel('PC1')  # we already handled the x-label with ax1\n",
    "\n",
    "#plt.plot(mode1.time,pc1_scaled)\n",
    "mode1.plot(color='black', ax=ax2, invert_yaxis=True)\n",
    "africa_ct.plot(ax=ax1, linewidth=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "The original dD records are shown in the colored lines, and the PC1 time series is shown in black. \n",
    " \n",
    "\n",
    "*   How do the original time series compare to the PC1 time series? Do they record similar trends?\n",
    "*   Which original dD record most closely resembles the PC1 time series?\n",
    "*   What changes in climate does the PC1 time series record over the past 20,000 years? *Hint: remember that more depleted dD suggests increased rainfall.*\n",
    "\n",
    "\n",
    "\n",
    " "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "machine_shape": "hm",
   "name": "W1D4_Tutorial5",
   "provenance": [
    {
     "file_id": "1l594NT5i1ubNU9d5esRFZvwj87ivhusI",
     "timestamp": 1680610931501
    },
    {
     "file_id": "1lHuVrVtAW4fQzc0dFdlZuwY0i71KWw_t",
     "timestamp": 1677637469824
    }
   ],
   "toc_visible": true
  },
  "gpuClass": "standard",
  "kernel": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}