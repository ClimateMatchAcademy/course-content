{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "# **Tutorial 3: Reconstructing Past Changes in Terrestrial Climate**\n",
    "**Week 1, Day 4, Paleoclimate**\n",
    "\n",
    "**Content creators:** Sloane Garelick\n",
    "\n",
    "**Content reviewers:** Brodie Pearson\n",
    "\n",
    "**Content editors:** Dionessa Biton\n",
    "\n",
    "**Production editors:** TBD\n",
    "\n",
    "**Our 2023 Sponsors:** TBD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "###**Code and Data Sources**\n",
    "\n",
    "Code for this tutorial is based on an existing notebook from LinkedEarth that provides instruction on [working with LiPD files](https://github.com/LinkedEarth/PyleoTutorials/blob/main/notebooks/L1_working_with_LiPD.ipynb). \n",
    "\n",
    "Data from the following sources are used in this tutorial:\n",
    "\n",
    "*   Euro2k database: PAGES2k Consortium., Emile-Geay, J., McKay, N. et al. A global multiproxy database for temperature reconstructions of the Common Era. Sci Data 4, 170088 (2017). https://doi.org/10.1038/sdata.2017.88\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "#**Tutorial 3 Objectives**\n",
    "\n",
    "In this tutorial, weâ€™ll explore the Euro2K proxy network, which is a subset of PAGES2K, the database we explored in the first tutorial. We will specifically focus on intepretting temperature change over the past 2,000 years as recorded by proxy records from tree rings, speleothems, and lake sediments. To analyze these datasets, we will group them by archive and create time series plots to assess temperature variations.\n",
    "\n",
    "During this tutorial you will:\n",
    "\n",
    "\n",
    "*   Plot temperature records based on three different terrestrial proxies\n",
    "*   Assess similarities and differences between the temperature records\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {},
    "executionInfo": {
     "elapsed": 29229,
     "status": "ok",
     "timestamp": 1680674509443,
     "user": {
      "displayName": "Brodie Pearson",
      "userId": "05269028596972519847"
     },
     "user_tz": 420
    },
    "tags": [
     "colab"
    ]
   },
   "outputs": [],
   "source": [
    "# # Install libraries\n",
    "# !pip install pandas\n",
    "# !pip install numpy\n",
    "# !pip install LiPD\n",
    "\n",
    "# !pip install cartopy\n",
    "# !pip install pyleoclim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pyleoclim as pyleo\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lipd\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "## Loading terrestrial paleoclimate records\n",
    "\n",
    "First, we need to download the data. Similar to Tutorial 1, the data is stored as a LiPD file, and we will be using Pyleoclim to format and interpret the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "import os, requests, tarfile\n",
    "folder_name = \"Euro2k\"\n",
    "if not os.path.exists(folder_name):\n",
    "    url = \"https://osf.io/7ezp3/download/\"\n",
    "    try:\n",
    "        r = requests.get(url)\n",
    "    except requests.ConnectionError:\n",
    "        print(\"!!! Failed to download data !!!\")\n",
    "    else:\n",
    "        if r.status_code != requests.codes.ok:\n",
    "            print(\"!!! Failed to download data !!!\")\n",
    "        else:\n",
    "            print(f\"Downloading {folder_name}...\")\n",
    "            with open(folder_name + \".zip\", \"wb\") as fid:\n",
    "                fid.write(r.content)\n",
    "            import zipfile\n",
    "            with zipfile.ZipFile(folder_name + \".zip\", 'r') as zip_ref:\n",
    "                zip_ref.extractall(\".\")\n",
    "            os.remove(folder_name + \".zip\")\n",
    "            print(f\"Download {folder_name} completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {},
    "executionInfo": {
     "elapsed": 29786,
     "status": "ok",
     "timestamp": 1680674667709,
     "user": {
      "displayName": "Brodie Pearson",
      "userId": "05269028596972519847"
     },
     "user_tz": 420
    }
   },
   "outputs": [],
   "source": [
    "# The LiPD object can be used to load datasets stored in the LiPD format.\n",
    "# In this first case study, we will load an entire library of LiPD files:\n",
    "d_euro = pyleo.Lipd('Euro2k')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "In this next cell of code, we will use `Lipd.to_tso` to obtain a list of dictionaries that can be iterated upon. Dictionaries are native to Python and can be easily explored as shown below. The first line of the code creates the list of dictionaries while the for loop goes over each dictionary to lift relevant information that would allow us to identify the relevant dictionary for our work and print it out per index:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {},
    "executionInfo": {
     "elapsed": 151,
     "status": "ok",
     "timestamp": 1680674784621,
     "user": {
      "displayName": "Brodie Pearson",
      "userId": "05269028596972519847"
     },
     "user_tz": 420
    }
   },
   "outputs": [],
   "source": [
    "ts_list = d_euro.to_tso()\n",
    "for idx, item in enumerate(ts_list):\n",
    "    print(str(idx)+': '+item['dataSetName']+': '+item['paleoData_variableName'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "Once we have our data downloaded and organized, we need to store the data as a `LipdSeriesList`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {},
    "executionInfo": {
     "elapsed": 401,
     "status": "ok",
     "timestamp": 1680674791430,
     "user": {
      "displayName": "Brodie Pearson",
      "userId": "05269028596972519847"
     },
     "user_tz": 420
    }
   },
   "outputs": [],
   "source": [
    "ts_SeriesList = d_euro.to_LipdSeriesList()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "series = pyleo.MultipleSeries(ts_SeriesList)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "Next, we can filter all of the data so that we only keep reconstructions from terrestrial archives (tree rings, speleothems and lake sediments)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "def filter_data(dataset, archive_type, variable_name):\n",
    "    \"\"\"\n",
    "    Return a MultipleSeries object with the variable record (variable_name) for a given archive_type.\n",
    "    \"\"\"\n",
    "    # Create a list of dictionary that can be iterated upon using Lipd.to_tso method\n",
    "    ts_list = dataset.to_tso()\n",
    "    # Append the correct indices for a given value of archive_type and variable_name\n",
    "    indices = []\n",
    "    for idx, item in enumerate(ts_list):\n",
    "        # Check that it is available to avoid errors on the loop\n",
    "        if 'archiveType' in item.keys():\n",
    "            # If it's a archive_type, then proceed to the next step\n",
    "            if item['archiveType'] == archive_type:\n",
    "                if item['paleoData_variableName'] == variable_name:\n",
    "                    indices.append(idx)\n",
    "    print(indices)\n",
    "    # Create a list of LipdSeries for the given indices\n",
    "    ts_list_archive_type = []\n",
    "    for indice in indices:\n",
    "        ts_list_archive_type.append(pyleo.LipdSeries(ts_list[indice]))\n",
    "\n",
    "    return pyleo.MultipleSeries(ts_list_archive_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "Let's create a new list that only has temperature reconstructions based on proxies from **lake sediments**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {},
    "executionInfo": {
     "elapsed": 163,
     "status": "ok",
     "timestamp": 1680674812384,
     "user": {
      "displayName": "Brodie Pearson",
      "userId": "05269028596972519847"
     },
     "user_tz": 420
    }
   },
   "outputs": [],
   "source": [
    "ms_euro_lake = filter_data(d_euro, 'lake sediment', 'temperature')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "Let's create a new list that only has temperature reconstructions based on proxies from **tree rings**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {},
    "executionInfo": {
     "elapsed": 187,
     "status": "ok",
     "timestamp": 1680674816989,
     "user": {
      "displayName": "Brodie Pearson",
      "userId": "05269028596972519847"
     },
     "user_tz": 420
    }
   },
   "outputs": [],
   "source": [
    "ms_euro_tree = filter_data(d_euro, 'tree', 'temperature')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "Let's create a new list that only has temperature reconstructions based on proxies from **speleothems**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {},
    "executionInfo": {
     "elapsed": 200,
     "status": "ok",
     "timestamp": 1680674825774,
     "user": {
      "displayName": "Brodie Pearson",
      "userId": "05269028596972519847"
     },
     "user_tz": 420
    }
   },
   "outputs": [],
   "source": [
    "ms_euro_spel = filter_data(d_euro, 'speleothem', 'd18O')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "Since we are going to compare temperature datasets based on different terrestrial climate archives (lake sediments, tree rings and speleothems), it's helpful to standardize the data since there are multiple proxy types in this subset of data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "#Standardize the data\n",
    "spel_stnd = ms_euro_spel.standardize()\n",
    "lake_stnd = ms_euro_lake.standardize()\n",
    "tree_stnd = ms_euro_tree.standardize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "Now we can use Pyleoclim functions to create three stacked plots of this data with lake sediment records on top, tree ring reconstructions in the middle and speleothem records on the bottom:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {},
    "executionInfo": {
     "elapsed": 4905,
     "status": "ok",
     "timestamp": 1680674844494,
     "user": {
      "displayName": "Brodie Pearson",
      "userId": "05269028596972519847"
     },
     "user_tz": 420
    }
   },
   "outputs": [],
   "source": [
    "lake_stnd.stackplot(label_x_loc=1.7,xlim=[0,2000],v_shift_factor =1,figsize=[9,5], time_unit=\"year\")\n",
    "tree_stnd.stackplot(label_x_loc=1.7,xlim=[0,2000],v_shift_factor =1,figsize=[9,5], time_unit=\"year\")\n",
    "spel_stnd.stackplot(label_x_loc=1.7,xlim=[0,2000],v_shift_factor =1,figsize=[9,5], time_unit=\"year\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "Let's make some inferences about the temperature data over the past 2,000 years:\n",
    "\n",
    "\n",
    "*   Do all of the reconstructions record the same patterns? \n",
    "*   Do the temperature records based on the same proxy record similar patterns?\n",
    "*   What is the long term temperature trend during this period of time?\n",
    "*   What might be causing the more frequent variations in temperature?\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "W1D4_Tutorial3",
   "provenance": [
    {
     "file_id": "1lHuVrVtAW4fQzc0dFdlZuwY0i71KWw_t",
     "timestamp": 1677637469824
    }
   ],
   "toc_visible": true
  },
  "kernel": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}