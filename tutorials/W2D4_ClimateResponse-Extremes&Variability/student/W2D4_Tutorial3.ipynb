{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/ClimateMatchAcademy/course-content/blob/main/tutorials/W2D4_ClimateResponse-Extremes&Variability/student/W2D4_Tutorial3.ipynb) &nbsp; <a href=\"https://kaggle.com/kernels/welcome?src=https://raw.githubusercontent.com/ClimateMatchAcademy/course-content/main/tutorials/W2D4_ClimateResponse-Extremes&Variability/student/W2D4_Tutorial3.ipynb\" target=\"_parent\"><img src=\"https://kaggle.com/static/images/open-in-kaggle.svg\" alt=\"Open in Kaggle\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "# Tutorial 3: Extreme Value Analysis - the GEV Distribution\n",
    "\n",
    "**Week 2, Day 4, Extremes & Vulnerability**\n",
    "\n",
    "**Content creators:** Matthias Aengenheyster, Joeri Reinders\n",
    "\n",
    "**Content reviewers:** Younkap Nina Duplex, Sloane Garelick, Zahra Khodakaramimaghsoud, Peter Ohue, Laura Paccini, Jenna Pearson, Agustina Pesce, Derick Temfack, Peizhen Yang, Cheng Zhang, Chi Zhang, Ohad Zivan\n",
    "\n",
    "**Content editors:** Jenna Pearson, Chi Zhang, Ohad Zivan\n",
    "\n",
    "**Production editors:** Wesley Banfield, Jenna Pearson, Chi Zhang, Ohad Zivan\n",
    "\n",
    "**Our 2023 Sponsors:** NASA TOPS and Google DeepMind"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "# Tutorial Objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "In the previous tutorial, you used the **empirical method** to determine return values. Another approach involves computing the probability of exceeding a certain threshold using a probability density function fitted to the data. For instance, in Tutorial 1, we used the normal distribution PDF. However, we observed that the normal distribution did not adequately fit our precipitation data. Here we will explore fitting a distribution that is typically more suitable for data with skewed histograms.\n",
    "\n",
    "By the end of this tutorial, you will gain the following skills:\n",
    "\n",
    "- Creating a quantile-quantile (QQ) plot to assess the goodness-of-fit between a distribution and the data.\n",
    "- Fitting a Generalized Extreme Value (GEV) distribution to the data.\n",
    "- Understanding how the parameters of the GEV distribution influence its behavior."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {},
    "executionInfo": {
     "elapsed": 2336,
     "status": "ok",
     "timestamp": 1681923364409,
     "user": {
      "displayName": "Matthias Aengenheyster",
      "userId": "16322208118439170907"
     },
     "user_tz": -60
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from scipy.stats import genextreme as gev\n",
    "import os\n",
    "import pooch\n",
    "import tempfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "# @title Figure Settings\n",
    "import ipywidgets as widgets  # interactive display\n",
    "\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "plt.style.use(\n",
    "    \"https://raw.githubusercontent.com/ClimateMatchAcademy/course-content/main/cma.mplstyle\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Helper functions\n",
    "\n",
    "\n",
    "def pooch_load(filelocation=None, filename=None, processor=None):\n",
    "    shared_location = \"/home/jovyan/shared/Data/tutorials/W2D4_ClimateResponse-Extremes&Variability\"  # this is different for each day\n",
    "    user_temp_cache = tempfile.gettempdir()\n",
    "\n",
    "    if os.path.exists(os.path.join(shared_location, filename)):\n",
    "        file = os.path.join(shared_location, filename)\n",
    "    else:\n",
    "        file = pooch.retrieve(\n",
    "            filelocation,\n",
    "            known_hash=None,\n",
    "            fname=os.path.join(user_temp_cache, filename),\n",
    "            processor=processor,\n",
    "        )\n",
    "\n",
    "    return file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "# @title Video 1: Extreme Value Analysis\n",
    "\n",
    "from ipywidgets import widgets\n",
    "from IPython.display import YouTubeVideo\n",
    "from IPython.display import IFrame\n",
    "from IPython.display import display\n",
    "\n",
    "\n",
    "class PlayVideo(IFrame):\n",
    "  def __init__(self, id, source, page=1, width=400, height=300, **kwargs):\n",
    "    self.id = id\n",
    "    if source == 'Bilibili':\n",
    "      src = f'https://player.bilibili.com/player.html?bvid={id}&page={page}'\n",
    "    elif source == 'Osf':\n",
    "      src = f'https://mfr.ca-1.osf.io/render?url=https://osf.io/download/{id}/?direct%26mode=render'\n",
    "    super(PlayVideo, self).__init__(src, width, height, **kwargs)\n",
    "\n",
    "\n",
    "def display_videos(video_ids, W=400, H=300, fs=1):\n",
    "  tab_contents = []\n",
    "  for i, video_id in enumerate(video_ids):\n",
    "    out = widgets.Output()\n",
    "    with out:\n",
    "      if video_ids[i][0] == 'Youtube':\n",
    "        video = YouTubeVideo(id=video_ids[i][1], width=W,\n",
    "                             height=H, fs=fs, rel=0)\n",
    "        print(f'Video available at https://youtube.com/watch?v={video.id}')\n",
    "      else:\n",
    "        video = PlayVideo(id=video_ids[i][1], source=video_ids[i][0], width=W,\n",
    "                          height=H, fs=fs, autoplay=False)\n",
    "        if video_ids[i][0] == 'Bilibili':\n",
    "          print(f'Video available at https://www.bilibili.com/video/{video.id}')\n",
    "        elif video_ids[i][0] == 'Osf':\n",
    "          print(f'Video available at https://osf.io/{video.id}')\n",
    "      display(video)\n",
    "    tab_contents.append(out)\n",
    "  return tab_contents\n",
    "\n",
    "\n",
    "video_ids = [('Youtube', 'Vblk--ifjsc'), ('Bilibili', 'BV1WM4y1x7aS')]\n",
    "tab_contents = display_videos(video_ids, W=730, H=410)\n",
    "tabs = widgets.Tab()\n",
    "tabs.children = tab_contents\n",
    "for i in range(len(tab_contents)):\n",
    "  tabs.set_title(i, video_ids[i][0])\n",
    "display(tabs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {},
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "# @markdown\n",
    "from ipywidgets import widgets\n",
    "from IPython.display import IFrame\n",
    "\n",
    "link_id = \"3bv76\"\n",
    "\n",
    "download_link = f\"https://osf.io/download/{link_id}/\"\n",
    "render_link = f\"https://mfr.ca-1.osf.io/render?url=https://osf.io/{link_id}/?direct%26mode=render%26action=download%26mode=render\"\n",
    "# @markdown\n",
    "out = widgets.Output()\n",
    "with out:\n",
    "    print(f\"If you want to download the slides: {download_link}\")\n",
    "    display(IFrame(src=f\"{render_link}\", width=730, height=410))\n",
    "display(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "# Section 1: Precipitation Data Histogram and Normal Distribution\n",
    "Let's repeat our first steps from tutorials 1 and 2: \n",
    "1) open the annual maximum daily precipitation record from Germany.\n",
    "2) create a histogram of the data and plot the normal distribution probability density function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {},
    "executionInfo": {
     "elapsed": 331,
     "status": "ok",
     "timestamp": 1681923455336,
     "user": {
      "displayName": "Matthias Aengenheyster",
      "userId": "16322208118439170907"
     },
     "user_tz": -60
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# download file: 'precipitationGermany_1920-2022.csv'\n",
    "filename_precipitationGermany = \"precipitationGermany_1920-2022.csv\"\n",
    "url_precipitationGermany = \"https://osf.io/xs7h6/download\"\n",
    "data = pd.read_csv(\n",
    "    pooch_load(url_precipitationGermany, filename_precipitationGermany), index_col=0\n",
    ").set_index(\"years\")\n",
    "data.columns = [\"precipitation\"]\n",
    "precipitation = data.precipitation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {},
    "executionInfo": {
     "elapsed": 755,
     "status": "ok",
     "timestamp": 1681923459971,
     "user": {
      "displayName": "Matthias Aengenheyster",
      "userId": "16322208118439170907"
     },
     "user_tz": -60
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "x_r100 = np.arange(0, 100, 1)\n",
    "bins = np.arange(0, precipitation.max(), 2)\n",
    "\n",
    "# make histogram\n",
    "sns.histplot(precipitation, bins=bins, stat=\"density\", ax=ax)\n",
    "\n",
    "# plot PDF\n",
    "ax.plot(\n",
    "    x_r100,\n",
    "    stats.norm.pdf(x_r100, precipitation.mean(), precipitation.std()),\n",
    "    c=\"k\",\n",
    "    lw=3,\n",
    ")\n",
    "\n",
    "ax.set_xlim(bins[0], bins[-1])\n",
    "ylim = ax.get_ylim()\n",
    "ax.set_xlabel(\"Annual Maximum Daily Precipitation \\n(mm/day)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "Next, we generate a [quanitile-quantile (QQ) plot](https://en.wikipedia.org/wiki/Q–Q_plot) to assess how well our data aligns with a normal distribution. A QQ plot compares the *actual* [percentiles](https://en.wikipedia.org/wiki/Percentile) of the data to the *expected* percentiles based on a specific distribution, such as a normal distribution in this case. The percentiles are the points in your data below which a certain proportion of your data fall. Here will be using [`norm.ppf()`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.norm.html#scipy-stats-norm) where 'ppf' stands for percent point function, and returns the quantiles of the normal distribution function (i.e. percentiles). On our precipitation data we will be using [`numpy.quantile()`](https://numpy.org/doc/stable/reference/generated/numpy.quantile.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {},
    "executionInfo": {
     "elapsed": 245,
     "status": "ok",
     "timestamp": 1681923461802,
     "user": {
      "displayName": "Matthias Aengenheyster",
      "userId": "16322208118439170907"
     },
     "user_tz": -60
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "x_r1 = np.linspace(0, 1, 100)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "\n",
    "ax.plot(\n",
    "    stats.norm.ppf(\n",
    "        x_r1, precipitation.mean(), precipitation.std()\n",
    "    ),  # quantiles of a normal distribution with the mean and std of our precip data\n",
    "    np.quantile(precipitation, x_r1),  # quantiles of our precip data\n",
    "    \"o\",\n",
    ")\n",
    "ax.plot(x_r100, x_r100, \"k\")\n",
    "\n",
    "ax.set_xlim(10, 72)\n",
    "ax.set_ylim(10, 72)\n",
    "\n",
    "ax.set_xlabel(\"Normal Quantiles\")\n",
    "ax.set_ylabel(\"Sample Quantiles\")\n",
    "\n",
    "ax.grid(True)\n",
    "ax.set_aspect(\"equal\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "If the fit was perfect, the quantile comparison would fall on the 1:1 line plotted in black. The stronger the deviations from the 1:1 line, the worse this particular probability density function fits our data. Hopefully, you concur that the current fit could be improved, particularly when it comes to the extreme values (lower and upper quantiles), which appear to be over- and underestimated by the normal distribution model. Therefore, let's explore alternative options, as there are numerous other distributions available. One example is the [General Extreme Value (GEV) distribution](https://en.wikipedia.org/wiki/Generalized_extreme_value_distribution).\n",
    "\n",
    "The normal distribution is completely defined by two parameters: its mean and standard deviation.\n",
    "In contrast, the GEV distribution is defined by three parameters: the location, scale, and shape parameters. When the mean of the normal distribution is increased, it shifts the distribution towards higher values, while increasing the standard deviation makes the distribution wider. The normal distribution is symmetrical to its mean as it lacks a parameter that influences its skewness: There is always exactly half of the distribution to the right and left of its mean. This can pose challenges in certain scenarios.\n",
    "\n",
    "In the GEV distribution, the location and scale parameters behave similarly to the mean and standard deviation in the normal distribution. The shape parameter impacts the tails of the distribution, making them thinner or thicker. As extreme event distributions often exhibit thick tails, they tend to possess slight skewness. Adjusting the shape parameter, therefore, influences the skewness (and kurtosis) of the data.\n",
    "\n",
    "To estimate the parameters of the GEV distribution, we utilize the [`stats.genextreme()`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.genextreme.html#scipy-stats-genextreme) function from the `scipy` package. Here we call this function `gev`. While the normal distribution only requires the mean and standard deviation as parameters, the GEV distribution requires three parameters (location, scale, and shape). These parameters can be estimated from data using by calling `gev.fit()`. Note the second argument to this function given below is optional, it is the starting guess for the shape parameter. It sometimes makes sense to set this to zero as otherwise the fitting algorithm may be unstable and return incorrect values (hint: always check if your results are sensible!)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {},
    "executionInfo": {
     "elapsed": 170,
     "status": "ok",
     "timestamp": 1681923489030,
     "user": {
      "displayName": "Matthias Aengenheyster",
      "userId": "16322208118439170907"
     },
     "user_tz": -60
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "shape, loc, scale = gev.fit(precipitation.values, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "shape, loc, scale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "Let's generate another histogram of the data and overlay the Generalized Extreme Value (GEV) distribution with the fitted parameters. It's important to note that there are two sign conventions for the shape parameter. You may encounter an application that has it defined the other way around - check the documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "# make histogram\n",
    "sns.histplot(precipitation, bins=bins, stat=\"density\", ax=ax)\n",
    "ax.set_xlim(bins[0], bins[-1])\n",
    "\n",
    "# add GEV PDF\n",
    "x_r80 = np.arange(80)\n",
    "\n",
    "ax.plot(x_r80, gev.pdf(x_r80, shape, loc=loc, scale=scale), \"k\", lw=3)\n",
    "ax.set_xlabel(\"Annual Maximum Daily Precipitation \\n(mm/day)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "And also create a QQ-plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {},
    "executionInfo": {
     "elapsed": 480,
     "status": "ok",
     "timestamp": 1681923514940,
     "user": {
      "displayName": "Matthias Aengenheyster",
      "userId": "16322208118439170907"
     },
     "user_tz": -60
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "x_r1 = np.linspace(0, 1, 100)\n",
    "x_r100 = np.linspace(0, 100, 100)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(\n",
    "    gev.ppf(\n",
    "        x_r1, shape, loc=loc, scale=scale\n",
    "    ),  # quantiles of GEV distribution using the parameter estimates from our data\n",
    "    np.quantile(precipitation, x_r1),\n",
    "    \"o\",\n",
    ")  # actual quantiles of our data\n",
    "\n",
    "ax.plot(x_r100, x_r100, \"k\")\n",
    "\n",
    "ax.set_xlim(10, 72)\n",
    "ax.set_ylim(10, 72)\n",
    "\n",
    "ax.set_xlabel(\"GEV Quantiles\")\n",
    "ax.set_ylabel(\"Sample Quantiles\")\n",
    "\n",
    "ax.grid(True)\n",
    "ax.set_aspect(\"equal\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "This looks much better! As we exepected, the GEV distribution is a better fit for the data than the Normal distribution given the skewness of the data we observed in tutorial 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "Now, we will overlay both PDFs (normal and GEV) on a single plot to visualize and compare the differences between them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {},
    "executionInfo": {
     "elapsed": 671,
     "status": "ok",
     "timestamp": 1681923521300,
     "user": {
      "displayName": "Matthias Aengenheyster",
      "userId": "16322208118439170907"
     },
     "user_tz": -60
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "sns.histplot(precipitation, bins=bins, stat=\"density\", ax=ax, alpha=0.5, lw=0)\n",
    "\n",
    "# normal distribution\n",
    "ax.plot(\n",
    "    x_r100,\n",
    "    stats.norm.pdf(x_r100, precipitation.mean(), precipitation.std()),\n",
    "    c=\"C3\",\n",
    "    lw=3,\n",
    "    label=\"Normal\",\n",
    ")\n",
    "# GEV distribution\n",
    "ax.plot(x_r100, gev.pdf(x_r100, shape, loc=loc, scale=scale), c=\"k\", lw=3, label=\"GEV\")\n",
    "ax.legend()\n",
    "ax.set_xlabel(\"Annual Maximum Daily Precipitation \\n(mm/day)\")\n",
    "ax.set_ylabel(\"Density\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "How well do the two fitted distributions reflect the observed data and how do they compare to each other? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "## Coding Exercise 1\n",
    "\n",
    "Parameters of the GEV distribution\n",
    "\n",
    "Play a little with the gev.pdf function to get a better sense of how the parameters affect the shape of the pdf (distribution). Plot the distribution against the\n",
    "‘x’ sequence and randomly change the parameters. What does each parameter do? \n",
    "\n",
    "Create three plots. In each, one of the parameters (location, scale, shape) is varied while the other two are held constant. The parameter values and ranges below may be a useful starting point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "# set range of location values to use\n",
    "range_loc = np.arange(20, 41, 4)\n",
    "\n",
    "# set shape parameter\n",
    "shape = 0\n",
    "\n",
    "# set scale parameter\n",
    "scale = 7\n",
    "\n",
    "# set x values\n",
    "x_r80 = np.linspace(0, 80, 1000)\n",
    "\n",
    "# setup plots\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# setup colors to use for lines\n",
    "colors_loc = plt.cm.coolwarm(np.linspace(0, 1, range_loc.size))\n",
    "\n",
    "# generate pdf for each location value\n",
    "for idx, loci in enumerate(range_loc):\n",
    "    ...\n",
    "\n",
    "# aesthetics\n",
    "ax.legend()\n",
    "ax.set_xlabel(\"Annual Maximum Daily Precipitation \\n(mm/day)\")\n",
    "ax.set_ylabel(\"Density\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# set range of scale values to use\n",
    "range_scale = np.arange(4, 11, 1)\n",
    "\n",
    "# set shape parameter\n",
    "shape = 0\n",
    "\n",
    "# set location parameter\n",
    "loc = 26\n",
    "\n",
    "# setup plots\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# setup colors to use for lines\n",
    "colors_scale = plt.cm.coolwarm(np.linspace(0, 1, range_scale.size))\n",
    "\n",
    "# generate pdf for each scale value\n",
    "for idx, scalei in enumerate(range_scale):\n",
    "    ...\n",
    "\n",
    "# aesthetics\n",
    "ax.legend()\n",
    "ax.set_xlabel(\"Annual Maximum Daily Precipitation \\n(mm/day)\")\n",
    "ax.set_ylabel(\"Density\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# set range of shape values to use\n",
    "range_shape = np.arange(-0.4, 0.4 + 0.1, 0.1)\n",
    "\n",
    "# set scale parameter\n",
    "scale = 7\n",
    "\n",
    "# set location parameter\n",
    "loc = 26\n",
    "\n",
    "# setup plots\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# setup colors to use for lines\n",
    "colors_shape = plt.cm.coolwarm(np.linspace(0, 1, range_shape.size))\n",
    "\n",
    "# generate pdf for each shape value\n",
    "for idx, shapei in enumerate(range_shape):\n",
    "    ...\n",
    "\n",
    "# aesthetics\n",
    "ax.legend()\n",
    "ax.set_xlabel(\"Annual Maximum Daily Precipitation \\n(mm/day)\")\n",
    "ax.set_ylabel(\"Density\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "## Questions 1\n",
    "\n",
    "1. How do the three parameters impact the shape of the distribution? What can you think of how these parameters affect extreme events?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "# Summary\n",
    "In this tutorial, you explored the the Generalized Extreme Value (GEV) distribution suitable for climate variables containing higher probabilities of extreme events. You used scipy to estimate these parameters from our data and fit a GEV distribution. You compared the fit of the normal and GEV distributions to your data using Quantile-Quantile (QQ) plots and overlaid the probability density functions of both distributions for visual comparison. Finally, you manipulated the parameters of the GEV distribution to understand their effects on the shape of the distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "# Resources\n",
    "\n",
    "Data from this tutorial uses the 0.25 degree precipitation dataset E-OBS. It combines precipitation observations to generate a gridded (i.e. no \"holes\") precipitation over Europe. We used the precipitation data from the gridpoint at 51 N, 6 E. \n",
    "\n",
    "The dataset can be accessed using the KNMI Climate Explorer [here](https://climexp.knmi.nl/select.cgi?id=someone@somewhere&field=ensembles_025_rr). The Climate Explorer is a great resource to access, manipulate and visualize climate data, including observations and climate model simulations. It is freely accessible - feel free to explore!"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "W2D4_Tutorial3",
   "provenance": [],
   "toc_visible": true
  },
  "kernel": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
