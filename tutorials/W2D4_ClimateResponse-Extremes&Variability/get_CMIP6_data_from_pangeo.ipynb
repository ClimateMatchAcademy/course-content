{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2e69bb7f",
   "metadata": {},
   "source": [
    "# Load CMIP6 Data from Pangeo\n",
    "\n",
    "The commented code boxes below recreate the data loaded in the previous line.\n",
    "\n",
    "It has been commented out as this code is NOT NECESSARY for this tutorial to run. Please DO NOT run it straightaway, the code takes quite long time to run and uses significant computing resources. However, the code is provided to give a better idea of how data can be obtained through [Pangeo](https://pangeo.io/) - which is an immensely valuable resource we have introduced previously. \n",
    "\n",
    "In this way you can access large amounts of climate model output that has been stored in the cloud. This is very useful to get easy access to such information. Feel free to modify the code to access different data and address your own questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c25f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import intake \n",
    "from xmip.preprocessing import combined_preprocessing\n",
    "from xarrayutils.plotting import shaded_line_plot\n",
    "\n",
    "from xmip.utils import google_cmip_col\n",
    "# we could do all of this with pure pandas on the underlying csv file\n",
    "col = google_cmip_col()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affcbf7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = col.search(\n",
    "    source_id=['MPI-ESM1-2-HR','MIROC6'],\n",
    "    variable_id=['pr','tas'],\n",
    "    member_id='r1i1p1f1', #\n",
    "    table_id='day',\n",
    "    grid_label='gn',\n",
    "    experiment_id = ['historical','ssp126', 'ssp245', 'ssp585'],\n",
    "    require_all_on = ['experiment_id','variable_id']\n",
    ")\n",
    "kwargs = dict(preprocess=combined_preprocessing, xarray_open_kwargs=dict(use_cftime=True))\n",
    "ds_dict = cat.to_dataset_dict(zarr_kwargs={'consolidated': True})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecce435d",
   "metadata": {},
   "source": [
    "Define one or more locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d7f1be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sel_Hamburg = dict(lon=10,lat=53.5)\n",
    "sel_Madrid = dict(lon=360-42,lat=40.5)\n",
    "sel_Delhi = dict(lon=77,lat=28.5)\n",
    "sel_Kinshasa = dict(lon=15,lat=-4)\n",
    "sel_Phoenix = dict(lon=360-112,lat=33.5)\n",
    "sel_Sydney = dict(lon=151,lat=-33.85)\n",
    "\n",
    "sels = dict(\n",
    "    Hamburg = sel_Hamburg,\n",
    "    Madrid = sel_Madrid,\n",
    "    Delhi = sel_Delhi,\n",
    "    Kinshasa = sel_Kinshasa,\n",
    "    Phoenix = sel_Phoenix,\n",
    "    Sydney = sel_Sydney\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "296d94e7",
   "metadata": {},
   "source": [
    "Assemble your data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5236ff74",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "model_dict = {}\n",
    "for k in ds_dict.keys():\n",
    "    string = k.split('.')\n",
    "    model = string[2]\n",
    "    models.append(model)\n",
    "    scenario = string[3]\n",
    "    print(string, model, scenario)\n",
    "    model_dict['%s.%s' % (model,scenario)] = k\n",
    "\n",
    "models = ['MPI-ESM1-2-HR', 'MIROC6']\n",
    "scenarios = ['ssp126','ssp245','ssp585']\n",
    "outs = []\n",
    "for model in models:\n",
    "    outsm = []\n",
    "    for city in sels.keys():\n",
    "        outis = []\n",
    "        for scenario in scenarios:\n",
    "            timeseries = xr.concat(\n",
    "                        [\n",
    "                            ds_dict[model_dict['%s.%s' % (model, 'historical')]].sel(sels[city],method='nearest').sel(time=slice('2014')),\n",
    "                            ds_dict[model_dict['%s.%s' % (model, scenario)]].sel(time=slice('2100')).sel(sels[city],method='nearest')\n",
    "                            # ds_dict['%s.%s' % (model, 'historical')].sel(sels[city],method='nearest').sel(time=slice('2014')),\n",
    "                            # ds_dict['%s.%s' % (model, scenario)].sel(sels[city],method='nearest')\n",
    "                        ],'time'\n",
    "                        )\n",
    "            timeseries = timeseries.assign_coords(city=city,scenario=scenario,model=model).squeeze()\n",
    "            outis.append(timeseries)\n",
    "            # outis.append(ds_dict[key].sel(sels[city],method='nearest').assign_coords(city=city,scenario=key).squeeze())\n",
    "        outsm.append(xr.concat(outis,'scenario'))\n",
    "    outs.append(xr.concat(outsm,'city'))\n",
    "data = xr.concat(outs,'model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea5d532f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The data has %.3f MB' % data.nbytes / 1e6)\n",
    "print('The next line triggers the computation!')\n",
    "#with ProgressBar():\n",
    "#     data.load()\n",
    "\n",
    "Fix time axis\n",
    "data = out2.assign_coords(time=pd.to_datetime(data.time))\n",
    "# Convert precip data to mm/day\n",
    "data['pr'] = data['pr'] * 86400\n",
    "data['pr'].attrs = data['pr'].attrs\n",
    "data['pr'].attrs['units'] = 'mm/day'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "climatematch",
   "language": "python",
   "name": "climatematch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
