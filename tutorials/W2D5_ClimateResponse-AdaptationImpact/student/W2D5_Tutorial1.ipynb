{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "myt07YFyNgmw",
   "metadata": {
    "execution": {}
   },
   "source": [
    "# **Tutorial 1: Linear Regression**\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "**Week 2, Day 5: Climate Response: adaptation and impact**\n",
    "\n",
    "**By Climatematch Academy**\n",
    "\n",
    "__Content creators:__ Deepak Mewada, Grace Lindsay\n",
    "\n",
    "__Content reviewers:__ \n",
    "\n",
    "__Content editors:__ Name Surname, Name Surname\n",
    "\n",
    "__Production editors:__ Name Surname, Name Surname"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "kDQc1jnoNWcp",
   "metadata": {
    "execution": {}
   },
   "source": [
    "___\n",
    "# **Tutorial Objectives**\n",
    "\n",
    "*Estimated timing of tutorial: 20 minutes [?]\n",
    "\n",
    "Welcome to tutorial 1 of a series focused on understanding the role of data science and machine learning in addressing the impact of climate change and adapting to it.\n",
    "\n",
    "In this tutorial, we will start with simple linear regression and learn how to model data using this technique. Specifically, by the end of this tutorial, you will be able to:\n",
    "\n",
    "- Understand what linear regression is and how it can be used to model data\n",
    "- Implement linear regression using scikit-learn in Python\n",
    "- Evaluate the performance of a linear regression model \n",
    "- Apply the learned linear regression model to make predictions on new, unseen data\n",
    "\n",
    "This tutorial serves as the foundation for the upcoming tutorials in this series, where we will cover other data modeling techniques and apply them to climate and environmental data. Specifically, in the upcoming tutorials, we will:\n",
    "\n",
    "- Learn about logistic regression using scikit-learn in tutorial 2\n",
    "- Get familiar with the dengue fever dataset in tutorial 3\n",
    "- Apply linear regression to the dengue fever dataset in tutorial 4\n",
    "- Learn about decision trees and apply them to the dengue fever dataset in tutorial 5\n",
    "- Get introduced to a small crop dataset in tutorial 6\n",
    "- Apply logistic regression to the crop dataset in tutorial 7\n",
    "- Learn how artificial neural networks can be applied to crop data in tutorial 8\n",
    "- Identify where more datasets and ideas can be found in tutorial 9\n",
    "\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Tutorial slides\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " These are the slides for the videos in all tutorials today\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Tutorial slides\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " These are the slides for the videos in all tutorials today\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Tutorial slides\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " These are the slides for the videos in all tutorials today\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  Tutorial slides\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " These are the slides for the videos in all tutorials today\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "######  Tutorial slides\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " These are the slides for the videos in all tutorials today\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#######  Tutorial slides\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " These are the slides for the videos in all tutorials today\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wlndBdbV5iJF",
   "metadata": {
    "cellView": "form",
    "execution": {},
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1681525378935,
     "user": {
      "displayName": "Deepak Mewada",
      "userId": "10376201445384716451"
     },
     "user_tz": -330
    },
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "# @title Tutorial slides\n",
    "\n",
    "# @markdown These are the slides for the videos in all tutorials today\n",
    "from IPython.display import IFrame\n",
    "IFrame(src=f\"https://mfr.ca-1.osf.io/render?url=https://osf.io/kaq2x/?direct%26mode=render%26action=download%26mode=render\", width=854, height=480)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Vtq0OyoRNPcc",
   "metadata": {
    "execution": {}
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "# **Setup**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Import necessary libraries:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Import necessary libraries:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Import necessary libraries:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  Import necessary libraries:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "######  Import necessary libraries:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#######  Import necessary libraries:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Kwsl6-KNNPcc",
   "metadata": {
    "cellView": "form",
    "execution": {},
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "#@title Import necessary libraries:\n",
    "\n",
    "import numpy as np  # Import the numpy library as np - used for array computing and linear algebra operations\n",
    "from sklearn.linear_model import LinearRegression  # Import the LinearRegression class from the sklearn.linear_model module - used for performing linear regression analysis\n",
    "import matplotlib.pyplot as plt  # Import the pyplot module from the matplotlib library - used for data visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wNqEz5P8j2Q-",
   "metadata": {
    "execution": {}
   },
   "source": [
    "<details>\n",
    "<summary> <font color='Red'>Click here if you are running on local machine or you encounter any error while importing   </font></summary>\n",
    "**NOTE :**  Please note that if you are running this code on a local machine and encounter an error while importing a library, make sure to install the library via pip. For example, if you receive a \"`ModuleNotFoundError: No module named 'library name'`\" error , please run \"`pip install 'library name'`\" to install the required module."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nULavCfq4o07",
   "metadata": {
    "execution": {}
   },
   "source": [
    "---\n",
    "\n",
    "# **Section 1: Linear Regression**\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "Implementing Linear Regression on synthetic dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Video 1: Video 1 Name\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Video 1: Video 1 Name\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Video 1: Video 1 Name\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  Video 1: Video 1 Name\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "######  Video 1: Video 1 Name\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#######  Video 1: Video 1 Name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ThcPwgvzvV-6",
   "metadata": {
    "cellView": "form",
    "execution": {},
    "executionInfo": {
     "elapsed": 460,
     "status": "ok",
     "timestamp": 1681525380609,
     "user": {
      "displayName": "Deepak Mewada",
      "userId": "10376201445384716451"
     },
     "user_tz": -330
    },
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "# @title Video 1: Video 1 Name\n",
    "from ipywidgets import widgets\n",
    "from IPython.display import display, IFrame, YouTubeVideo\n",
    "\n",
    "out2 = widgets.Output()\n",
    "with out2:\n",
    "  class BiliVideo(IFrame):\n",
    "    def __init__(self, id, page=1, width=400, height=300, **kwargs):\n",
    "      self.id=id\n",
    "      src = 'https://player.bilibili.com/player.html?bvid={0}&page={1}'.format(id, page)\n",
    "      super(BiliVideo, self).__init__(src, width, height, **kwargs)\n",
    "\n",
    "  video = BiliVideo(id=\"\", width=730, height=410, fs=1)\n",
    "  print(f'Video available at https://www.bilibili.com/video/{video.id}')\n",
    "  display(video)\n",
    "\n",
    "out1 = widgets.Output()\n",
    "with out1:\n",
    "  video = YouTubeVideo(id=\"\", width=730, height=410, fs=1, rel=0)\n",
    "  print(f'Video available at https://youtube.com/watch?v={video.id}')\n",
    "  display(video)\n",
    "\n",
    "out = widgets.Tab([out1, out2])\n",
    "out.set_title(0, 'Youtube')\n",
    "out.set_title(1, 'Bilibili')\n",
    "\n",
    "display(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e6687fc",
   "metadata": {
    "execution": {}
   },
   "source": [
    "In a regression problem, we need data features ('regressors', or independent variables) that we will use to predict a dependent variable. For example, we could try to predict an employee's salary (dependent variable) based on features such as the number of years at the company and performance ratings (regressors). \n",
    "\n",
    "To try out linear regression with scikit-learn, we will start with synthetic data. Linear regression assumes there is a linear relationship between the regressors and the predicted value, so we will simulate data that does have such a linear relationship.  Specifically, we will build data with the following relationship:\n",
    "\\begin{align}\n",
    " y = \\beta x_1 + (1-\\beta) x_2 + \\alpha \\epsilon \n",
    "\\end{align}\n",
    "\n",
    "where y is the dependent variable, and $x_1$ and $x_2$ are regressors. $\\beta$ can range from 0 to 1; it is a weighting variable that controls the relative influence from each regressor (at .5, both regressors contribute equally). $\\epsilon$ is a noise term that makes $y$ only partially dependent on these regressors. The strength of the noise is controlled by $\\alpha$.  \n",
    "\n",
    "Let's start by setting some values for the regressors. We will build them to have 0 mean."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "j9n17gXFOIXX",
   "metadata": {
    "execution": {}
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "## **Section 1.1:  Generating a Synthetic Dataset**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4uFxL_rZrNKj",
   "metadata": {
    "execution": {}
   },
   "source": [
    "This code generates two arrays of random numbers using the numpy library's random module. The `data_point`s variable is used to define the length of the generated arrays, and the `random.randn()` function is used twice to generate the arrays. The numpy library was previously imported and given the alias \"np\" for ease of use. The generated random numbers can be useful in various scientific and engineering applications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Generating regressors value 'x1' and 'x2' with NumPy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Generating regressors value 'x1' and 'x2' with NumPy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Generating regressors value 'x1' and 'x2' with NumPy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  Generating regressors value 'x1' and 'x2' with NumPy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "######  Generating regressors value 'x1' and 'x2' with NumPy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#######  Generating regressors value 'x1' and 'x2' with NumPy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Ov8RM-kOq8Ha",
   "metadata": {
    "cellView": "form",
    "execution": {},
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "#@title Generating regressors value 'x1' and 'x2' with NumPy\n",
    "\n",
    "# Importing the numpy library with the alias \"np\" earlier in the code\n",
    "# Numpy is a popular library used for numerical computing and mathematical operations in Python\n",
    "\n",
    "data_points = 100   # Defining the number of data points to generate\n",
    "\n",
    "x_1 = np.random.randn(data_points)   # Generating an array of 'data_points' numbers from a normal distribution with zero mean using numpy's 'random.randn()' function, and saving it to 'x_1'\n",
    "# 'random.randn()' function is a part of numpy's random module and generates an array of random numbers from a standard normal distribution (mean = 0, standard deviation = 1)\n",
    "\n",
    "x_2 = np.random.randn(data_points)   # Generating another array of 'data_points' numbers from a normal distribution with zero mean using numpy's 'random.randn()' function, and saving it to 'x_2'\n",
    "# We are again using the 'random.randn()' function from numpy's random module to generate another array of random numbers from a standard normal distribution. This time we are saving it to 'x_2' variable.\n",
    "\n",
    "# By using the numpy library's random module, we can generate random numbers efficiently, which is often useful in many scientific and engineering applications."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6656a6f",
   "metadata": {
    "execution": {}
   },
   "source": [
    "Now we can choose some weighting values and calculate the dependent variable:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Generating dependent variable  'y'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Generating dependent variable  'y'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Generating dependent variable  'y'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  Generating dependent variable  'y'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "######  Generating dependent variable  'y'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#######  Generating dependent variable  'y'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "YH_7qeJoKeJj",
   "metadata": {
    "cellView": "form",
    "execution": {},
    "executionInfo": {
     "elapsed": 386,
     "status": "ok",
     "timestamp": 1681525835642,
     "user": {
      "displayName": "Deepak Mewada",
      "userId": "10376201445384716451"
     },
     "user_tz": -330
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "#@title Generating dependent variable  'y'\n",
    "\n",
    "\n",
    "beta = .5   # Defining the weight for the first regressor\n",
    "alpha = .1    # Defining the weight for the noise\n",
    "\n",
    "def y_func(weights, regressors, noise):\n",
    "    \"\"\"\n",
    "    This function takes in three inputs:\n",
    "    - weights: a numpy array of weights (1 x r, where r is number of regressors)\n",
    "    - regressors: a numpy array of regressors (r x d, where d is number of datapoints)\n",
    "    - noise: a scalar value representing the amount of noise to be added to the output.\n",
    "\n",
    "    The function returns the dot product of 'weights' and 'regressors', plus some added noise (controlled by 'noise').\n",
    "    \"\"\"\n",
    "    # The dot product of weights and regressors is calculated using numpy's 'dot' function. Then, noise is added to the result using numpy's 'random.randn()' function.\n",
    "    return np.dot(weights, regressors) + noise * np.random.randn(regressors.shape[1])\n",
    "\n",
    "# Calling the function 'y_func' to generate 'y', using the variables 'alpha', 'beta', and 'x_1', 'x_2' that were previously defined.\n",
    "y = y_func(np.array([beta, 1-beta]), np.array([x_1, x_2]), alpha)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "JTXubiDuuTMi",
   "metadata": {
    "execution": {}
   },
   "source": [
    "The code generates a dependent variable 'y' by calling a function 'y_func()'. The function takes in weights, regressors, and noise as inputs, calculates the dot product of weights and regressors using numpy's 'dot' function, adds noise to the result using numpy's 'random.randn()' function, and returns the final result. The 'y_func()' function is called using previously defined variables 'beta', 'alpha', and 'x_1', 'x_2'."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "349c8677",
   "metadata": {
    "execution": {}
   },
   "source": [
    "### **Plotting the data**\n",
    "\n",
    "To fully understand what this function represents, we can plot the relationship between the regressors and y. Change the values of $alpha$ and $beta$ and see how it impacts these plots. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "uINr8aGSvLK5",
   "metadata": {
    "execution": {},
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1681525659917,
     "user": {
      "displayName": "Deepak Mewada",
      "userId": "10376201445384716451"
     },
     "user_tz": -330
    }
   },
   "outputs": [],
   "source": [
    "# Creating a figure with two subplots\n",
    "plt.subplot(1, 2, 1)         # The first subplot\n",
    "plt.scatter(x_1, y, c='r')   # Creating a scatter plot of x_1 vs. y, with the color 'red'\n",
    "plt.ylabel('y')              # Adding a y-axis label to the plot\n",
    "plt.xlabel('x_1')            # Adding an x-axis label to the plot\n",
    "\n",
    "plt.subplot(1, 2, 2)         # The second subplot\n",
    "plt.scatter(x_2, y, c='b')   # Creating a scatter plot of x_2 vs. y, with the color 'blue'\n",
    "plt.ylabel('y')              # Adding a y-axis label to the plot\n",
    "plt.xlabel('x_2')            # Adding an x-axis label to the plot\n",
    "\n",
    "plt.suptitle('Scatter plots of y against x_1 and x_2', fontsize=14)  # Adding a title to the overall figure\n",
    "plt.show()  # Displaying the plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "zPeztNPTwRKx",
   "metadata": {
    "execution": {}
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "## **Section 1.2 Fitting Model and Analyzing Results**\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "KXeWoc1fwlMB",
   "metadata": {
    "execution": {}
   },
   "source": [
    "Now we can test if linear regression can find these relationships between the regressors and the dependent variable and use it to predict $y$ values from new $x$ values. Let's start by making a dataset with $\\beta=.8$ and $\\alpha=.1$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9hnuGKaOK2t6",
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "beta = .8   # Defining the weight for the first regressor\n",
    "alpha = .1    # Defining the weight for the noise\n",
    "regressors = np.array([x_1, x_2])   # Creating an array of regressors (x_1 and x_2)\n",
    "\n",
    "# Calling the function 'y_func' to generate 'y', using the variables 'alpha', 'beta', and 'regressors' that were previously defined.\n",
    "y = y_func(np.array([beta, 1-beta]), regressors, alpha)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "-kwM7dzEwoQq",
   "metadata": {
    "execution": {}
   },
   "source": [
    "\n",
    "Then we can train a linear regression model. In scikit-learn, models are objects. So we first define a linear regression object and then train it with our synthetic data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "U2CJQMRQLFKh",
   "metadata": {
    "execution": {},
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1681490600468,
     "user": {
      "displayName": "Deepak Mewada",
      "userId": "10376201445384716451"
     },
     "user_tz": -330
    }
   },
   "outputs": [],
   "source": [
    "#here we will use 'LinearRegression' from 'sklearn.linear_model' which we imported earlier\n",
    "\n",
    "reg_model = LinearRegression()   # Creating a new instance of the LinearRegression class and assigning it to the variable 'reg_model'\n",
    "\n",
    "# Training the model using the fit() method of the LinearRegression class\n",
    "reg_model.fit(regressors.T, y)\n",
    "# Note that the regressors are transposed using the .T method to conform to the scikit-learn convention of having datapoints as rows and regressors as columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9e76208",
   "metadata": {
    "execution": {}
   },
   "source": [
    "The model has now been trained with our synthetic data. But we want to see if it has done a good job finding the relationships between these variables. \n",
    "\n",
    "We will first evaluate the coefficient of determination of the model fit. This is a measure of how much of the variability in the data the model has captured. It is also known as $R^2$ (\"R-squared\"). 1 is the best possible value. \n",
    "\n",
    "We will also look at the coefficients that the model has learned for each regressor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "IPvSJEhiLW2R",
   "metadata": {
    "execution": {},
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1681490600469,
     "user": {
      "displayName": "Deepak Mewada",
      "userId": "10376201445384716451"
     },
     "user_tz": -330
    }
   },
   "outputs": [],
   "source": [
    "reg_model.score(regressors.T, y)   # Calling the score() method of the LinearRegression class on the trained model 'reg_model' to get the coefficient of determination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "t86gWVPgLavR",
   "metadata": {
    "execution": {},
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1681490600469,
     "user": {
      "displayName": "Deepak Mewada",
      "userId": "10376201445384716451"
     },
     "user_tz": -330
    }
   },
   "outputs": [],
   "source": [
    "reg_model.coef_   # Accessing the 'coef_' attribute of the trained model 'reg_model' to get the coefficients (or weightings) of each regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ANJN5fT2Vp_D",
   "metadata": {
    "execution": {}
   },
   "source": [
    "As we can see, the model has a high coefficient of determination and does a good job of recovering the regressor weights (which we had set to .8 and 1 - .8 = .2). You can increase the amount of noise in the data and see how this impacts these results. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d61cbf5a",
   "metadata": {
    "execution": {}
   },
   "source": [
    "We have just evaluated the model on the exact same data points that we trained it on. This is not necessarily a good indication of how well it will perform on new data it hasn't seen before. Let's make two new data sets and test how well the trained model performs on them. In the first, the relationship between the x and y values will remain the same and we will just sample new x values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "p3imJoPEcEgi",
   "metadata": {
    "execution": {}
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "## **Section 1.3 Test the model on new unseen x values**\n",
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "n_D2EoE4McHB",
   "metadata": {
    "execution": {},
    "executionInfo": {
     "elapsed": 1415,
     "status": "ok",
     "timestamp": 1681490601871,
     "user": {
      "displayName": "Deepak Mewada",
      "userId": "10376201445384716451"
     },
     "user_tz": -330
    }
   },
   "outputs": [],
   "source": [
    "x_1_test1 = np.random.randn(data_points)   # Creating a new array of x_1 values using the same normal distribution as before\n",
    "x_2_test1 = np.random.randn(data_points)   # Creating a new array of x_2 values using the same normal distribution as before\n",
    "\n",
    "# Creating a new array of regressors (x_1_test1 and x_2_test1) to test the model's predictions\n",
    "regressors_test1 = np.array([x_1_test1, x_2_test1])\n",
    "\n",
    "# Getting the model's predictions on the new x values by calling the predict() method of the LinearRegression object\n",
    "preds_test1 = reg_model.predict(regressors_test1.T)\n",
    "\n",
    "# Assuming the same relationship of alpha=.8 and beta=.1 as set above, we can calculate the true y values\n",
    "y_test1 = y_func(np.array([beta, 1-beta]), regressors_test1, alpha)\n",
    "\n",
    "# Visualizing how aligned the predicted and true values are by creating a scatter plot\n",
    "plt.scatter(y_test1, preds_test1)\n",
    "plt.xlabel('true'); plt.ylabel('predicted')\n",
    "\n",
    "# Calculating the coefficient of determination (R^2) using the score() method of the LinearRegression object\n",
    "reg_model.score(regressors_test1.T, y_test1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a96ab74",
   "metadata": {
    "execution": {}
   },
   "source": [
    "As the plot and the coefficient of determination show, the model does well on this new data! \n",
    "\n",
    "But what if something changed between when we collected data to train the model and when we collected a second data set to test it on? Then the relationship between x and y may have changed. Would the model still work well?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9V01RmTRoD9k",
   "metadata": {
    "execution": {}
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "## **Section 1.4: Check the model on a new dataset with a slightly different relationship.**\n",
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "J9ogBurMMo2B",
   "metadata": {
    "execution": {},
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1681490601871,
     "user": {
      "displayName": "Deepak Mewada",
      "userId": "10376201445384716451"
     },
     "user_tz": -330
    }
   },
   "outputs": [],
   "source": [
    "## Section 1.3: Check the model on a new dataset with a slightly different relationship.\n",
    "\n",
    "x_1_test2 = np.random.randn(data_points)\n",
    "x_2_test2 = np.random.randn(data_points)\n",
    "\n",
    "#Get the model's predictions on these new x values\n",
    "regressors_test2 = np.array([x_1_test2, x_2_test2])\n",
    "preds_test2 = reg_model.predict(regressors_test2.T)\n",
    "\n",
    "#Assuming a different relationship (alpha = .6), we can calculate the true y values:\n",
    "alpha = .6\n",
    "y_test2 = y_func(np.array([beta, 1-beta]), regressors_test2, alpha)\n",
    "\n",
    "plt.scatter(y_test2, preds_test2) #visualizing how aligned the predicted and true values are\n",
    "plt.xlabel('true'); plt.ylabel('predicted')\n",
    "reg_model.score(regressors_test2.T, y_test2) #coef of determination"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adbea7cd",
   "metadata": {
    "execution": {}
   },
   "source": [
    "Now the model does not perform as well. This idea, that a model that performs well on the data it was trained on may not always generalize to new data, is an important concept in machine learning. It means we must always be careful when we make claims about how well a model performs or assumptions about how useful it will be in diverse circumstances. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "DiR7mcnycPiB",
   "metadata": {
    "execution": {}
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "# **Summary**\n",
    "\n",
    "Estimated timing of tutorial: \n",
    "\n",
    "In this tutorial, we learned about how linear regression was used to find relationships between regressor and dependent variables. We also discussed the importance of being cautious in making assumptions about the usefulness of models trained on specific data, as their performance could vary when applied to new data.\n",
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "myt07YFyNgmw",
    "DiR7mcnycPiB"
   ],
   "include_colab_link": true,
   "name": "W2D5_Tutorial1",
   "provenance": [
    {
     "file_id": "1OeCRQaEauQAWhy04fdLJeB5DH5vSt8wH",
     "timestamp": 1679050411619
    }
   ],
   "toc_visible": true
  },
  "kernel": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3 (pangeo)",
   "language": "python",
   "name": "pangeo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}