{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "myt07YFyNgmw",
   "metadata": {
    "execution": {}
   },
   "source": [
    "# **Tutorial 6:  Remote sensing crops dataset**\n",
    "\n",
    "**Week 2, Day 5: Climate Response: adaptation and impact**\n",
    "\n",
    "**By Climatematch Academy**\n",
    "\n",
    "__Content creators:__ Deepak Mewada, Grace Lindsay\n",
    "\n",
    "__Content reviewers:__ Ohad Zivan, Name Surname\n",
    "\n",
    "__Content editors:__ Name Surname, Name Surname\n",
    "\n",
    "__Production editors:__ Name Surname, Name Surname"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "kDQc1jnoNWcp",
   "metadata": {
    "execution": {}
   },
   "source": [
    "___\n",
    "# **Tutorial Objectives**\n",
    "\n",
    "*Estimated timing of tutorial: 10 minutes*\n",
    "\n",
    "Welcome to tutorial 6 of a series focused on understanding the role of data science and machine learning in addressing the impact of climate change and adapting to it.\n",
    "\n",
    "In this tutorial, we will become familiar with the Crop dataset. By the end of this tutorial, \n",
    "- You will learn about remote sensing data collected from the Sentinel-2 satellite to find crops in the Togolese Republic\n",
    "- You will learn to visualize and explore the dataset by Histogram, Heatmap and Scatter plot.\n",
    "- You will learn to visualize the correlation between different features of the dataset\n",
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Tutorial slides\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " These are the slides for the videos in all tutorials today\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Tutorial slides\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " These are the slides for the videos in all tutorials today\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Tutorial slides\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " These are the slides for the videos in all tutorials today\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  Tutorial slides\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " These are the slides for the videos in all tutorials today\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "######  Tutorial slides\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " These are the slides for the videos in all tutorials today\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#######  Tutorial slides\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " These are the slides for the videos in all tutorials today\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "########  Tutorial slides\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " These are the slides for the videos in all tutorials today\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#########  Tutorial slides\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " These are the slides for the videos in all tutorials today\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##########  Tutorial slides\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " These are the slides for the videos in all tutorials today\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###########  Tutorial slides\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " These are the slides for the videos in all tutorials today\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wlndBdbV5iJF",
   "metadata": {
    "cellView": "form",
    "execution": {},
    "executionInfo": {
     "elapsed": 432,
     "status": "ok",
     "timestamp": 1679179861338,
     "user": {
      "displayName": "Deepak Mewada",
      "userId": "10376201445384716451"
     },
     "user_tz": -330
    },
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "# @title Tutorial slides\n",
    "\n",
    "# @markdown These are the slides for the videos in all tutorials today\n",
    "from IPython.display import IFrame\n",
    "IFrame(src=f\"https://mfr.ca-1.osf.io/render?url=https://osf.io/kaq2x/?direct%26mode=render%26action=download%26mode=render\", width=854, height=480)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Vtq0OyoRNPcc",
   "metadata": {
    "execution": {}
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "# Setup\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Importing necessary libraries\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Importing necessary libraries\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Importing necessary libraries\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  Importing necessary libraries\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "######  Importing necessary libraries\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#######  Importing necessary libraries\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "########  Importing necessary libraries\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#########  Importing necessary libraries\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##########  Importing necessary libraries\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###########  Importing necessary libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Kwsl6-KNNPcc",
   "metadata": {
    "cellView": "form",
    "execution": {},
    "executionInfo": {
     "elapsed": 828,
     "status": "ok",
     "timestamp": 1681642222480,
     "user": {
      "displayName": "Deepak Mewada",
      "userId": "10376201445384716451"
     },
     "user_tz": -330
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "#@title Importing necessary libraries\n",
    "import numpy as np              # NumPy for numerical computing\n",
    "import pandas as pd             # Pandas for data manipulation\n",
    "import matplotlib.pyplot as plt # Matplotlib for visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vMap3TCmNPcc",
   "metadata": {
    "execution": {}
   },
   "source": [
    "<details>\n",
    "<summary> <font color='Red'>Click here if you are running on local machine or you encounter any error while importing   </font></summary>\n",
    "NOTE: Please note that if you are running this code on a local machine and encounter an error while importing a library, make sure to install the library via pip. For example, if you receive a `\"ModuleNotFoundError: No module named 'google.colab'\" `error while using 'Colab', please run `\"pip install google\"` to install the required module."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nULavCfq4o07",
   "metadata": {
    "execution": {}
   },
   "source": [
    "---\n",
    "\n",
    "# **Section 1: Remote Sensing Crops Dataset Exploration**\n",
    "\n",
    "In this section we will load, visualise and explore the remote sensing data collected from the Sentinel-2 satellite to find crops in the Togolese Republic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Video 1: Video 1 Name\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Video 1: Video 1 Name\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Video 1: Video 1 Name\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  Video 1: Video 1 Name\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "######  Video 1: Video 1 Name\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#######  Video 1: Video 1 Name\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "########  Video 1: Video 1 Name\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#########  Video 1: Video 1 Name\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##########  Video 1: Video 1 Name\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###########  Video 1: Video 1 Name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ThcPwgvzvV-6",
   "metadata": {
    "cellView": "form",
    "execution": {},
    "executionInfo": {
     "elapsed": 663,
     "status": "ok",
     "timestamp": 1679179862414,
     "user": {
      "displayName": "Deepak Mewada",
      "userId": "10376201445384716451"
     },
     "user_tz": -330
    },
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "# @title Video 1: Video 1 Name\n",
    "from ipywidgets import widgets\n",
    "from IPython.display import display, IFrame, YouTubeVideo\n",
    "\n",
    "out2 = widgets.Output()\n",
    "with out2:\n",
    "  class BiliVideo(IFrame):\n",
    "    def __init__(self, id, page=1, width=400, height=300, **kwargs):\n",
    "      self.id=id\n",
    "      src = 'https://player.bilibili.com/player.html?bvid={0}&page={1}'.format(id, page)\n",
    "      super(BiliVideo, self).__init__(src, width, height, **kwargs)\n",
    "\n",
    "  video = BiliVideo(id=\"\", width=730, height=410, fs=1)\n",
    "  print(f'Video available at https://www.bilibili.com/video/{video.id}')\n",
    "  display(video)\n",
    "\n",
    "out1 = widgets.Output()\n",
    "with out1:\n",
    "  video = YouTubeVideo(id=\"\", width=730, height=410, fs=1, rel=0)\n",
    "  print(f'Video available at https://youtube.com/watch?v={video.id}')\n",
    "  display(video)\n",
    "\n",
    "out = widgets.Tab([out1, out2])\n",
    "out.set_title(0, 'Youtube')\n",
    "out.set_title(1, 'Bilibili')\n",
    "\n",
    "display(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "j9n17gXFOIXX",
   "metadata": {
    "execution": {}
   },
   "source": [
    "---\n",
    "## **Section 1.1:  Loading  the dataset**\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad5c8b85",
   "metadata": {
    "execution": {}
   },
   "source": [
    "As discussed in the video, we will use remote sensing data collected from the Sentinel-2 satellite to find crops in the Togolese Republic. The data is described in [this paper](https://arxiv.org/pdf/2006.16866.pdf), and was accessed through [this repo](https://github.com/nasaharvest/cropharvest)). \n",
    "\n",
    "The data contains 1290 data points in the training set and 306 in the test set. Each data point represents one spatial location. As discussed in the video, the data contains normalized values from all Sentintel-2 bands, except B1 and B10, plus the pre-calculated NDVI. Therefore, each data point has 12 features in total. Each point is labeled as containing crops (1) or not (0).   \n",
    "If you want to know more about what these bands(feature) mean, you can refer to [this resource](https://en.wikipedia.org/wiki/Sentinel-2#cite_note-15:~:text=Spectral%20bands%20for%20the%20Sentinel%2D2%20sensors)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c241ff61",
   "metadata": {
    "execution": {},
    "executionInfo": {
     "elapsed": 23754,
     "status": "ok",
     "timestamp": 1681642247462,
     "user": {
      "displayName": "Deepak Mewada",
      "userId": "10376201445384716451"
     },
     "user_tz": -330
    }
   },
   "outputs": [],
   "source": [
    "#Load the data from the specified file path\n",
    "import os, pooch\n",
    "fname = 'togo_crops_data.npz'\n",
    "if not os.path.exists(fname):\n",
    "    url = \"https://osf.io/4tqhe/download\"\n",
    "    fname = pooch.retrieve(url, known_hash=None)\n",
    "data = np.load(fname)\n",
    "X_train = data['arr_0']  # Features of the training set\n",
    "y_train = data['arr_1']  # Labels of the training set\n",
    "X_test = data['arr_2']   # Features of the test set\n",
    "y_test = data['arr_3']   # Labels of the test set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "IPfncmu4zvQF",
   "metadata": {
    "execution": {}
   },
   "source": [
    "In the next few sections we will be learning about various ways to visualise the data to find some trends."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "XtgjDdu_eeC-",
   "metadata": {
    "execution": {}
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "## **Section 1.2 Visualising the Dataset**\n",
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76b6959e",
   "metadata": {
    "execution": {}
   },
   "source": [
    "### Visualisation 1.2 : Plot Histogram\n",
    "\n",
    "Plot histograms of the training values of each feature. Specifically, for each feature, make a single plot that contains two histograms: one of the values for locations with crops and one for those without. Set the bins the same for each and reduce the transparency of each so that both are visible and comparable. Also print the percentage of data points that have crops in them. It is important to understand how balanced a data set is when analyzing performance.  \n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mZgnpC9Y_4kk",
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "#################################################\n",
    "## TODO for students:\n",
    "# Fill in the code in empty places to remove this error\n",
    "# raise NotImplementedError(\"Student exercise: Fill in the code in empty places to remove this error\")\n",
    "#################################################\n",
    "\n",
    "# Separate the positive and negative classes\n",
    "pos_inds = ...  # Indices of positive class\n",
    "neg_inds = ...  # Indices of negative class\n",
    "\n",
    "# Create subplots for each feature\n",
    "for i in range(12):\n",
    "    plt.subplot(3, 4, i+1)  # Create a subplot\n",
    "    # Plot histograms of the positive and negative classes for the current feature\n",
    "    n, bins, patches = plt.hist(X_train[:, i][...], alpha=.5)  # Histogram of the positive class\n",
    "    plt.hist(X_train[:, i][...], bins=bins, alpha=.5)         # Histogram of the negative class\n",
    "    plt.title(f\"Feature {i+1}\")  # Set the title of the subplot to the current feature number\n",
    "\n",
    "plt.tight_layout()  # Adjust spacing between subplots\n",
    "plt.show()          # Display the subplots\n",
    "\n",
    "print('Percentage of positive samples: ' + str(...))  #hint calculate % by (number of positive/(number of positive + number of negative)); can use len to calculate no"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "VgA7EY85ttsU",
   "metadata": {
    "colab_type": "text",
    "execution": {},
    "executionInfo": {
     "elapsed": 2469,
     "status": "ok",
     "timestamp": 1679601692635,
     "user": {
      "displayName": "Grace Lindsay",
      "userId": "07080819108437112890"
     },
     "user_tz": 240
    }
   },
   "source": [
    "[*Click for solution*](https://github.com/NeuromatchAcademy/course-content/tree/main//tutorials/W2D5_ClimateResponse-AdaptationImpact/solutions/W2D5_Tutorial6_Solution_5a22ad64.py)\n",
    "\n",
    "*Example output:*\n",
    "\n",
    "<img alt='Solution hint' align='left' width=629.0 height=470.0 src=https://raw.githubusercontent.com/NeuromatchAcademy/course-content/main/tutorials/W2D5_ClimateResponse-AdaptationImpact/static/W2D5_Tutorial6_Solution_5a22ad64_0.png>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "l07SCayNAB8H",
   "metadata": {
    "execution": {}
   },
   "source": [
    "### Think! 1.1: Looking at features by class label \n",
    "\n",
    "Based on these plots, do you think the final feature would be useful for identifying crops? What about second to last?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "yZC3Qv3zu2T9",
   "metadata": {
    "execution": {}
   },
   "source": [
    "---\n",
    "## (Bonus) **Section 1.3: Visualization of correlation between the features**\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "Looking at how different features of the data relate to each other can help us better understand the data and can be important when thinking about modeling building."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a_pLI1SjhB2W",
   "metadata": {
    "execution": {}
   },
   "source": [
    "### Visualisation 1.3 : Plot Heatmap\n",
    "First we produce a heatmap showing the correlation coefficients between the features, with blue indicating negative correlation and red indicating positive correlation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "orl9SEzAocaU",
   "metadata": {
    "execution": {},
    "executionInfo": {
     "elapsed": 1419,
     "status": "ok",
     "timestamp": 1679179883593,
     "user": {
      "displayName": "Deepak Mewada",
      "userId": "10376201445384716451"
     },
     "user_tz": -330
    }
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "# Calculate the correlation matrix\n",
    "corr = np.corrcoef(X_train, rowvar=False)\n",
    "\n",
    "# Plot the correlation matrix using a heatmap\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "sns.heatmap(corr, cmap='coolwarm', center=0, annot=True, fmt='.2f',\n",
    "            xticklabels=[f\"Feature {i+1}\" for i in range(12)],\n",
    "            yticklabels=[f\"Feature {i+1}\" for i in range(12)])\n",
    "ax.set_title(\"Correlation between features\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cs37d_dGub2l",
   "metadata": {
    "execution": {}
   },
   "source": [
    "The correlation coefficient summarizes the relationship between two features. We can see this relationship more directly by plotting scatter plots of all the training data points. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ToQiMNJ2hPEW",
   "metadata": {
    "execution": {}
   },
   "source": [
    "### Visualisation 1.3 : Plot Scatter plots\n",
    "In this example, we create a 12x12 grid of subplots, with each subplot showing a scatter plot of two features. The color of the dots in the scatter plot represents the label of the data point (y_train). We set the cmap parameter of plt.scatter to 'bwr' to use a colormap that goes from blue for negative labels to red for positive labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Rl3-ue1unpQM",
   "metadata": {
    "execution": {},
    "executionInfo": {
     "elapsed": 13281,
     "status": "ok",
     "timestamp": 1679179882177,
     "user": {
      "displayName": "Deepak Mewada",
      "userId": "10376201445384716451"
     },
     "user_tz": -330
    }
   },
   "outputs": [],
   "source": [
    "# Plot the data using scatter plots\n",
    "fig, axs = plt.subplots(12, 12, figsize=(20, 20))\n",
    "for i in range(12):\n",
    "    for j in range(12):\n",
    "        axs[i, j].scatter(X_train[:, i], X_train[:, j], c=y_train, cmap='bwr')\n",
    "        axs[i, j].set_xlabel(f\"Feature {i+1}\")\n",
    "        axs[i, j].set_ylabel(f\"Feature {j+1}\")\n",
    "        axs[i, j].set_xticks([])\n",
    "        axs[i, j].set_yticks([])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "BUJCh76N2B8Q",
   "metadata": {
    "execution": {}
   },
   "source": [
    "### Think!: Reflecting on correlations\n",
    "\n",
    "Based on what you know about remote sensing and hyperspectral data, does it make sense that some pairs of features may be more correlated than others?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "DiR7mcnycPiB",
   "metadata": {
    "execution": {}
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "# **Summary**\n",
    "\n",
    "Estimated timing of tutorial: \n",
    "\n",
    "In this tutorial, we familiarized ourselves with the crop dataset and visualized it to analyze the impact of various features.\n",
    "\n",
    "---\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "W2D5_Tutorial6",
   "provenance": [
    {
     "file_id": "13-jG5UK8BxV_spBX8XZ4dnVOyy97tEuO",
     "timestamp": 1679050483001
    }
   ],
   "toc_visible": true
  },
  "kernel": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3 (pangeo)",
   "language": "python",
   "name": "pangeo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}