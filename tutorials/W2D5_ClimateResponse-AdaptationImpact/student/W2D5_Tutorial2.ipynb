{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "myt07YFyNgmw",
   "metadata": {
    "execution": {}
   },
   "source": [
    "# Tutorial 2:  Regression and Decision Trees on the Dengue Fever Dataset\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "**Week 2, Day 5: Climate Response: adaptation and impact**\n",
    "\n",
    "**By Climatematch Academy**\n",
    "\n",
    "__Content creators:__ Deepak Mewada, Grace Lindsay\n",
    "\n",
    "__Content reviewers:__ \n",
    "\n",
    "__Content editors:__ \n",
    "\n",
    "__Production editors:__ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "kDQc1jnoNWcp",
   "metadata": {
    "execution": {}
   },
   "source": [
    "___\n",
    "# Tutorial Objectives\n",
    "\n",
    "*Estimated timing of tutorial: 50 minutes* \n",
    "\n",
    "Welcome to tutorial 2 of a series focused on understanding the role of data science and machine learning in addressing the impact of climate change and adapting to it.\n",
    "\n",
    "In this tutorial, we will explore a dataset that relates weather variables to dengue fever cases. By the end of the tutorial, you will be able to:\n",
    "\n",
    "- Load the data into pandas dataframes and visualize it to see obvious trends.\n",
    "- Apply linear regression to the Dengue dataset, clean the data, implement linear regression using scikit-learn, and evaluate its performance. This will include handling categorical data using dummy variables and using scikit-learn's Poisson GLM method to handle integer-valued data.\n",
    "- Apply additional methods to the Dengue Fever dataset, including implementing Random Forest Regression, discussing and analyzing its performance, and measuring feature importance.\n",
    "\n",
    "This tutorial will provide you with practical experience in working with real-world datasets and implementing different regression techniques.\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Tutorial slides\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " These are the slides for the videos in all tutorials today\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Tutorial slides\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " These are the slides for the videos in all tutorials today\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Tutorial slides\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " These are the slides for the videos in all tutorials today\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  Tutorial slides\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " These are the slides for the videos in all tutorials today\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "######  Tutorial slides\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " These are the slides for the videos in all tutorials today\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#######  Tutorial slides\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " These are the slides for the videos in all tutorials today\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "########  Tutorial slides\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " These are the slides for the videos in all tutorials today\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#########  Tutorial slides\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " These are the slides for the videos in all tutorials today\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##########  Tutorial slides\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " These are the slides for the videos in all tutorials today\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###########  Tutorial slides\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " These are the slides for the videos in all tutorials today\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "############  Tutorial slides\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " These are the slides for the videos in all tutorials today\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#############  Tutorial slides\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " These are the slides for the videos in all tutorials today\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wlndBdbV5iJF",
   "metadata": {
    "cellView": "form",
    "execution": {},
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "# @title Tutorial slides\n",
    "\n",
    "# @markdown These are the slides for the videos in all tutorials today\n",
    "from IPython.display import IFrame\n",
    "IFrame(src=f\"https://mfr.ca-1.osf.io/render?url=https://osf.io/kaq2x/?direct%26mode=render%26action=download%26mode=render\", width=854, height=480)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Vtq0OyoRNPcc",
   "metadata": {
    "execution": {}
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Import necessary libraries:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Import necessary libraries:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Import necessary libraries:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  Import necessary libraries:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "######  Import necessary libraries:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#######  Import necessary libraries:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "########  Import necessary libraries:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#########  Import necessary libraries:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##########  Import necessary libraries:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###########  Import necessary libraries:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "############  Import necessary libraries:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#############  Import necessary libraries:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Kwsl6-KNNPcc",
   "metadata": {
    "cellView": "form",
    "execution": {},
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "#@title Import necessary libraries:\n",
    "\n",
    "import numpy as np  # Import the numpy library as np\n",
    "from sklearn.linear_model import LinearRegression # Import the LinearRegression class from the sklearn.linear_model module\n",
    "import matplotlib.pyplot as plt # Import the pyplot module from the matplotlib library\n",
    "import pandas as pd # Import the pandas library and the drive function from the google.colab module\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from matplotlib import cm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wNqEz5P8j2Q-",
   "metadata": {
    "execution": {}
   },
   "source": [
    "<details>\n",
    "<summary> <font color='Red'>Click here if you are running on local machine or you encounter any error while importing   </font></summary>\n",
    "\n",
    "\n",
    "**NOTE :**  Please note that if you are running this code on a local machine and encounter an error while importing a library, make sure to install the library via pip. For example, if you receive a \"`ModuleNotFoundError: No module named 'library name'`\" error , please run \"`pip install 'library name'`\" to install the required module."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nULavCfq4o07",
   "metadata": {
    "execution": {}
   },
   "source": [
    "---\n",
    "\n",
    "# **Section 1: Loading and Exploring Dengue Fever Data Set**\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Video 1: Video 1 Name\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Video 1: Video 1 Name\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Video 1: Video 1 Name\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  Video 1: Video 1 Name\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "######  Video 1: Video 1 Name\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#######  Video 1: Video 1 Name\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "########  Video 1: Video 1 Name\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#########  Video 1: Video 1 Name\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##########  Video 1: Video 1 Name\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###########  Video 1: Video 1 Name\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "############  Video 1: Video 1 Name\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#############  Video 1: Video 1 Name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ThcPwgvzvV-6",
   "metadata": {
    "cellView": "form",
    "execution": {},
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "# @title Video 1: Video 1 Name\n",
    "from ipywidgets import widgets\n",
    "from IPython.display import display, IFrame, YouTubeVideo\n",
    "\n",
    "out2 = widgets.Output()\n",
    "with out2:\n",
    "  class BiliVideo(IFrame):\n",
    "    def __init__(self, id, page=1, width=400, height=300, **kwargs):\n",
    "      self.id=id\n",
    "      src = 'https://player.bilibili.com/player.html?bvid={0}&page={1}'.format(id, page)\n",
    "      super(BiliVideo, self).__init__(src, width, height, **kwargs)\n",
    "\n",
    "  video = BiliVideo(id=\"\", width=730, height=410, fs=1)\n",
    "  print(f'Video available at https://www.bilibili.com/video/{video.id}')\n",
    "  display(video)\n",
    "\n",
    "out1 = widgets.Output()\n",
    "with out1:\n",
    "  video = YouTubeVideo(id=\"\", width=730, height=410, fs=1, rel=0)\n",
    "  print(f'Video available at https://youtube.com/watch?v={video.id}')\n",
    "  display(video)\n",
    "\n",
    "out = widgets.Tab([out1, out2])\n",
    "out.set_title(0, 'Youtube')\n",
    "out.set_title(1, 'Bilibili')\n",
    "\n",
    "display(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "j9n17gXFOIXX",
   "metadata": {
    "execution": {}
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "## Section 1.1:  Loading the Environmental data\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2c27233",
   "metadata": {
    "execution": {}
   },
   "source": [
    "As discussed in the video, we are working with a [data set](https://www.drivendata.org/competitions/44/dengai-predicting-disease-spread/page/81/) provided by [DrivenData](https://arxiv.org/abs/1606.07781) that centers on the goal of predicting dengue fever cases based on environmental variables.\n",
    "\n",
    "We will use pandas to interface with the data, which is shared in the .csv format. First, let's load the environmental data into a pandas dataframe and print its contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hpeaOl-v3Mod",
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "import pooch, os\n",
    "features_fname = \"dengue_features_train(1).csv\"\n",
    "if not os.path.exists(features_fname):\n",
    "    url = \"https://osf.io/wm9un/download/\"\n",
    "    features_fname = pooch.retrieve(url, known_hash=None)\n",
    "\n",
    "# Loading a CSV file named 'dengue_features_train(1).csv' into a pandas DataFrame named 'df'\n",
    "# The file path is specified as an absolute path to a Google Drive folder.\n",
    "df_features = pd.read_csv(features_fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dOsBX8X6ScK",
   "metadata": {
    "execution": {}
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "## Section 1.2:  Explore the dataset\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Vv82LGM26hiD",
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# Displaying the contents of the DataFrame named 'df'.\n",
    "# This is useful for verifying that the data was read correctly.\n",
    "df_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2e345ba",
   "metadata": {
    "execution": {}
   },
   "source": [
    "We can see some of the variables discussed in the video. For full documentation of these features, see the associated description [here](https://www.drivendata.org/competitions/44/dengai-predicting-disease-spread/page/82/). \n",
    "\n",
    "In climate science, visualizing data is an important step in understanding patterns and trends in environmental data. It can also help identify outliers and inconsistencies that need to be addressed before modeling. Therefore, in the next subsection, we will visualize the climate and environmental data to gain insights and identify potential issues.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98JK1Hy3IN0P",
   "metadata": {
    "execution": {}
   },
   "source": [
    "---\n",
    "## Section 1.3 Visualise the Data\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0Q1GTTR8imTs",
   "metadata": {
    "execution": {}
   },
   "source": [
    "### Coding Exercise 1.1: Inspect the data\n",
    "\n",
    "For this exercise, you have to visualize the data. Use hint for the function name if you are new to this\n",
    "\n",
    "*Exercise Objective*: \n",
    "1. Use pandas to plot histograms of these features using .hist() function\n",
    "2. Use the .isnull() function to see if there is any missing data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lawwAEiC8vZV",
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "#################################################\n",
    "## TODO for students:\n",
    "# Fill in the code in empty places to remove this erro\n",
    "# raise NotImplementedError(\"Student exercise: Fill in the code in empty places to remove this error\")\n",
    "#################################################\n",
    "\n",
    "# Display a histogram of the Pandas DataFrame 'df'\n",
    "df_features  # hint: invoke hist function here\n",
    "\n",
    "# Output the sum of null values for each column in 'df'\n",
    "df_features   # hint: invoke isnull function here and then invoke sum over"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "EQuT_FPO4T6P",
   "metadata": {
    "colab_type": "text",
    "execution": {}
   },
   "source": [
    "[*Click for solution*](https://github.com/NeuromatchAcademy/course-content/tree/main//tutorials/W2D5_ClimateResponse-AdaptationImpact/solutions/W2D5_Tutorial2_Solution_146bf19c.py)\n",
    "\n",
    "*Example output:*\n",
    "\n",
    "<img alt='Solution hint' align='left' width=1613.0 height=1604.0 src=https://raw.githubusercontent.com/NeuromatchAcademy/course-content/main/tutorials/W2D5_ClimateResponse-AdaptationImpact/static/W2D5_Tutorial2_Solution_146bf19c_1.png>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21bdc6b4",
   "metadata": {
    "execution": {}
   },
   "source": [
    "The above histograms show the number of data points that have the value given on the x-axis. As we can see, there is some missing data as well, particularly some of the NDVI measures. \n",
    "So far we have only been looking at the enviornmental data. Let's load the corresponding weekly dengue fever cases as well. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "FqcYp2yRhOAc",
   "metadata": {
    "execution": {}
   },
   "source": [
    "---\n",
    "## Section 1.4:  Load and Visualise the corresponding weekly dengue fever cases \n",
    "---\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9uCmTha48dY-",
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# Reading a CSV file named \"dengue_labels_train.csv\" and saving the data into a pandas DataFrame named \"df_dengue\".\n",
    "# The file path is specified as an absolute path to a Google Drive folder.\n",
    "labels_fname = \"dengue_labels_train.csv\"\n",
    "if not os.path.exists(labels_fname):\n",
    "    url = \"https://osf.io/6nw9x/download\"\n",
    "    labels_fname = pooch.retrieve(url, known_hash=None)\n",
    "df_labels = pd.read_csv(labels_fname)\n",
    "\n",
    "# Displaying the contents of the DataFrame named \"df_dengue\".\n",
    "# This is useful for verifying that the data was read correctly.\n",
    "df_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6Dq4k8mI4fO",
   "metadata": {
    "execution": {}
   },
   "source": [
    "---\n",
    "## Section 1.5 Visualise the weekly dangue fever cases \n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1M2cMCvkgyiD",
   "metadata": {
    "execution": {}
   },
   "source": [
    "### Coding Exercise 1.5: Visualise weekly dangue fever cases \n",
    "For this exercise, you have to visualise the data. You can start with ploting a histogram of the case numbers\n",
    "\n",
    "*Exercise Objective*:  \n",
    "1. Plot a histogram of the case numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Qr3PaKJKm7yL",
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "#################################################\n",
    "## TODO for students:\n",
    "# Fill in the code in empty places to remove this erro\n",
    "# raise NotImplementedError(\"Student exercise: Fill in the code in empty places to remove this error\")\n",
    "#################################################\n",
    "\n",
    "# Display a histogram of the 'total_cases' column in the 'df_dengue' DataFrame\n",
    "  #todo...        # Write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vGdyLzTOYNsX",
   "metadata": {
    "colab_type": "text",
    "execution": {}
   },
   "source": [
    "[*Click for solution*](https://github.com/NeuromatchAcademy/course-content/tree/main//tutorials/W2D5_ClimateResponse-AdaptationImpact/solutions/W2D5_Tutorial2_Solution_a4db964c.py)\n",
    "\n",
    "*Example output:*\n",
    "\n",
    "<img alt='Solution hint' align='left' width=561.0 height=433.0 src=https://raw.githubusercontent.com/NeuromatchAcademy/course-content/main/tutorials/W2D5_ClimateResponse-AdaptationImpact/static/W2D5_Tutorial2_Solution_a4db964c_1.png>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bmazJeh6n4HL",
   "metadata": {
    "execution": {}
   },
   "source": [
    "What did you see? In the next exercise we explore the data more and try to find some trends in the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "GQgRG63VkQIM",
   "metadata": {
    "execution": {}
   },
   "source": [
    "### Coding Exercise 1.6: Explore this data a little more. \n",
    "In this exercise, you have to explore this data a little more. For your help some objectives are given but you can try out more as well\n",
    "\n",
    "*Exercise Objective*: \n",
    "1. Plot total cases as a function of year\n",
    "2. Plot total cases as a function of the week of the year\n",
    "3. Plot total cases as two separate histograms, one for each of the cities.\n",
    "\n",
    "Play with data and observe the trend in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "RsdGCbDw-NlG",
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "#################################################\n",
    "## TODO for students:\n",
    "# Fill in the code in empty places to remove this error\n",
    "# raise NotImplementedError(\"Student exercise: Fill in the code in empty places to remove this error\")\n",
    "################################################\n",
    "\n",
    "# Creating a scatter plot of 'year' vs 'total_cases' in the DataFrame 'df_dengue'.\n",
    "df_labels.plot.scatter('year','total_cases')\n",
    "\n",
    "# Creating a scatter plot of 'weekofyear' vs 'total_cases' in the DataFrame 'df_dengue'.\n",
    "# df_dengue = ...\n",
    "\n",
    "# Creating a new DataFrame named 'new' that contains only the columns 'total_cases' and 'city' from 'df_dengue'.\n",
    "new = ...  # hint:you can use .copy()\n",
    "\n",
    "# Creating histograms of the 'total_cases' column in 'new' separated by the values in the 'city' column.\n",
    "# new...."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aC3XX1S8-Din",
   "metadata": {
    "colab_type": "text",
    "execution": {}
   },
   "source": [
    "[*Click for solution*](https://github.com/NeuromatchAcademy/course-content/tree/main//tutorials/W2D5_ClimateResponse-AdaptationImpact/solutions/W2D5_Tutorial2_Solution_7df3981d.py)\n",
    "\n",
    "*Example output:*\n",
    "\n",
    "<img alt='Solution hint' align='left' width=573.0 height=432.0 src=https://raw.githubusercontent.com/NeuromatchAcademy/course-content/main/tutorials/W2D5_ClimateResponse-AdaptationImpact/static/W2D5_Tutorial2_Solution_7df3981d_1.png>\n",
    "\n",
    "<img alt='Solution hint' align='left' width=572.0 height=432.0 src=https://raw.githubusercontent.com/NeuromatchAcademy/course-content/main/tutorials/W2D5_ClimateResponse-AdaptationImpact/static/W2D5_Tutorial2_Solution_7df3981d_2.png>\n",
    "\n",
    "<img alt='Solution hint' align='left' width=568.0 height=436.0 src=https://raw.githubusercontent.com/NeuromatchAcademy/course-content/main/tutorials/W2D5_ClimateResponse-AdaptationImpact/static/W2D5_Tutorial2_Solution_7df3981d_3.png>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ucPP9sGWo0Nc",
   "metadata": {
    "execution": {}
   },
   "source": [
    "### Think! : What trends do you see?\n",
    "\n",
    "Let's delve deeper into the data. What trends do you observe?\n",
    "Engage in a discussion with your group and see if anyone has noticed a trend that you may have missed.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "OJfHILMlkRtg",
   "metadata": {
    "execution": {}
   },
   "source": [
    "---\n",
    "# **Section 2 : Regression on Dengue Fever Dataset**\n",
    "---\n",
    "In the previous section, we explored the Dengue dataset. In this section, we will apply linear regression to this dataset.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "V2qPY6gYuetd",
   "metadata": {
    "execution": {}
   },
   "source": [
    "Since we have already explored and visualised the dataset we are ready to train a model.\n",
    "\n",
    "We will start by preprocessing the data and defining a model to predict cases of dengue fever.\n",
    "\n",
    "In the case of predicting dengue fever the environmental variables are the independent variables (or regressors), while number of dengue fever cases is the dependent variable that we want to predict."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "erqZu0VckSJc",
   "metadata": {
    "execution": {}
   },
   "source": [
    "---\n",
    "## Section 2.1:  Data Preprocessing\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "SYvfpa8B8S_D",
   "metadata": {
    "execution": {}
   },
   "source": [
    "\n",
    "In climate science, data is often incomplete or missing, and it's important to handle such missing values before using the data for prediction or analysis. In this case, we are replacing the missing values with median values and removing unnecessary columns that won't be used in our prediction.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Data Cleaning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Data Cleaning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  Data Cleaning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "######  Data Cleaning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#######  Data Cleaning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "########  Data Cleaning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#########  Data Cleaning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##########  Data Cleaning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###########  Data Cleaning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "############  Data Cleaning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#############  Data Cleaning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##############  Data Cleaning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "qCBHC6U78sL3",
   "metadata": {
    "cellView": "form",
    "execution": {},
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "#@title Data Cleaning\n",
    "\n",
    "# Drop columns 'city', 'year', and 'week_start_date' from the 'df' dataframe to create a new dataframe 'df_cleaned'\n",
    "df_cleaned = df_features.drop(['city','year','week_start_date'],axis=1)\n",
    "\n",
    "# Check for null and missing values\n",
    "print(\"Null and missing value before cleaning\" , df_cleaned.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "YrRfK2T8MW-m",
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# Replace missing values with median\n",
    "df_cleaned = df_cleaned.fillna(df_cleaned.median())\n",
    "\n",
    "# Check for null and missing values after replacing\n",
    "print(df_cleaned.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Rauj0P6EbNmz",
   "metadata": {
    "execution": {}
   },
   "source": [
    "To build a model with the climate data, we need to divide it into a training and test set to ensure that the model works well on held-out data. This is important because, as we have seen, evaluating the model on the exact data it was trained on can be misleading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "SvS4eEF1f6uL",
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "df_cleaned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###   Train-Test Split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####   Train-Test Split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####   Train-Test Split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "######   Train-Test Split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#######   Train-Test Split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "########   Train-Test Split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#########   Train-Test Split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##########   Train-Test Split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###########   Train-Test Split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "############   Train-Test Split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#############   Train-Test Split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##############   Train-Test Split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "M0XopmfSu7Ek",
   "metadata": {
    "cellView": "form",
    "execution": {},
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "#@title  Train-Test Split\n",
    "\n",
    "# Select the 'total_cases' column from the 'df_dengue' dataframe and assign it to the variable 'cases'\n",
    "cases = df_labels['total_cases']\n",
    "\n",
    "# Create a boolean mask with random values for each element in 'cases'\n",
    "np.random.seed(145) #setting the random seed ensures we are all using the same train/test split\n",
    "mask = np.random.rand(len(cases)) < 0.8   #this will use 80% of the data to train and 20% to test\n",
    "\n",
    "# Create two new dataframes from the 'df_cleaned' dataframe based on the boolean mask\n",
    "df_cleaned_train = df_cleaned[mask]\n",
    "df_cleaned_test = df_cleaned[~mask]\n",
    "\n",
    "# Create two new arrays from the 'cases' array based on the boolean mask\n",
    "cases_train = cases[mask]\n",
    "cases_test = cases[~mask]\n",
    "\n",
    "print(\" 80% of the data is split into the training set and remaining 20% into the test set.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "YNv05ncSfxzi",
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "df_cleaned_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ncAk7HbCh7gR",
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "cases_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "zPeztNPTwRKx",
   "metadata": {
    "execution": {}
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "## Section 2.2 Fitting Model and Analyzing Results \n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "kw987L7PkSJd",
   "metadata": {
    "execution": {}
   },
   "source": [
    "### Coding Exercise 2.2: Implement regression on Dengue Fever dataset and evaluate the performance\n",
    "For this exercise, use what you learned in the previous tutorials to train a linear regression model on the training data and evalute its performance. Evaluate its performance on the training data and the test data. Look specifically at the difference between predicted values and true values on the test set. \n",
    "\n",
    "*Exercise Objective*:\n",
    "1. Train a linear regression model on the training data\n",
    "2. Evaluate the performance of the model on both training and test data.\n",
    "3. Look specifically at the difference between predicted values and true values on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2boskgTN8REW",
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "#################################################\n",
    "## TODO for students:\n",
    "# Fill in the code in empty places to remove this error\n",
    "# raise NotImplementedError(\"Student exercise: Fill in the code in empty places to remove this error\")\n",
    "#################################################\n",
    "\n",
    "\n",
    "# Create a new instance of the LinearRegression class\n",
    "reg_model = ... # add code here\n",
    "\n",
    "# Train the model on the training data i.e on df_cleaned_train,cases_train\n",
    "...  # add code here\n",
    "\n",
    "# Print the R^2 score of the trained model on the training data\n",
    "print('r^2 on training data is: ')\n",
    "# print(reg_model.score(...,...))\n",
    "\n",
    "# Print the R^2 score of the trained model on the test data\n",
    "print('r^2 on test data is: ')\n",
    "# print(reg_model.score(...,...))\n",
    "\n",
    "# Create a scatter plot of the predicted values vs. the actual values for the test data\n",
    "# plt.scatter(...,reg_model.predict(df_cleaned_test))\n",
    "\n",
    "\n",
    "# Add axis labels to the scatter plot\n",
    "plt.xlabel('Actual Number of Dengue Cases')\n",
    "plt.ylabel('Predicted Number of Dengue Cases')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "F4d369IY_nc8",
   "metadata": {
    "colab_type": "text",
    "execution": {}
   },
   "source": [
    "[*Click for solution*](https://github.com/NeuromatchAcademy/course-content/tree/main//tutorials/W2D5_ClimateResponse-AdaptationImpact/solutions/W2D5_Tutorial2_Solution_0afb0959.py)\n",
    "\n",
    "*Example output:*\n",
    "\n",
    "<img alt='Solution hint' align='left' width=587.0 height=453.0 src=https://raw.githubusercontent.com/NeuromatchAcademy/course-content/main/tutorials/W2D5_ClimateResponse-AdaptationImpact/static/W2D5_Tutorial2_Solution_0afb0959_2.png>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eTro7UedNRmk",
   "metadata": {
    "execution": {}
   },
   "source": [
    "<details>\n",
    "<summary> <font color='orangered'>Click here description of plot  </font></summary>\n",
    "\n",
    "This code trains a linear regression model on a dataset and evaluates its performance on both the training and test data.\n",
    "\n",
    "The scatter plot generated at the end of the code shows the predicted values vs. the actual values for the test data. Each point in the scatter plot represents a single data point in the test set. The horizontal axis represents the actual number of dengue cases, while the vertical axis represents the predicted number of dengue cases.\n",
    "\n",
    "If the predicted values are close to the actual values, the scatter plot will show a diagonal line where the points cluster around. On the other hand, if the predicted values are far from the actual values, the scatter plot will be more spread out and may show a more random pattern of points.\n",
    "\n",
    "By visually inspecting the scatter plot and looking at the r^2, we can get an idea of how well the model is performing and how accurate its predictions are. How well does the model do?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Evaluating the performance of the model using metrics such as mean absolute error (MAE) and mean squared error (MSE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  Evaluating the performance of the model using metrics such as mean absolute error (MAE) and mean squared error (MSE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "######  Evaluating the performance of the model using metrics such as mean absolute error (MAE) and mean squared error (MSE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#######  Evaluating the performance of the model using metrics such as mean absolute error (MAE) and mean squared error (MSE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "########  Evaluating the performance of the model using metrics such as mean absolute error (MAE) and mean squared error (MSE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#########  Evaluating the performance of the model using metrics such as mean absolute error (MAE) and mean squared error (MSE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##########  Evaluating the performance of the model using metrics such as mean absolute error (MAE) and mean squared error (MSE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###########  Evaluating the performance of the model using metrics such as mean absolute error (MAE) and mean squared error (MSE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "############  Evaluating the performance of the model using metrics such as mean absolute error (MAE) and mean squared error (MSE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#############  Evaluating the performance of the model using metrics such as mean absolute error (MAE) and mean squared error (MSE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##############  Evaluating the performance of the model using metrics such as mean absolute error (MAE) and mean squared error (MSE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###############  Evaluating the performance of the model using metrics such as mean absolute error (MAE) and mean squared error (MSE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "BR4APm-zqPO9",
   "metadata": {
    "cellView": "form",
    "execution": {},
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "#@title Evaluating the performance of the model using metrics such as mean absolute error (MAE) and mean squared error (MSE)\n",
    "\n",
    "y_pred = reg_model.predict(df_cleaned_test)\n",
    "print('MAE:', mean_absolute_error(cases_test, y_pred))\n",
    "print('RMSE:', mean_squared_error(cases_test, y_pred,squared=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dKZf17NOWd-",
   "metadata": {
    "execution": {}
   },
   "source": [
    "<details>\n",
    "<summary> <font color='violet'>What is MAE and MSE   </font></summary>\n",
    "In addition to r^2, Mean Absolute Error (MAE) and Mean Squared Error (MSE) are both metrics used to evaluate the performance of a regression model. They both measure the difference between the predicted values and the actual values of the target variable.\n",
    "\n",
    "The MAE is calculated by taking the average of the absolute differences between the predicted and actual values:\n",
    "\\begin{align}\n",
    "MAE = \\frac{1}{n}\\sum_{i=1}^{n}|y_i - \\hat{y_i}|\n",
    "\\end{align}\n",
    "where $n$ is the number of samples, $y_i$ is the actual value of the target variable for sample $i$, and $\\hat{y}_i$ is the predicted value of the target variable for sample $i$.\n",
    "\n",
    "The RMSE is calculated by taking the square root of the average of the squared differences between the predicted and actual values:\n",
    "\\begin{align}\n",
    " RMSE = \\sqrt{\\frac{1}{n}\\sum_{i=1}^{n}(y_i - \\hat{y_i})^2}\n",
    "\\end{align} \n",
    "The main difference between MAE and RMSE is that RMSE gives more weight to larger errors, because the differences are squared. Therefore, if there are some large errors in the predictions, the MSE will be higher than the MAE.\n",
    "\n",
    "Both MAE and RMSE have the same unit of measurement as the target variable, and lower values indicate better model performance. However, the choice of which metric to use depends on the specific problem and the goals of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nMrfrggDkSJd",
   "metadata": {
    "execution": {}
   },
   "source": [
    "### Think! 2.2: What did you observe?\n",
    "\n",
    " Do you think the model performs well enough to be useful in anticipating dengue fever outbreaks? \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1LO0O5YkUsZB",
   "metadata": {
    "execution": {}
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "##(Bonus) Section 2.3 : Handling Different Scenarios\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Y6Pux46LWw7e",
   "metadata": {
    "execution": {}
   },
   "source": [
    "### Section 2.3.1: Handling Categorical Regressor \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "RNS2yeHewz7r",
   "metadata": {
    "execution": {}
   },
   "source": [
    "We chose to remove city as a regressor because it is not a numerical value and therefore does not fit as easily into the linear regression framework. However it is possible to include such categorical data. To do so, you need to turn the string variables representing cities into 'dummy variables', that is, numerical values that stand in for the categories. Here we can simply arbitrarily set one city to the value 0 and the other the value 1. See how including city impacts regression performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pIVU36FuB1cc",
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# Include city as a regressor by creating dummy variables for the 'city' column\n",
    "df_cleaned_city = pd.get_dummies(df_features[['city']], drop_first=True)\n",
    "df_cleaned_city.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Combine the cleaned data with the city dummy variables\n",
    "df_cleaned_combined = pd.concat([df_cleaned, df_cleaned_city], axis=1)\n",
    "\n",
    "# Split the data into training and test sets using a random mask\n",
    "np.random.seed(144)\n",
    "mask = np.random.rand(len(cases)) < 0.8\n",
    "df_cleaned_train = df_cleaned_combined[mask]\n",
    "df_cleaned_test = df_cleaned_combined[~mask]\n",
    "cases_train = cases[mask]\n",
    "cases_test = cases[~mask]\n",
    "\n",
    "# Train a linear regression model with city as a regressor\n",
    "reg_model_city = LinearRegression()\n",
    "reg_model_city.fit(df_cleaned_train, cases_train)\n",
    "\n",
    "# Print R-squared scores for the train and test sets\n",
    "print('R-squared on training data is: ', reg_model_city.score(df_cleaned_train, cases_train))\n",
    "print('R-squared on test data is: ', reg_model_city.score(df_cleaned_test, cases_test))\n",
    "\n",
    "# Create a scatter plot of the predicted values vs. the actual values for the test data\n",
    "plt.scatter(cases_test, reg_model_city.predict(df_cleaned_test))\n",
    "plt.xlabel('Actual number of dengue cases')\n",
    "plt.ylabel('Predicted number of dengue cases')\n",
    "plt.title('Predicted vs Actual number of dengue cases (with city as a regressor)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "AwjpUDzNTTwN",
   "metadata": {
    "execution": {}
   },
   "source": [
    "<details>\n",
    "<summary> <font color='orangered'>Click here description of plot  </font></summary>\n",
    "The plot generated is a scatter plot with the actual total cases on the x-axis and the predicted total cases on the y-axis. Each point on the plot represents a test data point. \n",
    "The accuracy of the model can also be evaluated numerically by computing metrics such as mean absolute error (MAE) and mean squared error (MSE), as well as the R-squared score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Evaluating the performance of the model using metrics such as mean absolute error (MAE) and root mean squared error (RMSE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  Evaluating the performance of the model using metrics such as mean absolute error (MAE) and root mean squared error (RMSE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "######  Evaluating the performance of the model using metrics such as mean absolute error (MAE) and root mean squared error (RMSE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#######  Evaluating the performance of the model using metrics such as mean absolute error (MAE) and root mean squared error (RMSE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "########  Evaluating the performance of the model using metrics such as mean absolute error (MAE) and root mean squared error (RMSE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#########  Evaluating the performance of the model using metrics such as mean absolute error (MAE) and root mean squared error (RMSE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##########  Evaluating the performance of the model using metrics such as mean absolute error (MAE) and root mean squared error (RMSE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###########  Evaluating the performance of the model using metrics such as mean absolute error (MAE) and root mean squared error (RMSE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "############  Evaluating the performance of the model using metrics such as mean absolute error (MAE) and root mean squared error (RMSE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#############  Evaluating the performance of the model using metrics such as mean absolute error (MAE) and root mean squared error (RMSE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##############  Evaluating the performance of the model using metrics such as mean absolute error (MAE) and root mean squared error (RMSE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###############  Evaluating the performance of the model using metrics such as mean absolute error (MAE) and root mean squared error (RMSE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "MaxjVAr7qoZe",
   "metadata": {
    "cellView": "form",
    "execution": {},
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "#@title Evaluating the performance of the model using metrics such as mean absolute error (MAE) and root mean squared error (RMSE)\n",
    "\n",
    "y_pred = reg_model_city.predict(df_cleaned_test)\n",
    "print('MAE:', mean_absolute_error(cases_test, y_pred))\n",
    "print('RMSE:', mean_squared_error(cases_test, y_pred, squared=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42hJ6JUTCMkG",
   "metadata": {
    "execution": {}
   },
   "source": [
    "Does including the city help the model predict cases?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "UJjPu06M-fAG",
   "metadata": {
    "execution": {}
   },
   "source": [
    "###  Section 2.3.2 : Handling Integer Valued Dependent Variable "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7OZbW4DpDtT5",
   "metadata": {
    "execution": {}
   },
   "source": [
    "In our simulated data, the dependent variable was real-valued and followed a normal distribution. Here, the weekly case numbers are integers and are better described by a [Poisson distribution](https://en.wikipedia.org/wiki/Poisson_distribution). Therefore, plain linear regression is not actually the most appropriate approach for this data. Rather, we should use a generalized linear model, or GLM, which is like linear regression, but includes an extra step that makes it more suited to handle Poisson data. Try to use [scikit-learn's Poisson GLM method](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.PoissonRegressor.html) on this data. Evaluate the performance o this model on all the same metrics as above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "-Ux5wOt-DZS-",
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# import PoissonRegressor from sklearn.linear_model\n",
    "from sklearn.linear_model import PoissonRegressor\n",
    "\n",
    "# create PoissonRegressor object\n",
    "poisson_reg = PoissonRegressor()\n",
    "\n",
    "# fit the PoissonRegressor model with training data\n",
    "poisson_reg.fit(df_cleaned_train, cases_train)\n",
    "\n",
    "# calculate r^2 score on training data\n",
    "print('r^2 on training data is: ')\n",
    "print(poisson_reg.score(df_cleaned_train, cases_train))\n",
    "\n",
    "# calculate r^2 score on test data\n",
    "print('r^2 on test data is: ')\n",
    "print(poisson_reg.score(df_cleaned_test, cases_test))\n",
    "\n",
    "# plot predicted values against test data\n",
    "plt.scatter(cases_test, poisson_reg.predict(df_cleaned_test))\n",
    "\n",
    "# add plot title and labels\n",
    "plt.title(\"Predicted Cases vs Actual Cases\")\n",
    "plt.xlabel(\"Actual Cases\")\n",
    "plt.ylabel(\"Predicted Cases\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ZDS3UirhTVhl",
   "metadata": {
    "execution": {}
   },
   "source": [
    "<details>\n",
    "<summary> <font color='orangered'>Click here description of plot  </font></summary>\n",
    "The plot generated is a scatter plot with the actual total cases on the x-axis and the predicted total cases on the y-axis. Each point on the plot represents a test data point."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Evaluating the performance of the model using metrics such as mean absolute error (MAE) and root mean squared error (RMSE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  Evaluating the performance of the model using metrics such as mean absolute error (MAE) and root mean squared error (RMSE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "######  Evaluating the performance of the model using metrics such as mean absolute error (MAE) and root mean squared error (RMSE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#######  Evaluating the performance of the model using metrics such as mean absolute error (MAE) and root mean squared error (RMSE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "########  Evaluating the performance of the model using metrics such as mean absolute error (MAE) and root mean squared error (RMSE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#########  Evaluating the performance of the model using metrics such as mean absolute error (MAE) and root mean squared error (RMSE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##########  Evaluating the performance of the model using metrics such as mean absolute error (MAE) and root mean squared error (RMSE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###########  Evaluating the performance of the model using metrics such as mean absolute error (MAE) and root mean squared error (RMSE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "############  Evaluating the performance of the model using metrics such as mean absolute error (MAE) and root mean squared error (RMSE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#############  Evaluating the performance of the model using metrics such as mean absolute error (MAE) and root mean squared error (RMSE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##############  Evaluating the performance of the model using metrics such as mean absolute error (MAE) and root mean squared error (RMSE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###############  Evaluating the performance of the model using metrics such as mean absolute error (MAE) and root mean squared error (RMSE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "O2q7OQNzq2he",
   "metadata": {
    "cellView": "form",
    "execution": {},
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "#@title Evaluating the performance of the model using metrics such as mean absolute error (MAE) and root mean squared error (RMSE)\n",
    "\n",
    "y_pred = poisson_reg.predict(df_cleaned_test)\n",
    "print('MAE:', mean_absolute_error(cases_test, y_pred))\n",
    "print('RMSE:', mean_squared_error(cases_test, y_pred, squared=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "C7Jl9oPkCs-P",
   "metadata": {
    "execution": {}
   },
   "source": [
    "### Think! 2.3: Performance of model\n",
    "\n",
    "Engage in discussion with your pod to share your observations from the additional changes above.\n",
    "- What did you observe?\n",
    "- Reflect on how different factors may affect the performance of the model.\n",
    "- Brainstorm as a group additional ways to improve the model's performance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "GjB_Kfmtkhd3",
   "metadata": {
    "execution": {}
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "# **Section 3 : Decision Trees** \n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ftQG5z97vhix",
   "metadata": {
    "execution": {}
   },
   "source": [
    "In the field of climate science, decision trees and random forests can be powerful tools for making predictions and analyzing complex data.\n",
    "\n",
    "A decision tree is a type of model that is constructed by recursively splitting the data based on the values of the input features. Each internal node in the tree represents a decision based on the value of a feature, and each leaf node represents a prediction. Decision trees are easy to interpret and can capture complex, nonlinear relationships in the data.\n",
    "\n",
    "Random forests are a type of ensemble model that combines multiple decision trees to make predictions. Each tree in the forest is trained on a random subset of the data, and the final prediction is the average of the predictions from all the trees. Random forests are particularly useful in climate science because they can handle high-dimensional data with many features and can capture both linear and nonlinear relationships.\n",
    "\n",
    "By using decision trees and random forests, climate scientists can make accurate predictions about a variety of climate-related variables, such as temperature, precipitation, and sea level rise. They can also gain insights into the complex relationships between different variables and identify important features that contribute to these relationships."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6HDz0Wae8BUQ",
   "metadata": {
    "execution": {}
   },
   "source": [
    " By training a Random Forest Model in this tutorial, we can better understand the relationship between climate variables and dengue fever cases, and potentially improve our ability to predict and prevent outbreaks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "UnpSMiiu8BUT",
   "metadata": {
    "execution": {}
   },
   "source": [
    "---\n",
    "## Section 3.1 Fitting Model and Analyzing Results \n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0C_hBsqj8BUT",
   "metadata": {
    "execution": {}
   },
   "source": [
    "Next, you will train a random forest regression model using scikit-learn's RandomForestRegressor class, with default hyperparameters. Use the documentation of the method [here](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html) to help you if needed. Evaluate the model's performance on the training and test data and make a scatter plot of predicted vs actual cases for the test data. \n",
    "Use `RandomForestRegressor()` which we already imported."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Data Cleaning on original raw data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Making sure we are working with cleaned data with the columns we want.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Data Cleaning on original raw data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Making sure we are working with cleaned data with the columns we want.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  Data Cleaning on original raw data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Making sure we are working with cleaned data with the columns we want.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "######  Data Cleaning on original raw data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Making sure we are working with cleaned data with the columns we want.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#######  Data Cleaning on original raw data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Making sure we are working with cleaned data with the columns we want.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "########  Data Cleaning on original raw data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Making sure we are working with cleaned data with the columns we want.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#########  Data Cleaning on original raw data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Making sure we are working with cleaned data with the columns we want.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##########  Data Cleaning on original raw data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Making sure we are working with cleaned data with the columns we want.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###########  Data Cleaning on original raw data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Making sure we are working with cleaned data with the columns we want.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "############  Data Cleaning on original raw data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Making sure we are working with cleaned data with the columns we want.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#############  Data Cleaning on original raw data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Making sure we are working with cleaned data with the columns we want.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##############  Data Cleaning on original raw data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Making sure we are working with cleaned data with the columns we want.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9L8mgENYji3w",
   "metadata": {
    "cellView": "form",
    "execution": {},
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "#@title Data Cleaning on original raw data\n",
    "#@markdown Making sure we are working with cleaned data with the columns we want.\n",
    "# Drop non-numeric columns and replace missing values\n",
    "df_cleaned = df_features.drop(['city', 'year', 'week_start_date'], axis=1)\n",
    "df_cleaned = df_cleaned.fillna(df_cleaned.median())\n",
    "\n",
    "# Extract the target variable (total_cases)\n",
    "cases = df_labels['total_cases']\n",
    "\n",
    "# Split the data into training and testing sets using a random mask\n",
    "np.random.seed(145) #setting the random seed ensures we are all using the same train/test split\n",
    "mask = np.random.rand(len(cases)) < 0.8   # use 80% of the data for training\n",
    "\n",
    "df_cleaned_train = df_cleaned[mask]\n",
    "df_cleaned_test = df_cleaned[~mask]\n",
    "\n",
    "cases_train = cases[mask]\n",
    "cases_test = cases[~mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "B37Yys8Y8BUU",
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "#################################################\n",
    "## TODO for students:\n",
    "# Fill in the code in empty places to remove this error\n",
    "# raise NotImplementedError(\"Student exercise: Fill in the code in empty places to remove this error\")\n",
    "#################################################\n",
    "\n",
    "# to_remove solution\n",
    "\n",
    "# Train a random forest regression model\n",
    "\n",
    "rf =  ...      # hint : use the RandomForestRegressor we imported earlier\n",
    "# rf.fit(..., ....) #todo : run fit on 'df_cleaned_train' and 'cases_train'\n",
    "\n",
    "# Evaluate the model's performance on the training and testing data\n",
    "print('R^2 on training data is: ')\n",
    "#print(rf.score(..,...)) #todo : calculate accuracy hint : by calling rf.score() on 'df_cleaned_train' and 'cases_train'\n",
    "\n",
    "print('R^2 on test data is: ')\n",
    "print(...)  # todo: #todo : calculate accuracy; hint : by calling rf.score() on 'df_cleaned_test' and 'cases_test'\n",
    "\n",
    "\n",
    "# uncommnet the code below to check wether your implementation is correct or not\n",
    "# Plot the predicted vs. actual total cases on the test data\n",
    "# plt.scatter(cases_test, rf.predict(df_cleaned_test))\n",
    "# plt.xlabel('Actual Total Cases')\n",
    "# plt.ylabel('Predicted Total Cases')\n",
    "# plt.title('Random Forest Regression')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "uX736VJs8BUU",
   "metadata": {
    "colab_type": "text",
    "execution": {}
   },
   "source": [
    "[*Click for solution*](https://github.com/NeuromatchAcademy/course-content/tree/main//tutorials/W2D5_ClimateResponse-AdaptationImpact/solutions/W2D5_Tutorial2_Solution_658d1bf5.py)\n",
    "\n",
    "*Example output:*\n",
    "\n",
    "<img alt='Solution hint' align='left' width=585.0 height=453.0 src=https://raw.githubusercontent.com/NeuromatchAcademy/course-content/main/tutorials/W2D5_ClimateResponse-AdaptationImpact/static/W2D5_Tutorial2_Solution_658d1bf5_1.png>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "N-GIWnvNPwDk",
   "metadata": {
    "execution": {}
   },
   "source": [
    "<details>\n",
    "<summary> <font color='orangered'>Click here description of plot  </font></summary>\n",
    "The plot generated is a scatter plot with the actual total cases on the x-axis and the predicted total cases on the y-axis. Each point on the plot represents a test data point. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Evaluating the performance of the model using metrics such as mean absolute error (MAE) and root mean squared error (MSE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Evaluating the performance of the model using metrics such as mean absolute error (MAE) and root mean squared error (MSE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Evaluating the performance of the model using metrics such as mean absolute error (MAE) and root mean squared error (MSE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Evaluating the performance of the model using metrics such as mean absolute error (MAE) and root mean squared error (MSE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Evaluating the performance of the model using metrics such as mean absolute error (MAE) and root mean squared error (MSE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Evaluating the performance of the model using metrics such as mean absolute error (MAE) and root mean squared error (MSE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Evaluating the performance of the model using metrics such as mean absolute error (MAE) and root mean squared error (MSE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Evaluating the performance of the model using metrics such as mean absolute error (MAE) and root mean squared error (MSE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Evaluating the performance of the model using metrics such as mean absolute error (MAE) and root mean squared error (MSE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Evaluating the performance of the model using metrics such as mean absolute error (MAE) and root mean squared error (MSE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Evaluating the performance of the model using metrics such as mean absolute error (MAE) and root mean squared error (MSE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Evaluating the performance of the model using metrics such as mean absolute error (MAE) and root mean squared error (MSE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "StIShdNq8BUV",
   "metadata": {
    "cellView": "form",
    "execution": {},
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "#@markdown Evaluating the performance of the model using metrics such as mean absolute error (MAE) and root mean squared error (MSE)\n",
    "\n",
    "y_pred = rf.predict(df_cleaned_test)\n",
    "print('MAE:', mean_absolute_error(cases_test, y_pred))\n",
    "print('RMSE:', mean_squared_error(cases_test, y_pred, squared=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "xoZ3jPdk8BUV",
   "metadata": {
    "execution": {}
   },
   "source": [
    "### Think! 3.1: Reflecting on the performance \n",
    "Please think and discuss the following questions with your pod members:\n",
    "\n",
    "- How does the performance of the random forest model compare to that of the linear regression model?\n",
    "- How does the performance on the test data compare to the performance on the training data?\n",
    "- What could be the reason behind performing well on the training data but poorly on the test data? Hint: Look up 'overfitting'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "GCDqyjt18BUV",
   "metadata": {
    "execution": {}
   },
   "source": [
    "\n",
    "\n",
    "```\n",
    "#  to_remove explanation\n",
    "\n",
    "* The random forest model generally performs better than the linear regression model as it can capture non-linear relationships between features and target.\n",
    "* The low performance of the model on the test set might be due to the model learning the noise in the training data instead of the underlying patterns.\n",
    "* Overfitting is the term for good training performance but poor test performance,where the model fits the training data too closely and fails to generalize to new data.\n",
    "* Solutions to handle overfitting include reducing model complexity, increasing dataset size, using regularization, or cross-validation. Ensemble models such as random forests also do inherently help control overfitting by averaging many different models\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "VX-uYtUS8BUV",
   "metadata": {
    "execution": {}
   },
   "source": [
    "---\n",
    "## Section 3.2 :  Looking at Feature Importance\n",
    "---\n",
    "When we train a model to predict an outcome, it's important to understand which inputs to the model are most important in driving that prediction. This is where 'feature importance' methods come in.\n",
    "\n",
    "One way to measure feature importance is by using the permutation method. This involves randomly shuffling the values of a feature and testing the performance of the model with these permuted values. The amount that the model performance decreases when the feature's values are permuted can provide an indication of how important it is.\n",
    "\n",
    "For climate scientists, understanding feature importance can help identify key variables that contribute to predicting important outcomes, such as temperature or precipitation patterns.\n",
    "\n",
    "Thankfully, Sci-kit learn has a method that implements permutation importance, and outputs a normalized measure of how much each feature impacts performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " *Execute this cell to enable the plotting function to be used for plotting performance of our model in next cell: `plot_feature_importance`*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " *Execute this cell to enable the plotting function to be used for plotting performance of our model in next cell: `plot_feature_importance`*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " *Execute this cell to enable the plotting function to be used for plotting performance of our model in next cell: `plot_feature_importance`*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " *Execute this cell to enable the plotting function to be used for plotting performance of our model in next cell: `plot_feature_importance`*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " *Execute this cell to enable the plotting function to be used for plotting performance of our model in next cell: `plot_feature_importance`*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " *Execute this cell to enable the plotting function to be used for plotting performance of our model in next cell: `plot_feature_importance`*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " *Execute this cell to enable the plotting function to be used for plotting performance of our model in next cell: `plot_feature_importance`*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " *Execute this cell to enable the plotting function to be used for plotting performance of our model in next cell: `plot_feature_importance`*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " *Execute this cell to enable the plotting function to be used for plotting performance of our model in next cell: `plot_feature_importance`*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " *Execute this cell to enable the plotting function to be used for plotting performance of our model in next cell: `plot_feature_importance`*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " *Execute this cell to enable the plotting function to be used for plotting performance of our model in next cell: `plot_feature_importance`*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " *Execute this cell to enable the plotting function to be used for plotting performance of our model in next cell: `plot_feature_importance`*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afXyxUfgdM67",
   "metadata": {
    "cellView": "form",
    "execution": {},
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "#@markdown *Execute this cell to enable the plotting function to be used for plotting performance of our model in next cell: `plot_feature_importance`*\n",
    "\n",
    "def plot_feature_importance(perm_feat_imp):\n",
    "    # Increase the size of the plot for better readability\n",
    "    plt.figure(figsize=(12, 8))\n",
    "\n",
    "    # Plot the feature importance with error bars in navy blue color\n",
    "    plt.errorbar(np.arange(len(df_cleaned.columns)), perm_feat_imp['importances_mean'], perm_feat_imp['importances_std'], fmt='o', capsize=5, markersize=5, color='navy')\n",
    "\n",
    "    # Set the x-axis and y-axis labels and title\n",
    "    plt.xlabel('Features', fontsize=14)\n",
    "    plt.ylabel('Importance', fontsize=14)\n",
    "    plt.title('Feature Importance Plot', fontsize=16)\n",
    "\n",
    "    # Rotate the x-axis labels for better readability\n",
    "    plt.xticks(np.arange(len(df_cleaned.columns)), df_cleaned.columns, rotation=45, ha='right', fontsize=12)\n",
    "\n",
    "    # Add gridlines for better visualization\n",
    "    plt.grid(True, axis='y', linestyle='--')\n",
    "\n",
    "    # Add a color map for better visualization\n",
    "    # The color of each bar represents the relative feature importance value\n",
    "    colors = cm.Blues(perm_feat_imp['importances_mean'] / perm_feat_imp['importances_mean'].max())\n",
    "    plt.bar(np.arange(len(df_cleaned.columns)), perm_feat_imp['importances_mean'], color=colors)\n",
    "\n",
    "    # Display the plot\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "LuqdCv4FdM68",
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# Plot the feature importance of each input to the model\n",
    "\n",
    "# Import the permutation_importance function from the sklearn.inspection module\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "# Use permutation_importance to calculate the feature importances of the trained random forest model\n",
    "# df_cleaned_test contains the preprocessed test dataset, cases_test contains the actual number of dengue fever cases in the test dataset\n",
    "# n_repeats specifies how many times the feature importances are calculated for each feature\n",
    "# random_state is used to seed the random number generator for reproducibility\n",
    "perm_feat_imp = permutation_importance(rf, df_cleaned_test, cases_test,\n",
    "                           n_repeats=10,\n",
    "                           random_state=0)\n",
    "\n",
    "# Create a plot of the feature importances\n",
    "plot_feature_importance(perm_feat_imp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "VTbaHX2S8BUW",
   "metadata": {
    "execution": {}
   },
   "source": [
    "<details>\n",
    "<summary> <font color='orangered'>Click here for description of plot 📊 </font></summary>\n",
    "\n",
    "The plot generated is a feature importance plot that provides insights into the importance of different features in predicting the target variable. Let's break down the key elements and address the specific issues raised.\n",
    "\n",
    "1. Feature Importance Representation:\n",
    "- Each bar in the plot represents a feature from the dataset.\n",
    "- The color and height of each bar represents the relative feature importance value.\n",
    "- Darker shades of blue/higher values indicate higher importance\n",
    "- Specifically, importance is measured as the decrease in performance that comes from permuting that feature.\n",
    "\n",
    "2. Error Bars and Variability:\n",
    "- The error bars present around each feature's bar represent the variability in importance values.\n",
    "- They indicate the uncertainty or variability in the importance estimates calculated through repeated permutations.\n",
    "- A longer error bar suggests higher variability, meaning the importance value for that feature may change significantly with different permutations.\n",
    "- Conversely, a shorter error bar indicates lower variability, indicating that the importance value is relatively stable and less influenced by random permutations.\n",
    "\n",
    "Understanding the feature importance plot empowers us to identify the most influential factors within our dataset. By recognizing these crucial features, we gain deeper insights into the underlying relationships within climate science data. This knowledge is invaluable for further analysis and informed decision-making processes within our field.\n",
    "\n",
    "It's important to note that the interpretation of feature importance can vary depending on the dataset and modeling technique employed. To gain a comprehensive understanding of feature importance analysis in the context of climate science, it is advisable to consult domain experts and explore additional resources tailored to your specific interests.\n",
    "\n",
    "By delving into the world of feature importance, we unlock the potential to unravel the intricate dynamics of our climate science data and make meaningful contributions to this fascinating field of study.\n",
    "\n",
    " </summary>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "EJ1y4x4X8BUW",
   "metadata": {
    "execution": {}
   },
   "source": [
    "### Think! 3.2 : Reflection on importance 🧠💭\n",
    "Please think and discuss the following questions with your pod members:\n",
    "\n",
    "- Which features were most important?\n",
    "- Why do you think these features are important?\n",
    "- Do you think understanding the importance of the different features could help you make a better model?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "IFZVBmzu8BUX",
   "metadata": {
    "execution": {}
   },
   "source": [
    "\n",
    "---\n",
    "## (Bonus⚡) Section 3.3: Comparing Feature Importance Methods\n",
    "\n",
    "The Random Forest Regression model also has a built-in estimation of feature importance. This estimation comes directly from how the decision trees are trained; specifically, it is a measure of how useful the feature is at splitting the data averaged across all nodes and trees. We can access these values directly from the trained model.\n",
    "\n",
    "Different methods of estimating feature importance can come to different conclusions and may have different biases. Therefore it is good to compare estimations across methods. How do these two methods compare? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "i2-RQwIw8BUX",
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# Set the figure size for better readability\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Create a bar chart of the feature importances returned by the random forest model\n",
    "plt.bar(np.arange(len(rf.feature_importances_)), rf.feature_importances_, color='navy')\n",
    "\n",
    "# Set the x-axis and y-axis labels and title\n",
    "plt.xlabel('Features', fontsize=14)\n",
    "plt.ylabel('Importance', fontsize=14)\n",
    "plt.title('Feature Importance Plot', fontsize=16)\n",
    "\n",
    "# Rotate the x-axis labels for better readability\n",
    "plt.xticks(np.arange(len(df_cleaned.columns)), df_cleaned.columns, rotation=45, ha='right', fontsize=12)\n",
    "\n",
    "# Set the y-axis limit to better visualize the differences in feature importance\n",
    "plt.ylim(0, rf.feature_importances_.max() * 1.1)\n",
    "\n",
    "# Add gridlines for better visualization\n",
    "plt.grid(True, axis='y', linestyle='--')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cXiY9CWU8BUX",
   "metadata": {
    "execution": {}
   },
   "source": [
    "\n",
    "<details>\n",
    "<summary> <font color='orangered'>Click here for description of plot </font></summary>\n",
    "\n",
    "The bar chart displays the feature importances returned by the random forest model. Each bar represents the relative importance of each feature in predicting the number of dengue fever cases in the preprocessed dataset. The y-axis represents the importance of the features, while the x-axis displays the name of the features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Rod5BrQakSJf",
   "metadata": {
    "execution": {}
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "# Summary\n",
    "\n",
    "In these tutorials, we explored various methods of analyzing the Dengue Fever dataset from a climate science perspective. We started by using pandas to handle the data and visualizing trends and anomalies. Next, we applied linear regression to model the data and handle categorical and integer-valued data. Finally, we applied random forest regression to improve the performance of our model and learned about feature importance. Overall, learners gained practical experience in using different modeling techniques to analyze and make predictions about real-world climate data. \n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ytSWAGmQ8BUY",
   "metadata": {
    "execution": {}
   },
   "source": [
    "#Extra Exercises or Project Ideas\n",
    "\n",
    "1. Try experimenting with different hyperparameters for the random forest model, such as n_estimators, max_depth, and min_samples_leaf. How do these hyperparameters affect the performance of the model? \n",
    "\n",
    "2. Try using a different machine learning algorithm to predict the number of Dengue fever cases, such as a support vector machine. How does the performance of these algorithms compare to the random forest model?\n",
    "\n",
    "3. Try using a different dataset to predict the number of cases of a different disease or health condition. How does the preprocessing and modeling process differ for this dataset compared to the Dengue fever dataset?\n",
    "\n",
    "4. Try visualizing the decision tree of the random forest model using the plot_tree function of the sklearn package. What insights can you gain from the visualization of the decision tree?\n",
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "BCXJHHHy9ZU-",
   "metadata": {
    "execution": {}
   },
   "source": [
    "\n",
    "\n",
    "<p align='right'><font color='gree'>Congratulations!</font> 🎉  You have reached the end of Tutorial 2!!</p>"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "W2D5_Tutorial2",
   "provenance": [],
   "toc_visible": true
  },
  "kernel": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3 (pangeo)",
   "language": "python",
   "name": "pangeo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}