{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/ClimateMatchAcademy/course-content/blob/main/tutorials/W1D2_StateoftheClimateOceanandAtmosphereReanalysis/student/W1D2_Tutorial2.ipynb) Â  <a href=\"https://kaggle.com/kernels/welcome?src=https://raw.githubusercontent.com/ClimateMatchAcademy/course-content/main/tutorials/W1D2_StateoftheClimateOceanandAtmosphereReanalysis/student/W1D2_Tutorial2.ipynb\" target=\"_blank\"><img alt=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "# **Tutorial 2: A Lot of Weather Makes Climate - Exploring the ERA5 Reanalysis**\n",
    "\n",
    "**Week 1, Day 2, Ocean-Atmosphere Reanalysis**\n",
    "\n",
    "__Content creators:__ Momme Hell\n",
    "\n",
    "**Content reviewers:** Katrina Dobson, Danika Gupta, Maria Gonzalez, Will Gregory, Nahid Hasan, Sherry Mi, Beatriz Cosenza Muralles, Jenna Pearson, Chi Zhang, Ohad Zivan\n",
    "\n",
    "**Content editors:** Jenna Pearson, Chi Zhang, Ohad Zivan\n",
    "\n",
    "**Production editors:** Wesley Banfield, Jenna Pearson, Chi Zhang, Ohad Zivan\n",
    "\n",
    "**Our 2023 Sponsors:** NASA TOPS and Google DeepMind"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {},
    "tags": []
   },
   "source": [
    "# Tutorial Objectives\n",
    "\n",
    "In the previous tutorial, we learned about ENSO, which is a specific atmosphere-ocean dynamical phenomena. You will now examine the atmosphere and the ocean systems more generally.\n",
    "\n",
    "In this tutorial, you will learn to work with reanalysis data. These data combine observations and models of the Earth system, and are a critical tool for weather and climate science. You will first utilize two methods to access a specific reanalysis dataset (ECMWF's ERA5; through [PO.DAAC](https://podaac.jpl.nasa.gov/) and through the web Copernicus API). You will then select and mask a region of interest, investigating how important climate variables change on medium length timescales (hours to months) within this region.\n",
    "\n",
    "By the end of this tutorial, you will be able to:\n",
    "- Access and select reanalysis data of cliamtically-important variables\n",
    "- Plot maps to explore changes on various time scales.\n",
    "- Compute and compare timeseries of different variables from reanalysis data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {},
    "tags": []
   },
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "colab"
    ]
   },
   "outputs": [],
   "source": [
    "# installations ( uncomment and run this cell ONLY when using google colab or kaggle )\n",
    "\n",
    "# !pip install pythia_datasets\n",
    "# !pip install cartopy\n",
    "# !pip install geoviews\n",
    "\n",
    "# !pip install boto3 --quiet\n",
    "# !pip install intake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "both",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "from intake import open_catalog\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import xarray as xr\n",
    "import fsspec\n",
    "import numpy as np\n",
    "\n",
    "import boto3\n",
    "import botocore\n",
    "import datetime\n",
    "import numpy as np\n",
    "import os\n",
    "import pooch\n",
    "import tempfile\n",
    "import geoviews as gv\n",
    "import holoviews\n",
    "from geoviews import Dataset as gvDataset\n",
    "import geoviews.feature as gf\n",
    "from geoviews import Image as gvImage\n",
    "\n",
    "from cartopy import crs as ccrs\n",
    "from cartopy import feature as cfeature\n",
    "\n",
    "# import warnings\n",
    "# #  Suppress warnings issued by Cartopy when downloading data files\n",
    "# warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Figure Settings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# @title Figure Settings\n",
    "import ipywidgets as widgets  # interactive display\n",
    "\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "plt.style.use(\n",
    "    \"https://raw.githubusercontent.com/ClimateMatchAcademy/course-content/main/cma.mplstyle\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Helper functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# @title Helper functions\n",
    "\n",
    "def pooch_load(filelocation=None, filename=None, processor=None):\n",
    "    shared_location = \"/home/jovyan/shared/Data/tutorials/W1D2_StateoftheClimateOceanandAtmosphereReanalysis\"  # this is different for each day\n",
    "    user_temp_cache = tempfile.gettempdir()\n",
    "\n",
    "    if os.path.exists(os.path.join(shared_location, filename)):\n",
    "        file = os.path.join(shared_location, filename)\n",
    "    else:\n",
    "        file = pooch.retrieve(\n",
    "            filelocation,\n",
    "            known_hash=None,\n",
    "            fname=os.path.join(user_temp_cache, filename),\n",
    "            processor=processor,\n",
    "        )\n",
    "\n",
    "    return file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Video 1: ECMWF Reanalysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "# @title Video 1: ECMWF Reanalysis\n",
    "\n",
    "from ipywidgets import widgets\n",
    "from IPython.display import YouTubeVideo\n",
    "from IPython.display import IFrame\n",
    "from IPython.display import display\n",
    "\n",
    "\n",
    "class PlayVideo(IFrame):\n",
    "  def __init__(self, id, source, page=1, width=400, height=300, **kwargs):\n",
    "    self.id = id\n",
    "    if source == 'Bilibili':\n",
    "      src = f'https://player.bilibili.com/player.html?bvid={id}&page={page}'\n",
    "    elif source == 'Osf':\n",
    "      src = f'https://mfr.ca-1.osf.io/render?url=https://osf.io/download/{id}/?direct%26mode=render'\n",
    "    super(PlayVideo, self).__init__(src, width, height, **kwargs)\n",
    "\n",
    "\n",
    "def display_videos(video_ids, W=400, H=300, fs=1):\n",
    "  tab_contents = []\n",
    "  for i, video_id in enumerate(video_ids):\n",
    "    out = widgets.Output()\n",
    "    with out:\n",
    "      if video_ids[i][0] == 'Youtube':\n",
    "        video = YouTubeVideo(id=video_ids[i][1], width=W,\n",
    "                             height=H, fs=fs, rel=0)\n",
    "        print(f'Video available at https://youtube.com/watch?v={video.id}')\n",
    "      else:\n",
    "        video = PlayVideo(id=video_ids[i][1], source=video_ids[i][0], width=W,\n",
    "                          height=H, fs=fs, autoplay=False)\n",
    "        if video_ids[i][0] == 'Bilibili':\n",
    "          print(f'Video available at https://www.bilibili.com/video/{video.id}')\n",
    "        elif video_ids[i][0] == 'Osf':\n",
    "          print(f'Video available at https://osf.io/{video.id}')\n",
    "      display(video)\n",
    "    tab_contents.append(out)\n",
    "  return tab_contents\n",
    "\n",
    "\n",
    "video_ids = [('Youtube', 'xn_SGxTm6LA'), ('Bilibili', 'BV1g94y1B7Yw')]\n",
    "tab_contents = display_videos(video_ids, W=730, H=410)\n",
    "tabs = widgets.Tab()\n",
    "tabs.children = tab_contents\n",
    "for i in range(len(tab_contents)):\n",
    "  tabs.set_title(i, video_ids[i][0])\n",
    "display(tabs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "# Section 1: What is Reanalysis Data?\n",
    "\n",
    "**Reanalysis** refers to the process of combining historical observations from a variety of sources, such as weather stations, satellite measurments, and ocean buoys, with numerical models to create a comprehensive and consistent record of past weather and climate conditions. Reanalysis data is a useful tool to examine the Earth's climate system over a wide range of time scales, from seasonal through decadal to century-scale changes. \n",
    "\n",
    "There are multiple Earth system reanalysis products (e.g. MERRA-2, NCEP-NCAR, JRA-55C, [see extensive list here](https://climatedataguide.ucar.edu/climate-data/atmospheric-reanalysis-overview-comparison-tables)), and no single product fits all needs. For the purposes of this tutorial you will be using a product from the European Centre for Medium-Range Weather Forecasts (ECMWF) called **ECMWF Reanalysis v5 (ERA5)**. [This video](https://climate.copernicus.eu/climate-reanalysis) from the ECMWF provides you with a brief introduction to the ERA5 product."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "## Section 1.1: Accessing ERA5 Data\n",
    "\n",
    "You will access the data through the an AWS S3 bucket of the data: [ECMWF ERA5 Reanalysis](https://registry.opendata.aws/ecmwf-era5/). To do this you need the name of the bucket \"era5-pds\", and the file location in the bucket. *Note: you can open the [AWS link](https://registry.opendata.aws/ecmwf-era5/) and find a guided tutorial on how to explore the S3 bucket.*\n",
    "\n",
    "Let's select a specific year and month to work with, March of 2018:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "era5_bucket = \"era5-pds\"\n",
    "client = boto3.client(\n",
    "    \"s3\", config=botocore.client.Config(signature_version=botocore.UNSIGNED)\n",
    ")  # initialize aws s3 bucket client\n",
    "date_sel = datetime.datetime(\n",
    "    2018, 3, 1, 0\n",
    ")  # select a desired date and hours (midnight is zero)\n",
    "prefix = date_sel.strftime(\"%Y/%m/\")  # format the date to match the s3 bucket\n",
    "metadata_file = \"main.nc\"  # filename on the s3 bucket\n",
    "metadata_key = prefix + metadata_file  # file location and name on the s3 bucket\n",
    "filepath = pooch_load(\n",
    "    filelocation=\"http://s3.amazonaws.com/\" + era5_bucket + \"/\" + metadata_key,\n",
    "    filename=metadata_file,\n",
    ")  # open the file\n",
    "\n",
    "ds_meta = xr.open_dataset(filepath)  # open the file\n",
    "ds_meta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "You just loaded an `xarray` dataset, as introduced at the first day. This dataset contains 19 variables covering the whole globe (-90 to +90 degrees in latitude, 0 to 360 degrees on longitude) along with their respective coordinates. With this dataset you have access to our best estimates of climate parameters with a temporal resolution of 1 hour and a spatial resolution of 1/4 degree (i.e. grid points near the Equator represent a ~25 km x 25 km region). This is a lot of data, but still just a fraction the data available through the [full ERA5 dataset](https://cds.climate.copernicus.eu/cdsapp#!/dataset/reanalysis-era5-land?tab=overview). \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "## Section 1.2: Selecting Regions of Interest\n",
    "The global ERA5 data over the entire time range is so large that even just one variable would be too large to store on your computer. Here you will apply a method to load a region (i.e., a spatial subset) of the data. In this first example, you will load *air surface temperature at 2 meters* data for a small region in the Northeastern United States. In later tutorials you will have the opportunity to select a region of your choice and to explore other climate variables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# the order of the lat lon range has to follow the convention of the data set.\n",
    "# for this dataset, longitude ranges from 0 to 360 degrees and\n",
    "# latitude ranges from 90 degrees Northto 90 degrees South .\n",
    "\n",
    "# northeastern United States\n",
    "lat_range = [55.2, 30.2]  # from north to south\n",
    "lon_range = [270, 295]  # from west to east"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note this can take several minutes to download\n",
    "selected_vars = [\n",
    "    \"air_temperature_at_2_metres\",\n",
    "    \"northward_wind_at_10_metres\",\n",
    "    \"eastward_wind_at_10_metres\",\n",
    "    \"surface_air_pressure\",\n",
    "    \"sea_surface_temperature\",\n",
    "]  # the variables we want\n",
    "s3_data_ptrn = (\n",
    "    \"{year}/{month}/data/{var}.nc\"  # path and filename format for this S3 bucket\n",
    ")\n",
    "year_s3 = date_sel.strftime(\"%Y\")  # extract the year\n",
    "month_s3 = date_sel.strftime(\"%m\")  # extract the month\n",
    "ERA5_select = []  # initialize the dataset, will save a complicated check later\n",
    "for var in selected_vars:  # this will download 5 files of 500Mb each.\n",
    "    s3_data_key = s3_data_ptrn.format(\n",
    "        year=year_s3, month=month_s3, var=var\n",
    "    )  # variable specific  key\n",
    "    print(\"Downloading %s from S3...\" % s3_data_key)\n",
    "    filepath = pooch_load(\n",
    "        filelocation=\"http://s3.amazonaws.com/\" + era5_bucket + \"/\" + s3_data_key,\n",
    "        filename=s3_data_key,\n",
    "    )  # open the file\n",
    "    ds_temp = xr.open_dataset(filepath)  # retrieve the variable from the bucket\n",
    "    if (\n",
    "        ERA5_select\n",
    "    ):  # check if the dataset is empty or not (first iteration of the loop)\n",
    "        ERA5_select = xr.merge(\n",
    "            [ERA5_select, ds_temp]\n",
    "        )  # if not empty, merge the new file\n",
    "    else:\n",
    "        ERA5_select = ds_temp  # if empty, just assign the new file\n",
    "\n",
    "ERA5_allvars = ERA5_select.sel(lon=slice(lon_range[0], lon_range[1])).sel(\n",
    "    lat=slice(lat_range[0], lat_range[1])\n",
    ")\n",
    "ERA5_allvars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "The magnitude of the wind vector represents the wind speed \n",
    "\n",
    "\\begin{align}\n",
    "||u|| = \\sqrt{u^2 + v^2}\n",
    "\\end{align}\n",
    "\n",
    "which you will use later in the tutorial and discuss in more detail in tutorial 4. We will calculate that here and add it to our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute ten meter wind speed\n",
    "ERA5_allvars[\"wind_speed\"] = np.sqrt(\n",
    "    ERA5_allvars[\"northward_wind_at_10_metres\"] ** 2\n",
    "    + ERA5_allvars[\"eastward_wind_at_10_metres\"] ** 2\n",
    ")  # calculate the wind speed from the vectors\n",
    "# name and units in the DataArray:\n",
    "ERA5_allvars[\"wind_speed\"].attrs[\n",
    "    \"long_name\"\n",
    "] = \"10-meter wind speed\"  # assigning long name to the windspeed\n",
    "ERA5_allvars[\"wind_speed\"].attrs[\"units\"] = \"m/s\"  # assigning units\n",
    "ERA5_allvars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "# Section 2: Plotting Spatial Maps of Reanalysis Data\n",
    "First, let's plot the region's surface temperature for the first time step of the reanalysis dataset. To do this let's extract the air temperatre data from the dataset containing all the variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_surface_temp_2m = ERA5_allvars.air_temperature_at_2_metres"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "We will be plotting this a little bit differently that you have previously plotted a map (and differently to how you will plot in most tutorials) so we can look at a few times steps interactively later. To do this we are using the package [geoviews](https://geoviews.org). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "holoviews.extension(\"bokeh\")\n",
    "\n",
    "dataset_plot = gvDataset(ds_surface_temp_2m.isel(time0=0))  # select the first time step\n",
    "\n",
    "# create the image\n",
    "images = dataset_plot.to(\n",
    "    gvImage, [\"longitude\", \"latitude\"], [\"air_temperature_at_2_metres\"], \"hour\"\n",
    ")\n",
    "\n",
    "# aesthetics, add coastlines etc.\n",
    "images.opts(\n",
    "    cmap=\"coolwarm\",\n",
    "    colorbar=True,\n",
    "    width=600,\n",
    "    height=400,\n",
    "    projection=ccrs.PlateCarree(),\n",
    "    clabel=\"2m Air Temperature [K]\",\n",
    ") * gf.coastline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "In the above figure, coastlines are shown as black lines. Most of the selected region is land, with some ocean (lower left) and a lake (top middle).\n",
    "\n",
    "Next, we will examine variability at two different frequencies using interactive plots:\n",
    "\n",
    "1. **Hourly variability** \n",
    "2. **Daily variability** \n",
    "\n",
    "Note that in the previous tutorial you computed the monthly variability, or *climatology*, but here you only have one month of data loaded (March 2018). If you are curious about longer timescales you will visit this in the next tutorial!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# interactive plot of hourly frequency of surface temperature\n",
    "# this cell may take a little longer as it contains several maps in a single plotting function\n",
    "ds_surface_temp_2m_hour = ds_surface_temp_2m.groupby(\"time0.hour\").mean()\n",
    "dataset_plot = gvDataset(\n",
    "    ds_surface_temp_2m_hour.isel(hour=slice(0, 12))\n",
    ")  # only the first 12 time steps, as it is a time consuming task\n",
    "images = dataset_plot.to(\n",
    "    gvImage, [\"longitude\", \"latitude\"], [\"air_temperature_at_2_metres\"], \"hour\"\n",
    ")\n",
    "images.opts(\n",
    "    cmap=\"coolwarm\",\n",
    "    colorbar=True,\n",
    "    width=600,\n",
    "    height=400,\n",
    "    projection=ccrs.PlateCarree(),\n",
    "    clabel=\"2m Air Temperature [K]\",\n",
    ") * gf.coastline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# interactive plot of hourly frequency of surface temperature\n",
    "# this cell may take a little longer as it contains several maps in a single plotting function holoviews.extension('bokeh')\n",
    "ds_surface_temp_2m_day = ds_surface_temp_2m.groupby(\"time0.day\").mean()\n",
    "dataset_plot = gvDataset(\n",
    "    ds_surface_temp_2m_day.isel(day=slice(0, 10))\n",
    ")  # only the first 10 time steps, as it is a time consuming task\n",
    "images = dataset_plot.to(\n",
    "    gvImage, [\"longitude\", \"latitude\"], [\"air_temperature_at_2_metres\"], \"day\"\n",
    ")\n",
    "images.opts(\n",
    "    cmap=\"coolwarm\",\n",
    "    colorbar=True,\n",
    "    width=600,\n",
    "    height=400,\n",
    "    projection=ccrs.PlateCarree(),\n",
    "    clabel=\"Air Temperature [K]\",\n",
    ") * gf.coastline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "### Question 2\n",
    "1. What differences do you notice between the hourly and daily interactive plots, and are there any interesting spatial patterns of these temperature changes?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "# Section 3: Plotting Timeseries of Reanalysis Data\n",
    "\n",
    "## Section 3.1: Surface Air Temperature Timeseries\n",
    "\n",
    "You have demonstrated that there are a lot of changes in surface temperature within a day and between days. It is crucial to understand this *temporal variability* in the data when performing climate analysis.\n",
    "\n",
    "Rather than plotting interactive spatial maps for different timescales, in this last section you will create a timeseries of surface air temperature from the data you have already examined to look at variability on longer than daily timescales. Instead of taking the mean in ***time*** to create *maps*, you will now take the mean in ***space*** to create *timeseries*.\n",
    "\n",
    "*Note that the spatially-averaged data will now only have a time coordinate coordinate, making it a timeseries (ts).*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# find weights (this is a regular grid so we can use cos(lat))\n",
    "weights = np.cos(np.deg2rad(ds_surface_temp_2m.lat))\n",
    "weights.name = \"weights\"\n",
    "\n",
    "# take the weighted spatial mean since the latitude range of the region of interest is large\n",
    "ds_surface_temp_2m_ts = ds_surface_temp_2m.weighted(weights).mean([\"lon\", \"lat\"])\n",
    "ds_surface_temp_2m_ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the timeseries of surface temperature\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 3))\n",
    "\n",
    "ax.plot(ds_surface_temp_2m_ts.time0, ds_surface_temp_2m_ts)\n",
    "ax.set_ylabel(\"2m Air \\nTemperature (K)\")\n",
    "ax.xaxis.set_tick_params(rotation=45)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "### Questions 3.1\n",
    "1. What is the dominant source of the high frequency (short timescale) variability? \n",
    "2. What drives the lower frequency variability? \n",
    "3. Would the ENSO variablity that you computed in the previous tutorial show up here? Why or why not?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "## Section 3.2: Comparing Timeseries of Multiple Variables\n",
    "\n",
    "Below you will calculate the timeseries of the surface air temperature which we just plotted, alongside timeseries of several other ERA5 variables for the same period and region: 10-meter wind speed, atmospheric surface pressure, and sea surface temperature. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ERA5_allvars_ts = ERA5_allvars.weighted(weights).mean([\"lon\", \"lat\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_vars = [\n",
    "    \"air_temperature_at_2_metres\",\n",
    "    \"wind_speed\",\n",
    "    \"surface_air_pressure\",\n",
    "    \"sea_surface_temperature\",\n",
    "]\n",
    "\n",
    "fig, ax_list = plt.subplots(len(plot_vars), 1, figsize=(10, 13), sharex=True)\n",
    "\n",
    "for var, ax in zip(plot_vars, ax_list):\n",
    "\n",
    "    ax.plot(ERA5_allvars_ts.time0, ERA5_allvars_ts[var])\n",
    "    ax.set_ylabel(\n",
    "        ERA5_allvars[var].attrs[\"long_name\"] + \": \" + ERA5_allvars[var].attrs[\"units\"],\n",
    "        fontsize=12,\n",
    "    )\n",
    "    ax.xaxis.set_tick_params(rotation=45)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {},
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Questions 3.2\n",
    "\n",
    "Which variable shows variability that is dominated by:\n",
    "1. The diurnal cycle?\n",
    "2. The synoptic [~5 day] scale?\n",
    "3. A mix of these two timescales?\n",
    "4. Longer timescales?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "## Bonus Section 1: Selecting a Different Spatial Region\n",
    "\n",
    "Define another spatial region, such as where you live, by selecting a longitude and latitude range of of your choosing. To find the longitude and latitude coordinates of your region, you can use [Google Earth view](https://earth.google.com/), and read the position of your cursor in the lower right corner.\n",
    "\n",
    "### Bonus Section 1.1: Note About the Geographic Coordinate System and the Coordinates Used in This Dataset\n",
    "A point on Earth is described by latitude-longitude coordinates relative to the zero-meridian line going through Greenwich in London, UK (longitude = 0 degree) and the xero-latitude line along the equator (latitude = 0 degrees). Points east of Greenwich up to the *dateline* on the opposite side of the globe are referenced as 0 to +180 and points to the west of Greenwich are 0 to -180. -180 and +180 refer to the same longitude, the so-called *dateline* in the central pacific. \n",
    "\n",
    "However, our data is referenced in a slightly different way where longitude runs from 0 to 360 rather than -180 to +180. Longitude increases as you move east of Greenwich, until you reach Greenwich again (0 or 360 degrees), rather than stopping at the *dateline*. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "# Summary\n",
    "\n",
    "In this tutorial, you learned how to access and process ERA5 reanalysis data. You are able to select specific regions within the reanalysis dataset and perform operations such as taking spatial and temporal averages.\n",
    "\n",
    "You also looked at different climate variables to distinguish idenitfy the variability present at different timescales.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "# Resources\n",
    "\n",
    "Data for this tutorial can be accessed [here](https://registry.opendata.aws/ecmwf-era5/)."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "W1D2_Tutorial2",
   "provenance": [],
   "toc_visible": true
  },
  "kernel": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "climatematch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}